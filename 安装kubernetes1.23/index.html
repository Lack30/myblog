<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>安装kubernetes1.23 - lack 的个人博客</title><meta name="Description" content="关于 DoIt 主题"><meta property="og:title" content="安装kubernetes1.23" />
<meta property="og:description" content="本文介绍如何通过 Kubeadm 工具安装 Kubernetes 1.23。 一、准备 1.1 系统环境 准备三台vmware虚拟机，配置为 CentOS7.6 / 2Core / 2G，系统环境如下: 1 2 3 172.16.219.100 k8s-master 172.16.219.101 k8s-slave1 172.16.219.102 k8s-slave2 1.2 配" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://xingyys.tech/%E5%AE%89%E8%A3%85kubernetes1.23/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-01-13T18:44:33+08:00" />
<meta property="article:modified_time" content="2022-01-13T18:44:33+08:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="安装kubernetes1.23"/>
<meta name="twitter:description" content="本文介绍如何通过 Kubeadm 工具安装 Kubernetes 1.23。 一、准备 1.1 系统环境 准备三台vmware虚拟机，配置为 CentOS7.6 / 2Core / 2G，系统环境如下: 1 2 3 172.16.219.100 k8s-master 172.16.219.101 k8s-slave1 172.16.219.102 k8s-slave2 1.2 配"/>
<meta name="application-name" content="DoIt">
<meta name="apple-mobile-web-app-title" content="DoIt"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://xingyys.tech/%E5%AE%89%E8%A3%85kubernetes1.23/" /><link rel="prev" href="http://xingyys.tech/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" /><link rel="next" href="http://xingyys.tech/clion%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95c%E4%BB%A3%E7%A0%81/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><meta name="google-site-verification" content="MQ8DNu27ayX6B_4ObiEDK09vGr1fdy7kOAnbd09hJk4" /><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "安装kubernetes1.23",
        "inLanguage": "zh-CN",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/xingyys.tech\/%E5%AE%89%E8%A3%85kubernetes1.23\/"
        },"image": ["http:\/\/xingyys.tech\/images\/Apple-Devices-Preview.png"],"genre": "posts","keywords": "k8s","wordcount":  3854 ,
        "url": "http:\/\/xingyys.tech\/%E5%AE%89%E8%A3%85kubernetes1.23\/","datePublished": "2022-01-13T18:44:33+08:00","dateModified": "2022-01-13T18:44:33+08:00","license": "This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.","publisher": {
            "@type": "Organization",
            "name": "xxxx","logo": {
                    "@type": "ImageObject",
                    "url": "http:\/\/xingyys.tech\/images\/avatar.webp",
                    "width":  528 ,
                    "height":  560 
                }},"author": {
                "@type": "Person",
                "name": "Lack"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="lack 的个人博客">Lack个人博客</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> 所有文章 </a><a class="menu-item" href="/tags/"> 标签 </a><a class="menu-item" href="/categories/"> 分类 </a><a class="menu-item" href="/authors/"> 作者 </a><a class="menu-item" href="https://github.com/lack-io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i>  </a><a class="menu-item" href="/about/" title="关于"> 关于 </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item language" title="选择语言">简体中文<i class="fas fa-chevron-right fa-fw"></i>
                        <select class="language-select" id="language-select-desktop" onchange="location = this.value;"><option value="/%E5%AE%89%E8%A3%85kubernetes1.23/" selected>简体中文</option></select>
                    </a><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="lack 的个人博客">Lack个人博客</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="搜索文章标题或内容..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="搜索">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="清空">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        取消
                    </a>
                </div><a class="menu-item" href="/posts/" title="">所有文章</a><a class="menu-item" href="/tags/" title="">标签</a><a class="menu-item" href="/categories/" title="">分类</a><a class="menu-item" href="/authors/" title="">作者</a><a class="menu-item" href="https://github.com/lack-io" title="GitHub" rel="noopener noreffer" target="_blank"><i class='fab fa-github fa-fw'></i></a><a class="menu-item" href="/about/" title="关于">关于</a><a href="javascript:void(0);" class="menu-item theme-switch" title="切换主题">
                <i class="fas fa-adjust fa-fw"></i>
            </a><a href="javascript:void(0);" class="menu-item" title="选择语言">简体中文<i class="fas fa-chevron-right fa-fw"></i>
                    <select class="language-select" onchange="location = this.value;"><option value="/%E5%AE%89%E8%A3%85kubernetes1.23/" selected>简体中文</option></select>
                </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">目录</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">安装kubernetes1.23</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/lack-io" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>Lack</a></span>&nbsp;<span class="post-category">收录于 <a href="/categories/%E4%BA%91%E5%8E%9F%E7%94%9F/"><i class="far fa-folder fa-fw"></i>云原生</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-01-13">2022-01-13</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;约 3854 字&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;预计阅读 8 分钟&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="">
                <div class="details-summary toc-title">
                    <span>目录</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#一准备">一、准备</a>
      <ul>
        <li><a href="#11-系统环境">1.1 系统环境</a></li>
        <li><a href="#12-配置防火墙">1.2 配置防火墙</a></li>
        <li><a href="#13-关闭-swap-分区">1.3 关闭 swap 分区</a></li>
        <li><a href="#14-部署-containerd">1.4 部署 containerd</a></li>
      </ul>
    </li>
    <li><a href="#二部署-kubernetes">二、部署 Kubernetes</a>
      <ul>
        <li><a href="#21-安装-kubeadm">2.1 安装 kubeadm</a></li>
        <li><a href="#22-初始化集群">2.2 初始化集群</a></li>
        <li><a href="#23-安装-helm-包管理器">2.3 安装 helm 包管理器</a></li>
        <li><a href="#24-安装-calico">2.4 安装 Calico</a></li>
        <li><a href="#25-添加工作节点">2.5 添加工作节点</a></li>
      </ul>
    </li>
    <li><a href="#三kubernetes-常用组件">三、Kubernetes 常用组件</a>
      <ul>
        <li><a href="#31-部署-ingress-nginx">3.1 部署 ingress-nginx</a></li>
        <li><a href="#32-部署-metrics-server">3.2 部署 metrics-server</a></li>
        <li><a href="#33-部署-dashboard">3.3 部署 dashboard</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>本文介绍如何通过 Kubeadm 工具安装 Kubernetes 1.23。</p>
<h2 id="一准备">一、准备</h2>
<h3 id="11-系统环境">1.1 系统环境</h3>
<p>准备三台vmware虚拟机，配置为 CentOS7.6 / 2Core / 2G，系统环境如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">172.16.219.100 k8s-master
172.16.219.101 k8s-slave1
172.16.219.102 k8s-slave2
</code></pre></td></tr></table>
</div>
</div><h3 id="12-配置防火墙">1.2 配置防火墙</h3>
<p>关闭Linux的防火墙</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">systemctl stop firewalld
systemctl disable firewalld
</code></pre></td></tr></table>
</div>
</div><p>关闭 selinux</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">setenforce <span class="m">0</span>
</code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">vim /etc/selinux/config
<span class="nv">SELINUX</span><span class="o">=</span>disabled
</code></pre></td></tr></table>
</div>
</div><h3 id="13-关闭-swap-分区">1.3 关闭 swap 分区</h3>
<p>Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动。 关闭系统的Swap方法如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">swapoff -a
</code></pre></td></tr></table>
</div>
</div><p>同时修改 <code>/etc/fstab</code>:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="c1">#UUID=7f0f3bd8-3605-4ad7-81b0-1a91c735969f swap                    swap    defaults        0 0</span>
</code></pre></td></tr></table>
</div>
</div><h3 id="14-部署-containerd">1.4 部署 containerd</h3>
<p>kubernetes 1.22 版本之后，默认的容器运行时变成 containerd。所以在安装 k8s 之前先安装 containerd。</p>
<p>配置 overlay</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">cat <span class="s">&lt;&lt; EOF &gt; /etc/modules-load.d/containerd.conf
</span><span class="s">overlay
</span><span class="s">br_netfilter
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><p>加载内核配置</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">modprobe overlay
modprobe br_netfilter
</code></pre></td></tr></table>
</div>
</div><p>修改网络相关的内核参数</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">cat <span class="s">&lt;&lt; EOF &gt; /etc/sysctl.d/99-kubernetes-cri.conf
</span><span class="s">net.bridge.bridge-nf-call-ip6tables = 1
</span><span class="s">net.bridge.bridge-nf-call-iptables = 1
</span><span class="s">net.ipv4.ip_forward = 1
</span><span class="s">user.max_user_namespaces=28633
</span><span class="s">vm.swappiness=0
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><p>加载配置</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">sysctl -p /etc/sysctl.d/99-kubernetes-cri.conf
</code></pre></td></tr></table>
</div>
</div><p>现在 kube-proxy 可以使用 ipvs 来代替原来的 iptables。配置 ipvs:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">cat &gt; /etc/sysconfig/modules/ipvs.modules <span class="s">&lt;&lt;EOF
</span><span class="s">#!/bin/bash
</span><span class="s">modprobe -- ip_vs
</span><span class="s">modprobe -- ip_vs_rr
</span><span class="s">modprobe -- ip_vs_wrr
</span><span class="s">modprobe -- ip_vs_sh
</span><span class="s">modprobe -- nf_conntrack_ipv4
</span><span class="s">EOF</span>

chmod <span class="m">755</span> /etc/sysconfig/modules/ipvs.modules 
bash /etc/sysconfig/modules/ipvs.modules 
</code></pre></td></tr></table>
</div>
</div><p>安装 ipvs 工具，方便管理 ipvs 规则</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">yum install -y ipset ipvsadm
</code></pre></td></tr></table>
</div>
</div><p>安装部署 containerd，在各个节点上安装 containerd</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">wget https://github.com/containerd/containerd/releases/download/v1.5.8/cri-containerd-cni-1.5.8-linux-amd64.tar.gz
</code></pre></td></tr></table>
</div>
</div><p>直接解压到 <code>/</code> 目录下，</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">tar -zxvf cri-containerd-cni-1.5.8-linux-amd64.tar.gz -C /
</code></pre></td></tr></table>
</div>
</div><p>由于 <code>cri-containerd-cni-1.5.8-linux-amd64.tar.gz</code> 包内部的 runc 包在 CentOS7 下的动态链接有问题，所以需要下载二进制文件替换它。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">wget https://github.com/opencontainers/runc/releases/download/v1.1.0-rc.1/runc.amd64
mv runc.amd64 /usr/local/sbin/runc
</code></pre></td></tr></table>
</div>
</div><p>生成 containerd 的配置文件并修改</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">mkdir -p /etc/containerd
containerd config default &gt; /etc/containerd/config.toml
</code></pre></td></tr></table>
</div>
</div><p>根据文档Container runtimes 中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为容器的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里配置各个节点上containerd的cgroup driver为systemd。</p>
<p>修改前面生成的配置文件 <code>/etc/containerd/config.toml</code>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc<span class="o">]</span>
  ...
  <span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span class="o">]</span>
    <span class="nv">SystemdCgroup</span> <span class="o">=</span> <span class="nb">true</span>
</code></pre></td></tr></table>
</div>
</div><p>由于 k8s.grc.io 被墙，替换成国内源。再修改 <code>/etc/containerd/config.toml</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="o">[</span>plugins.<span class="s2">&#34;io.containerd.grpc.v1.cri&#34;</span><span class="o">]</span>
  ...
  <span class="c1"># sandbox_image = &#34;k8s.gcr.io/pause:3.5&#34;</span>
  <span class="nv">sandbox_image</span> <span class="o">=</span> <span class="s2">&#34;registry.aliyuncs.com/google_containers/pause:3.6&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>配置 containerd 开机自启</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">systemctl <span class="nb">enable</span> containerd
systemctl start containerd
</code></pre></td></tr></table>
</div>
</div><p>执行 crictl 命令测试</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"> crictl version
Version:  0.1.0
RuntimeName:  containerd
RuntimeVersion:  v1.5.8
RuntimeApiVersion:  v1alpha2
</code></pre></td></tr></table>
</div>
</div><h2 id="二部署-kubernetes">二、部署 Kubernetes</h2>
<h3 id="21-安装-kubeadm">2.1 安装 kubeadm</h3>
<p>环境都准备完成后，开始证实安装 k8s。在每个节点上安装 kubeadm 和 kubelet，先配置 yum 源</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">cat <span class="s">&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span><span class="s">[kubernetes]
</span><span class="s">name=Kubernetes
</span><span class="s">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
</span><span class="s">enabled=1
</span><span class="s">gpgcheck=0
</span><span class="s">repo_gpgcheck=0
</span><span class="s">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
</span><span class="s">        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span><span class="s">EOF</span>
</code></pre></td></tr></table>
</div>
</div><p>更新缓存</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">yum makecache fast
yum install -y kubelet kubeadm kubectl
</code></pre></td></tr></table>
</div>
</div><p>开机启动 kubelet 服务</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">systemctl <span class="nb">enable</span> kubelet
</code></pre></td></tr></table>
</div>
</div><h3 id="22-初始化集群">2.2 初始化集群</h3>
<p>使用 <code>kubeadm config print init-defaults --component-configs KubeletConfiguration</code> 可以打印集群初始化默认的使用的配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 1.2.3.4
  bindPort: <span class="m">6443</span>
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  imagePullPolicy: IfNotPresent
  name: node
  taints: null
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: <span class="o">{}</span>
dns: <span class="o">{}</span>
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: k8s.gcr.io
kind: ClusterConfiguration
kubernetesVersion: 1.23.0
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
scheduler: <span class="o">{}</span>
---
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: <span class="nb">false</span>
  webhook:
    cacheTTL: 0s
    enabled: <span class="nb">true</span>
  x509:
    clientCAFile: /etc/kubernetes/pki/ca.crt
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 0s
    cacheUnauthorizedTTL: 0s
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
cpuManagerReconcilePeriod: 0s
evictionPressureTransitionPeriod: 0s
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: <span class="m">10248</span>
httpCheckFrequency: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
logging:
  flushFrequency: <span class="m">0</span>
  options:
    json:
      infoBufferSize: <span class="s2">&#34;0&#34;</span>
  verbosity: <span class="m">0</span>
memorySwap: <span class="o">{}</span>
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
rotateCertificates: <span class="nb">true</span>
runtimeRequestTimeout: 0s
shutdownGracePeriod: 0s
shutdownGracePeriodCriticalPods: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s
</code></pre></td></tr></table>
</div>
</div><p>从默认的配置中可以看到，可以使用<code>imageRepository</code>定制在集群初始化时拉取k8s所需镜像的地址。基于默认配置定制出本次使用kubeadm初始化集群所需的配置文件<code>kubeadm.yaml</code>：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 172.16.219.100
  bindPort: <span class="m">6443</span>
nodeRegistration:
  criSocket: /run/containerd/containerd.sock
  taints:
  - effect: PreferNoSchedule
    key: node-role.kubernetes.io/master
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.23.1
imageRepository: registry.aliyuncs.com/google_containers
networking:
  podSubnet: 10.244.0.0/16
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cgroupDriver: systemd
failSwapOn: <span class="nb">false</span>
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs
</code></pre></td></tr></table>
</div>
</div><p>这里定制了<code>imageRepository</code>为阿里云的registry，避免因gcr被墙，无法直接拉取镜像。<code>criSocket</code> 设置了容器运行时为containerd。 同时设置kubelet的<code>cgroupDriver</code>为systemd，设置kube-proxy代理模式为ipvs。</p>
<p>在开始初始化集群之前可以使用<code>kubeadm config images pull --config kubeadm.yaml</code>预先在各个服务器节点上拉取所k8s需要的容器镜像。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubeadm config images pull --config kubeadm.yaml
</code></pre></td></tr></table>
</div>
</div><p>接下来使用kubeadm初始化集群，选择node1作为Master Node，在node1上执行下面的命令：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubeadm init --config kubeadm.yaml
</code></pre></td></tr></table>
</div>
</div><p>执行过程中会输出相关日志。其中有以下关键内容：</p>
<ul>
<li><code>[certs]</code>生成相关的各种证书</li>
<li><code>[kubeconfig]</code>生成相关的kubeconfig文件</li>
<li><code>[kubelet-start]</code> 生成kubelet的配置文件&quot;<code>/var/lib/kubelet/config.yaml</code>&quot;</li>
<li><code>[control-plane]</code>使用/etc/kubernetes/manifests目录中的yaml文件创建apiserver、controller-manager、scheduler的静态pod</li>
<li><code>[bootstraptoken]</code>生成token记录下来，后边使用<code>kubeadm join</code>往集群中添加节点时会用到</li>
<li>下面的命令是配置常规用户如何使用kubectl访问集群：</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">mkdir -p <span class="nv">$HOME</span>/.kube
sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</code></pre></td></tr></table>
</div>
</div><ul>
<li>最后给出添加新的工作节点命令<code>kubeadm join 172.16.219.100:6443 --token rdm2to.z9n608f4ix4lnik8 --discovery-token-ca-cert-hash sha256:047a21a7d519b87e594d36a6fdbfadc86557cd602ee58bda8f7fc97f38cba4d9</code></li>
</ul>
<p>查看集群状态</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl get cs
Warning: v1 ComponentStatus is deprecated in v1.19+
NAME                 STATUS    MESSAGE                         ERROR
controller-manager   Healthy   ok
scheduler            Healthy   ok
etcd-0               Healthy   <span class="o">{</span><span class="s2">&#34;health&#34;</span>:<span class="s2">&#34;true&#34;</span>,<span class="s2">&#34;reason&#34;</span>:<span class="s2">&#34;&#34;</span><span class="o">}</span>
</code></pre></td></tr></table>
</div>
</div><blockquote>
<p>注意：如果集群初始化中出现问题，可以使用 <code>kubeadm reset</code> 命令清除安装的内容，再重新安装。</p>
</blockquote>
<h3 id="23-安装-helm-包管理器">2.3 安装 helm 包管理器</h3>
<p>helm 是开源的 k8s 包管理工具，可以简化 k8s 服务的安装步骤。安装命令如下:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz
tar -zxvf helm-v3.7.2-linux-amd64.tar.gz
mv linux-amd64/helm  /usr/local/bin/
</code></pre></td></tr></table>
</div>
</div><p>使用命令 <code>helm list</code> 检查。</p>
<h3 id="24-安装-calico">2.4 安装 Calico</h3>
<p>使用 Calico 作为 k8s 的 CNI。这里使用 helm 安装。
下载 <code>tigera-openrator</code> 的 helm chart：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">wget https://github.com/projectcalico/calico/releases/download/v3.21.2/tigera-operator-v3.21.2-1.tgz
</code></pre></td></tr></table>
</div>
</div><p>查看这个 chart 中可定制的配置:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">helm show values tigera-operator-v3.21.2-1.tgz &gt; calico.yaml
 
imagePullSecrets: <span class="o">{}</span>

installation:
  enabled: <span class="nb">true</span>
  kubernetesProvider: <span class="s2">&#34;&#34;</span>

apiServer:
  enabled: <span class="nb">true</span>

certs:
  node:
    key:
    cert:
    commonName:
  typha:
    key:
    cert:
    commonName:
    caBundle:

<span class="c1"># Configuration for the tigera operator</span>
tigeraOperator:
  image: tigera/operator
  version: v1.23.3
  registry: quay.io
calicoctl:
  image: quay.io/docker.io/calico/ctl
  tag: v3.21.2
</code></pre></td></tr></table>
</div>
</div><p>使用 helm 安装 calico</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">helm install calico tigera-operator-v3.21.2-1.tgz -f calico.yaml
</code></pre></td></tr></table>
</div>
</div><p>等待所有 Pod 安装完成</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl get pods -n calico-system
NAME                                       READY   STATUS    RESTARTS   AGE
calico-kube-controllers-59c45ff85c-cvzg6   1/1     Running   <span class="m">0</span>          9h
calico-node-lb7q8                          0/1     Running   <span class="m">0</span>          9h
calico-typha-68c8b9b5ff-bdh6h              1/1     Running   <span class="m">0</span>          9h
</code></pre></td></tr></table>
</div>
</div><p>查看 calico 新增的相关资源</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl api-resources <span class="p">|</span> grep calico
bgpconfigurations                              crd.projectcalico.org/v1               <span class="nb">false</span>        BGPConfiguration
bgppeers                                       crd.projectcalico.org/v1               <span class="nb">false</span>        BGPPeer
blockaffinities                                crd.projectcalico.org/v1               <span class="nb">false</span>        BlockAffinity
caliconodestatuses                             crd.projectcalico.org/v1               <span class="nb">false</span>        CalicoNodeStatus
clusterinformations                            crd.projectcalico.org/v1               <span class="nb">false</span>        ClusterInformation
felixconfigurations                            crd.projectcalico.org/v1               <span class="nb">false</span>        FelixConfiguration
globalnetworkpolicies                          crd.projectcalico.org/v1               <span class="nb">false</span>        GlobalNetworkPolicy
globalnetworksets                              crd.projectcalico.org/v1               <span class="nb">false</span>        GlobalNetworkSet
hostendpoints                                  crd.projectcalico.org/v1               <span class="nb">false</span>        HostEndpoint
ipamblocks                                     crd.projectcalico.org/v1               <span class="nb">false</span>        IPAMBlock
ipamconfigs                                    crd.projectcalico.org/v1               <span class="nb">false</span>        IPAMConfig
ipamhandles                                    crd.projectcalico.org/v1               <span class="nb">false</span>        IPAMHandle
ippools                                        crd.projectcalico.org/v1               <span class="nb">false</span>        IPPool
ipreservations                                 crd.projectcalico.org/v1               <span class="nb">false</span>        IPReservation
kubecontrollersconfigurations                  crd.projectcalico.org/v1               <span class="nb">false</span>        KubeControllersConfiguration
networkpolicies                                crd.projectcalico.org/v1               <span class="nb">true</span>         NetworkPolicy
networksets                                    crd.projectcalico.org/v1               <span class="nb">true</span>         NetworkSet
</code></pre></td></tr></table>
</div>
</div><p>这些api资源是属于calico的，因此不建议使用kubectl来管理，推荐按照calicoctl来管理这些api资源。 将calicoctl安装为kubectl的插件:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="nb">cd</span> /usr/local/bin
curl -o kubectl-calico -O -L  <span class="s2">&#34;https://github.com/projectcalico/calicoctl/releases/download/v3.21.2/calicoctl&#34;</span> 
chmod +x kubectl-calico
</code></pre></td></tr></table>
</div>
</div><p>验证插件正常工作:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl calico -h
</code></pre></td></tr></table>
</div>
</div><p>检测 k8s CoreDns 服务</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl run curl --image<span class="o">=</span>radial/busyboxplus:curl -it
If you don<span class="err">&#39;</span>t see a <span class="nb">command</span> prompt, try pressing enter.
<span class="o">[</span> root@curl:/ <span class="o">]</span>$
</code></pre></td></tr></table>
</div>
</div><p>通过命令 nslookup kubernetes.default 检测</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">nslookup kubernetes.default
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
</code></pre></td></tr></table>
</div>
</div><h3 id="25-添加工作节点">2.5 添加工作节点</h3>
<p>将 k8s-slave1 和 k8s-slave2 节点添加到集群中。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubeadm join 172.16.219.100:6443 --token rdm2to.z9n608f4ix4lnik8 --discovery-token-ca-cert-hash sha256:047a21a7d519b87e594d36a6fdbfadc86557cd602ee58bda8f7fc97f38cba4d9<span class="sb">`</span>
</code></pre></td></tr></table>
</div>
</div><p>在 k8s-master 上测试结果：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl get nodes
NAME         STATUS   ROLES                       AGE   VERSION
k8s-master   Ready    control-plane,edge,master   9h    v1.23.1
k8s-slave1   Ready    &lt;none&gt;                      9h    v1.23.1
k8s-slave2   Ready    &lt;none&gt;                      9h    v1.23.1
</code></pre></td></tr></table>
</div>
</div><h2 id="三kubernetes-常用组件">三、Kubernetes 常用组件</h2>
<h3 id="31-部署-ingress-nginx">3.1 部署 ingress-nginx</h3>
<p>k8s 提供 ingress，可以间集群的服务提供给外部进行访问。Nginx Ingress Controller被部署在Kubernetes的边缘节点上。</p>
<p>这里将node1(172.168.219.101)作为边缘节点，打上Label：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl label node k8s-slave1 node-role.kubernetes.io/edge<span class="o">=</span>
</code></pre></td></tr></table>
</div>
</div><p>下载 ingress-nginx</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">wget https://github.com/kubernetes/ingress-nginx/releases/download/helm-chart-4.0.13/ingress-nginx-4.0.13.tgz
</code></pre></td></tr></table>
</div>
</div><p>修改 chart 的配置：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">controller:
  ingressClassResource:
    name: nginx
    enabled: <span class="nb">true</span>
    default: <span class="nb">true</span>
    controllerValue: <span class="s2">&#34;k8s.io/ingress-nginx&#34;</span>
  admissionWebhooks:
    enabled: <span class="nb">false</span>
  replicaCount: <span class="m">1</span>
  image:
    <span class="c1"># registry: k8s.gcr.io</span>
    <span class="c1"># image: ingress-nginx/controller</span>
    <span class="c1"># tag: &#34;v1.1.0&#34;</span>
    registry: docker.io
    image: unreachableg/k8s.gcr.io_ingress-nginx_controller
    tag: <span class="s2">&#34;v1.1.0&#34;</span>
    digest: sha256:4f5df867e9367f76acfc39a0f85487dc63526e27735fa82fc57d6a652bafbbf6
  hostNetwork: <span class="nb">true</span>
  nodeSelector:
    node-role.kubernetes.io/edge: <span class="s1">&#39;&#39;</span>
  affinity:
    podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - nginx-ingress
            - key: component
              operator: In
              values:
              - controller
          topologyKey: kubernetes.io/hostname
  tolerations:
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: NoSchedule
      - key: node-role.kubernetes.io/master
        operator: Exists
        effect: PreferNoSchedule
</code></pre></td></tr></table>
</div>
</div><p>nginx ingress controller的副本数<code>replicaCount</code>为1，将被调度到node1这个边缘节点上。这里并没有指定nginx ingress controller service的<code>externalIPs</code>，而是通过<code>hostNetwork: true</code>设置nginx ingress controller使用宿主机网络。 因为k8s.gcr.io被墙，这里替换成<code>unreachableg/k8s.gcr.io_ingress-nginx_controller</code>提前拉取一下镜像:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">crictl pull unreachableg/k8s.gcr.io_ingress-nginx_controller:v1.1.0
</code></pre></td></tr></table>
</div>
</div><p>安装 ingress-nginx</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">helm install ingress-nginx ingress-nginx-4.0.13.tgz --create-namespace -n ingress-nginx -f values.yaml
</code></pre></td></tr></table>
</div>
</div><p>通过访问 <code>http://172.16.219.101</code> 测试，返回 404 表示安装成功。</p>
<h3 id="32-部署-metrics-server">3.2 部署 metrics-server</h3>
<p>下载描述文件</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.2/components.yaml
</code></pre></td></tr></table>
</div>
</div><p>修改components.yaml中的image为<code>docker.io/unreachableg/k8s.gcr.io_metrics-server_metrics-server:v0.5.2</code>。</p>
<p>修改components.yaml中容器的启动参数，加入<code>--kubelet-insecure-tls</code>。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl apply -f components.yaml
</code></pre></td></tr></table>
</div>
</div><p>metrics-server的pod正常启动后，等一段时间就可以使用kubectl top查看集群和pod的metrics信息:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl top node --use-protocol-buffers<span class="o">=</span><span class="nb">true</span>
NAME         CPU<span class="o">(</span>cores<span class="o">)</span>   CPU%   MEMORY<span class="o">(</span>bytes<span class="o">)</span>   MEMORY%
k8s-master   287m         14%    1236Mi          71%
k8s-slave1   99m          4%     894Mi           51%
k8s-slave2   100m         5%     876Mi           50%

kubectl top pod -n kube-system --use-protocol-buffers<span class="o">=</span><span class="nb">true</span>
NAME                                    CPU<span class="o">(</span>cores<span class="o">)</span>   MEMORY<span class="o">(</span>bytes<span class="o">)</span>
coredns-6d8c4cb4d-klthf                 3m           17Mi
coredns-6d8c4cb4d-xmgnj                 3m           15Mi
etcd-k8s-master                         53m          60Mi
kube-apiserver-k8s-master               84m          391Mi
kube-controller-manager-k8s-master      31m          72Mi
kube-proxy-6fxdl                        14m          18Mi
kube-proxy-ggf2t                        12m          16Mi
kube-proxy-l5t9b                        13m          22Mi
kube-scheduler-k8s-master               5m           29Mi
kubernetes-dashboard-79f67c7494-pb6rq   1m           38Mi
metrics-server-74689dcfd-c9fqn          5m           33Mi
</code></pre></td></tr></table>
</div>
</div><h3 id="33-部署-dashboard">3.3 部署 dashboard</h3>
<p>使用helm部署k8s的dashboard，添加chart repo:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
helm repo update
</code></pre></td></tr></table>
</div>
</div><p>查看chart的可定制配置:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">helm show values kubernetes-dashboard/kubernetes-dashboard
</code></pre></td></tr></table>
</div>
</div><p>修改 chart 的定制配置</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">image:
  repository: kubernetesui/dashboard
  tag: v2.4.0
ingress:
  enabled: <span class="nb">true</span>
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: <span class="s2">&#34;true&#34;</span>
    nginx.ingress.kubernetes.io/backend-protocol: <span class="s2">&#34;HTTPS&#34;</span>
  hosts:
  - k8s.example.com
  tls:
    - secretName: example-com-tls-secret
      hosts:
      - k8s.example.com
metricsScraper:
  enabled: <span class="nb">true</span>
</code></pre></td></tr></table>
</div>
</div><p>生成个人证书：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">mkdir -p /etc/k8s/ssl/
<span class="nb">cd</span> /etc/k8s/ssl
openssl genrsa -out dashboard.key <span class="m">2048</span>
openssl req -new -x509 -key dashboard.key -out dashboard.crt -subj <span class="s2">&#34;/O=dashboard/CN=k8s.example.com&#34;</span>
</code></pre></td></tr></table>
</div>
</div><p>先创建存放k8s.example.comssl证书的secret:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl create secret tls example-com-tls-secret --cert<span class="o">=</span>/etc/k8s/ssl/dashboard.crt --key<span class="o">=</span>/etc/k8s/ssl/dashboard.key -n kube-system
</code></pre></td></tr></table>
</div>
</div><p>使用helm部署dashboard:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">helm install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard -n kube-system -f dashboard-ingress.yaml
</code></pre></td></tr></table>
</div>
</div><p>确认上面的命令部署成功。</p>
<p>创建管理员sa:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl create serviceaccount kube-dashboard-admin-sa -n kube-system

kubectl create clusterrolebinding kube-dashboard-admin-sa <span class="se">\
</span><span class="se"></span>--clusterrole<span class="o">=</span>cluster-admin --serviceaccount<span class="o">=</span>kube-system:kube-dashboard-admin-sa
</code></pre></td></tr></table>
</div>
</div><p>获取集群管理员登录dashboard所需token:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl describe -n kube-system secret <span class="k">$(</span>kubectl -n kube-system get secret <span class="p">|</span> grep kube-dashboard-admin-sa-token<span class="p">|</span>awk -F <span class="s1">&#39; &#39;</span> <span class="s1">&#39;{print $1}&#39;</span><span class="k">)</span>
Name:         kube-dashboard-admin-sa-token-7r5dh
Namespace:    kube-system
Labels:       &lt;none&gt;
Annotations:  kubernetes.io/service-account.name: kube-dashboard-admin-sa
              kubernetes.io/service-account.uid: 594e7c8a-4a81-43ec-9819-0df5d7813cfd

Type:  kubernetes.io/service-account-token

<span class="nv">Data</span>
<span class="o">====</span>
ca.crt:     <span class="m">1099</span> bytes
namespace:  <span class="m">11</span> bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IjJWLUlNOFBfd2lFUWZzVTZ6UHNMRFludHpkaU5TbFdwME80MmNMbGpVQTgifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlLWRhc2hib2FyZC1hZG1pbi1zYS10b2tlbi03cjVkaCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlLWRhc2hib2FyZC1hZG1pbi1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6IjU5NGU3YzhhLTRhODEtNDNlYy05ODE5LTBkZjVkNzgxM2NmZCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlLWRhc2hib2FyZC1hZG1pbi1zYSJ9.P_zB-q-gp38XEkGMbtrdZawRwpL740Z2amVg1mQ5SeHY701cU2wNziIMfi_UyKRP0BZ1O_F8l2g-kEqzot5i9Pjbrw9mkJfx4x3AVXDCWHv6a-TJJSyXCj1Of8dFzksMWrkdXL3UHGAOZZ9DGMcPIeuaN1CQIOJVo9shInBcQt8dHglr8rBtAhnuMnhOJZZc9Pp1gXCktw2iWr1oeEdpZtgLYCH3c4hpMi9oQnkyP70T0m69BJBkbHP0_toMJISZk-NkR3KmhB4Ze959lyCFA09urP6sZKETlcxy1q_nJ1ILmMJWJaTGinY1hlHEGRYwz7Qur5N7oKEeAiJWugam5w
</code></pre></td></tr></table>
</div>
</div><p>由于这里的证书和域名都是自生成的，所以集群外无法解析。在本机的 /etc/hosts 上添加记录</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">172.16.219.101 k8s.example.com
</code></pre></td></tr></table>
</div>
</div><p>同时在集群的 coredns 中添加记录</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash">kubectl describe configmap coredns -n kube-system
Name:         coredns
Namespace:    kube-system
Labels:       &lt;none&gt;
Annotations:  &lt;none&gt;

<span class="nv">Data</span>
<span class="o">====</span>
Corefile:
----
.:53 <span class="o">{</span>
    errors
    health <span class="o">{</span>
       lameduck 5s
    <span class="o">}</span>
    ready
    kubernetes cluster.local in-addr.arpa ip6.arpa <span class="o">{</span>
       pods insecure
       fallthrough in-addr.arpa ip6.arpa
       ttl <span class="m">30</span>
    <span class="o">}</span>
    hosts <span class="o">{</span>
       172.16.219.101 k8s.example.com
       fallthrough
    <span class="o">}</span>
    prometheus :9153
    forward . /etc/resolv.conf <span class="o">{</span>
       max_concurrent <span class="m">1000</span>
    <span class="o">}</span>
    cache <span class="m">30</span>
    loop
    reload
    loadbalance
<span class="o">}</span>


<span class="nv">BinaryData</span>
<span class="o">====</span>
</code></pre></td></tr></table>
</div>
</div><p>使用上面的token登录k8s dashboard。
<img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://raw.githubusercontent.com/xingyys/myblog/main/posts/images/20220113203555.png"
        data-srcset="https://raw.githubusercontent.com/xingyys/myblog/main/posts/images/20220113203555.png, https://raw.githubusercontent.com/xingyys/myblog/main/posts/images/20220113203555.png 1.5x, https://raw.githubusercontent.com/xingyys/myblog/main/posts/images/20220113203555.png 2x"
        data-sizes="auto"
        alt="https://raw.githubusercontent.com/xingyys/myblog/main/posts/images/20220113203555.png"
        title="https://raw.githubusercontent.com/xingyys/myblog/main/posts/images/20220113203555.png" /></p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>更新于 2022-01-13</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/%E5%AE%89%E8%A3%85kubernetes1.23/index.md" target="_blank">阅读原始文档</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/k8s/">k8s</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">返回</a></span>&nbsp;|&nbsp;<span><a href="/">主页</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/containerd%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/" class="prev" rel="prev" title="Containerd源码分析"><i class="fas fa-angle-left fa-fw"></i>Containerd源码分析</a>
            <a href="/clion%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95c%E4%BB%A3%E7%A0%81/" class="next" rel="next" title="Clion远程调试c代码">Clion远程调试c代码<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
<div id="comments"><div id="gitalk" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://github.com/gitalk/gitalk"></a>Gitalk</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">由 <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.87.0">Hugo</a> 强力驱动 | 主题 - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2019 - 2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/lack-io" target="_blank">Lack</a></span>&nbsp;|&nbsp;<span class="license"><a rel="license external nofollow noopener noreffer" href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank">CC BY-NC 4.0</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="回到顶部">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="查看评论">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/gitalk/gitalk.min.css"><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="/lib/gitalk/gitalk.min.js"></script><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/algoliasearch/algoliasearch-lite.umd.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"复制到剪贴板","maxShownLines":10},"comment":{"gitalk":{"admin":["lack-io"],"clientID":"e0b00024a2e428bbbcba","clientSecret":"3aa82dd31f80aace3a4ee39da331ebc5cab55c79","id":"2022-01-13T18:44:33+08:00","owner":"lack-io","repo":"blog_comment","title":"安装kubernetes1.23"}},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"algoliaAppID":"2F98FFY5I5","algoliaIndex":"zh_cn_index","algoliaSearchKey":"b00eb2b5541b2ebb14e1d581011b4daf","highlightTag":"em","maxResultLength":10,"noResultsFound":"没有找到结果","snippetLength":50,"type":"algolia"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
