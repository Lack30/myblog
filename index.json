[{"categories":null,"content":"暂时为空 ","date":"2017-08-20","objectID":"/about/:0:0","tags":null,"title":"关于","uri":"/about/"},{"categories":["笔记"],"content":"计算机系统漫游 计算机系统是由硬件和软件组成。 ","date":"2021-08-31","objectID":"/csapp/:1:0","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.1 信息就是位 + 上下文 系统中所有的信息——包括磁盘文件、内存中的程序、内存中存放的用户数据以及网络上传送的数据，都是由一串 bit 表示的。区分不同数据对象的唯一方法是我们读到这些数据对象是的上下文。 ","date":"2021-08-31","objectID":"/csapp/:1:1","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.2 程序被其他程序翻译成不同的格式 ","date":"2021-08-31","objectID":"/csapp/:1:2","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.3 了解编译系统如何工作是大有益处的 为什么程序员必须要知道编译系统是如何工作的? 优化程序性能。 理解链接时出现的错误。 避免安全漏洞。 ","date":"2021-08-31","objectID":"/csapp/:1:3","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.4 处理器读并解释储存在内存中指令 系统硬件组成 总线: 贯穿整个系统的一组电子管道，称作总线，他携带信息字节并负责在各个部件间传递。 I/O设备: 系统与外部世界的联系通道。每个 I/O 设备都通过一个控制器或者适配器与 I/O 总线相连。控制器和适配器之间的区别主要在于它们的封装方式。控制器是 I/O 设备本身或者系统的主印制电路板上的芯片组。而适配器则是一块插在主板插槽上的卡。 主存: 主存是一个临时存储设备，在处理执行程序时，用来存放程序和程序处理的数据。从物理上来说，主存是由一组动态随机存储存储器 (DRAM) 芯片组成的。从逻辑上来说，存储器是一个线性的字节数组，每个字节都有其唯一的地址(数组索引)，这些地址是从零开始的。 处理器：中央处理单元 (CPU)，简称处理器，是解释(或)执行存储在主存中指令的引擎、处理器的核心是一个大小与一个字的存储设备(或寄存器)，称为程序计数器(PC)。在任何时刻，PC 都指向主存中的某条机器语言指令。 系统执行一个 Hello World 程序时，硬件运行流程。 键盘输入命令时，shell 程序将字符逐一读入寄存器，再存放到内存中。 键入回车键后，shell 执行一系列指令来加载可执行的 hello 文件，将 hello 目标文件中的代码和数据从磁盘复制到内存。 处理器开始执行 hello 程序 main 程序中的机器语言指令。 这些指令将输出的字符串中的字节从主存复制到寄存器文件，再从寄存器文件中复制到显示设备，最终显示在屏幕上。 ","date":"2021-08-31","objectID":"/csapp/:1:4","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.5 高速缓存至关重要 系统运行时会频繁的挪动信息，而不同存储设备之间的读写性能有严重偏差 (从寄存器中读取数据比从主存中读取快100被，从主存中读取又比磁盘中快 1000 万倍)。所以不同存储设备间需要高速缓存来提供系统运行速度。 这里的高速缓存是相对概念。 ","date":"2021-08-31","objectID":"/csapp/:1:5","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.6 存储设备形成层次结构 ","date":"2021-08-31","objectID":"/csapp/:1:6","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.7 操作系统管理硬件 我们并不直接访问硬件，而是通过操作系统。所有应用程序对硬件的操作尝试都必须通过操作系统。 操作系统有两个基本功能: 防止硬件被失控的应用程序滥用。 向应用程序提供简单一致的机制来控制复杂而又通常不大相同的低级硬件设备。 操作系统通过几个基本抽象概念来实现这两个功能。 进程: 操作系统对一个正在运行的程序的一种抽象。 上下文: 操作系统保持跟踪进程运行所需的所有状态信息，其中包含 PC 和寄存器文件的当前值，以及主存的内存。 在任何一个时刻，单处理器系统都只能执行一个进程的代码。当操作系统决定要把控制权从当前进程转移到某个新进程时，就会进行上下文切换。这一过程有操作系统内核 (kernel) 管理。 线程: 现代操作系统中，一个进程实际上可以由多个称为线程的执行单元组成，每个线程都裕兴在进程的上下文中，并共享同样的代码和全局数据。 虚拟机内存是一个抽象概念，它为每个进程提供一个假象，即每个进程都在独占地使用主存，每个进程看到的内存都是一致的，称为虚拟地址空间。 虚拟地址空间从下至上依次为: 程序代码和数据。对所有的进程来说，代码是从同一固定地址开始，紧接着的是和 C 全局变量相对应的数据位置。代码和数据区是直接按照可执行目标文件的内容初始化的。 堆。堆可以在运行时动态地扩展和收缩。 共享库。存放 C 标准库和数学库这些共享库的代码和数据。 栈。位于用户虚拟地址空间顶部，编译器用它来实现函数调用，它和堆一样在程序运行期间可以动态地扩展和收缩。每次调用一个函数时，栈就会增长，从一个函数返回时，栈就会收缩。 内核虚拟内存。地址空间顶部的区域是为内核保留的。不允许应用程序读写这个区域的内容或者直接调用内核代码定义的函数。相反，他们必须调用内核来执行这些操作。 文件就是字节序列！每个 I/O 设备，包括磁盘、键盘、显示器，甚至网络，都可以看成文件。 ","date":"2021-08-31","objectID":"/csapp/:1:7","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.8 系统之间利用网络通信 硬件和软件组合成一个系统，而通过网络间不同的主机连接成一个更广大的现代系统。 ","date":"2021-08-31","objectID":"/csapp/:1:8","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"1.9 重要主题 并发 (concurrency): 一个同时具有多个活动的系统。 并行 (parallelism): 用并发来是一个系统运行得更快。 超线程：有时称为同时多线程 (simultaneous multi-threading)，是一项允许一个 CPU 执行多个控制流的技术。 抽象的使用是计算机科学中最为重要的概念之一。这里介绍四个抽象: 文件是对 I/O 设备的抽象。 虚拟内存是对程序存储器的抽象。 进程是对一个正在运行的程序的抽象。 虚拟机是对整个计算机的抽象。 ","date":"2021-08-31","objectID":"/csapp/:1:9","tags":["计算机"],"title":"深入理解计算机系统","uri":"/csapp/"},{"categories":["笔记"],"content":"查询所有触发器 select*fromuser_triggers; 根据名称禁用触发器 altertriggerLOGMNRGGC_TRIGGERdisable; 查询所有 job select*fromuser_jobs; 根据 id 禁用 job BEGINdbms_job.broken(4001,true);END; 禁用 oracle dblink altersystemsetopen_links=0sid='$sid'scope=spfile;altersystemsetopen_links_per_instance=0sid='$sid'scope=spfile; 启用 oracle dblink altersystemsetopen_links=4sid='$sid'scope=spfile;altersystemsetopen_links_per_instance=4sid='$sid'scope=spfile; ","date":"2021-08-30","objectID":"/dblink/:0:0","tags":["oracle"],"title":"Dblink","uri":"/dblink/"},{"categories":["虚拟化"],"content":"简介 libguestfs 是一套管理虚拟机镜像的工具。它提供以一系列命令和API来修改和管理虚拟机的镜像。 安装 直接使用 yum 安装 libguestfs : yum install -y libguestfs-tool libguestfs-devel 默认不支持修改 windows 镜像，可以安装 libguestfs-winsupport : yum install -y libguestfs-winsupport libguestfs 命令 libguestfs 的通用参数 -a|–add image : 指定查看的镜像文件路径 -c|–connect uri : 指定远程 libvirt 地址 -d|–domain guest : 指定 libvirt 上的 domain 名称 注: libguestfs 的命令需要调用 libvirt 所以响应的速度会比较慢。同时，如果命令会修改镜像的内容，需要先关闭域，避免造成数据不同步。 ","date":"2021-01-31","objectID":"/libguestfs/:0:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-inspector virt-inspector 命令用来查看镜像信息，输出格式为 xml $ virt-inspector -d centos \u003c?xml version=\"1.0\"?\u003e \u003coperatingsystems\u003e \u003coperatingsystem\u003e \u003croot\u003e/dev/centos/root\u003c/root\u003e \u003cname\u003elinux\u003c/name\u003e \u003carch\u003ex86_64\u003c/arch\u003e \u003cdistro\u003ecentos\u003c/distro\u003e \u003cproduct_name\u003eCentOS Linux release 7.6.1810 (Core) \u003c/product_name\u003e \u003cmajor_version\u003e7\u003c/major_version\u003e \u003cminor_version\u003e6\u003c/minor_version\u003e \u003cpackage_format\u003erpm\u003c/package_format\u003e \u003cpackage_management\u003eyum\u003c/package_management\u003e \u003chostname\u003elocalhost.localdomain\u003c/hostname\u003e \u003cosinfo\u003ecentos7.0\u003c/osinfo\u003e \u003cmountpoints\u003e \u003cmountpoint dev=\"/dev/centos/root\"\u003e/\u003c/mountpoint\u003e \u003cmountpoint dev=\"/dev/sda1\"\u003e/boot\u003c/mountpoint\u003e \u003c/mountpoints\u003e \u003cfilesystems\u003e \u003cfilesystem dev=\"/dev/centos/root\"\u003e \u003ctype\u003exfs\u003c/type\u003e \u003cuuid\u003e12e94e0d-93e6-4714-9c61-116fbe994936\u003c/uuid\u003e \u003c/filesystem\u003e ... ... \u003cxml\u003e ","date":"2021-01-31","objectID":"/libguestfs/:1:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-watch virt-watch 查看本机虚拟化环境 $ virt-what vmware ","date":"2021-01-31","objectID":"/libguestfs/:2:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-host-validator virt-host-validator 检查本地环境是否符合虚拟化 $ virt-host-validate QEMU: 正在检查 for hardware virtualization : PASS QEMU: 正在检查 if device /dev/kvm exists : PASS QEMU: 正在检查 if device /dev/kvm is accessible : PASS QEMU: 正在检查 if device /dev/vhost-net exists : PASS ... ... ","date":"2021-01-31","objectID":"/libguestfs/:3:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-get-kernel virt-get-kernel 获取镜像的内核文件 $ virt-get-kernel -d centos download: /boot/vmlinuz-3.10.0-957.el7.x86_64 -\u003e ./vmlinuz-3.10.0-957.el7.x86_64 download: /boot/initramfs-3.10.0-957.el7.x86_64.img -\u003e ./initramfs-3.10.0-957.el7.x86_64.img ","date":"2021-01-31","objectID":"/libguestfs/:4:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-filesystems virt-filesystems 查看镜像的文件系统 $ virt-filesystems -d centos /dev/sda1 /dev/centos/root ","date":"2021-01-31","objectID":"/libguestfs/:5:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-df virt-df 用来查看镜像的文件系统容量，同 df 命令 $ virt-df -d centos -h 文件系统 大小 已用空间 可用空间 使用百分比% centos:/dev/sda1 1014M 100M 914M 10% centos:/dev/centos/root 17G 974M 16G 6% ","date":"2021-01-31","objectID":"/libguestfs/:6:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-ls virt-ls 查看镜像的文件信息，同 ls 命令 $ virt-ls -d centos /root/ -l total 28 dr-xr-x---. 2 root root 135 Jan 26 15:07 . dr-xr-xr-x. 17 root root 224 Jan 16 09:56 .. -rw-------. 1 root root 45 Jan 26 15:07 .bash_history -rw-r--r--. 1 root root 18 Dec 29 2013 .bash_logout -rw-r--r--. 1 root root 176 Dec 29 2013 .bash_profile -rw-r--r--. 1 root root 176 Dec 29 2013 .bashrc -rw-r--r--. 1 root root 100 Dec 29 2013 .cshrc -rw-r--r--. 1 root root 129 Dec 29 2013 .tcshrc -rw-------. 1 root root 1259 Jan 16 09:57 anaconda-ks.cfg ","date":"2021-01-31","objectID":"/libguestfs/:7:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-cat virt-cat 查看镜像内的文件内容，同 cat 命令 $ virt-cat -d centos /etc/passwd root:xx:0:0:root:/root:/bin/bash ... ... ","date":"2021-01-31","objectID":"/libguestfs/:8:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-log virt-log 查看镜像的日志信息 $ virt-log -d centos Jan 30 20:13:01 localhost rsyslogd: [origin software=\"rsyslogd\" swVersion=\"8.24.0-34.el7\" x-pid=\"3123\" x-info=\"http://www.rsyslog.com\"] rsyslogd was HUPed Jan 30 20:33:37 localhost qemu-ga: info: guest-shutdown called, mode: powerdown Jan 30 20:33:37 localhost systemd: Started Delayed Shutdown Service. ","date":"2021-01-31","objectID":"/libguestfs/:9:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-tail virt-tail 监听文件内容，同 tail 命令 $ virt-tail -d centos /var/log/messages --- /var/log/messages --- ... ","date":"2021-01-31","objectID":"/libguestfs/:10:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-alignment-scan virt-alignment-scan 查看镜像分区是否对齐 $ virt-alignment-scan -a centos.qcow2 /dev/sda1 1048576 1024K ok /dev/sda2 1074790400 1024K ok ","date":"2021-01-31","objectID":"/libguestfs/:11:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-diff virt-diff 比较镜像间的不同 $ # virt-diff -a centos.qcow2 -A centos.img - d 0550 150 /root + d 0550 135 /root # changed: st_size - - 0644 4 /root/kvm.txt - d 1777 187 /tmp + d 1777 172 /tmp # changed: st_size - - 0644 4 /tmp/kvm.txt ","date":"2021-01-31","objectID":"/libguestfs/:12:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-sparisify virt-sparisify 用来消除镜像内的空洞文件，减少镜像大小 $ virt-sparsify centos.qcow2 -f qcow2 centos2.qcow2 [ 0.0] Create overlay file in /tmp to protect source disk [ 0.0] Examine source disk [ 3.4] Fill free space in /dev/centos/root with zero 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 33.5] Clearing Linux swap on /dev/centos/swap 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ --:-- [ 36.2] Fill free space in /dev/sda1 with zero [ 38.5] Copy to destination and make sparse [ 51.4] Sparsify operation completed with no errors. virt-sparsify: Before deleting the old disk, carefully check that the target disk boots and works correctly. 执行完成后生成 centos2.qcow2 文件: $ ll -h 总用量 4.0G -rw-r--r-- 1 root root 1.1G 1月 30 23:39 centos2.qcow2 -rw-r--r-- 1 root root 1.5G 1月 30 20:33 centos.img -rw-r--r-- 1 root root 1.5G 1月 30 20:43 centos.qcow2 ","date":"2021-01-31","objectID":"/libguestfs/:13:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-copy-in virt-copy-in 将本地文件复制到镜像中 $ virt-copy-in -a centos.qcow2 kvm.txt /tmp/ $ virt-ls -a centos.qcow2 /tmp/ kvm.txt ","date":"2021-01-31","objectID":"/libguestfs/:14:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-copy-out virt-copy-out 将镜像中的文件复制到本地 $ virt-copy-out -a centos.qcow2 /tmp/kvm.txt . ","date":"2021-01-31","objectID":"/libguestfs/:15:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-edit virt-edit 编译镜像内的文件，默认会打开本地的 Vim 进行编辑 $ virt-edit -a centos.qcow2 /tmp/kvm.txt $ virt-cat -a centos.qcow2 /tmp/kvm.txt kvm kvm11 ","date":"2021-01-31","objectID":"/libguestfs/:16:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-make-fs virt-make-fs 根据本地的目录创建一个镜像 $ mkdir /input $ echo \"input\" \u003e /input/1.txt $ virt-make-fs --partition=gpt --type=ntfs --size=1G --format=qcow2 /input sdb.qcow2 ","date":"2021-01-31","objectID":"/libguestfs/:17:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-tar-in virt-tar-in tar 压缩文件拷贝进虚拟机并解压 $ virt-tar-in -a centos.qcow2 kvm.tar /root/ ","date":"2021-01-31","objectID":"/libguestfs/:18:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-tar-out virt-tar-out 镜像内指定目录文件拷贝并压缩 $ virt-tar-out -a centos.qcow2 /root root.tar ","date":"2021-01-31","objectID":"/libguestfs/:19:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"guestmount guestmount 将镜像中的文件系统分区挂载到本地目录 $ guestmount -a centos.qcow2 -m /dev/sda1 /mnt ","date":"2021-01-31","objectID":"/libguestfs/:20:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"guestumount guestumount 卸载 guestmount 挂载的目录 $ guestumount /mnt ","date":"2021-01-31","objectID":"/libguestfs/:21:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-rescue virt-rescue 进入救援模式，修复镜像 $ virt-rescue -a centos.qcow2 ","date":"2021-01-31","objectID":"/libguestfs/:22:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"virt-resize virt-resize 镜像分区缩容和扩容 给其中某个分区扩容 5G $ virt-filesystems --long -h --all -a olddisk $ truncate -r olddisk newdisk $ truncate -s +5G newdisk $ virt-resize --expand /dev/sda2 olddisk newdisk /boot 分区扩容 200MB bigger, 剩下的分配给 /dev/sda2: $ virt-resize --resize /dev/sda1=+200M --expand /dev/sda2 olddisk newdisk lvm 分区扩容 $ virt-resize --expand /dev/sda2 --LV-expand /dev/vg_guest/lv_root olddisk newdisk ","date":"2021-01-31","objectID":"/libguestfs/:23:0","tags":["kvm","linux"],"title":"KVM镜像管理工具libguestfs","uri":"/libguestfs/"},{"categories":["虚拟化"],"content":"qemu-img 是 QEMU 的磁盘管理工具，它允许用户创建、转化、修改 QEMU 磁盘。 注：qemu-img 操作磁盘时需要关闭 kvm 虚拟机，直接在虚拟机运行时修改磁盘可能会导致数据不一致甚至导致磁盘损坏。 qemu-img 基本命令 ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:0:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"check 语法: check [-f fmt] filename 对磁盘镜像文件进行一致性检查，查找镜像文件中的错误，目前仅支持对“qcow2”、“qed”、“vdi”格式文件的检查。其中，qcow2 是 QEMU 0.8.3版本引入的镜像文件格式，也是目前使用最广泛的格式。qed（QEMU enhanced disk）是从 QEMU 0.14 版开始加入的增强磁盘文件格式，为了避免 qcow2 格式的一些缺点，也为了提高性能，不过目前还不够成熟。而 vdi（Virtual Disk Image）是 Oracle 的 VirtualBox 虚拟机中的存储格式。参数-f fmt 是指定文件的格式，如果不指定格式 qemu-img 会自动检测，filename 是磁盘镜像文件的名称（包括路径）。 # qemu-img check -f qcow2 sdb.qcow2 No errors were found on the image. Image end offset: 524288 ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:1:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"create 语法: create [-f fmt] [-o options] filename [size] 创建一个格式为 fmt，大小为 size，文件名为filename 的镜像文件。根据文件格式 fmt 的不同，还可以添加一个或多个选项（options）来附加对该文件的各种功能设置，可以使用“-o ?”来查询某种格式文件支持那些选项，在“-o”选项中各个选项用逗号来分隔。 如果 “-o” 选项中使用了 backing_file 这个选项来指定其后端镜像文件，那么这个创建的镜像文件仅记录与后端镜像文件的差异部分。后端镜像文件不会被修改，除非在 QEMU monitor 中使用\"commit\" 命令或者使用 “qemu-img commit” 命令去手动提交这些改动。这种情况下，size 参数不是必须需的，其值默认为后端镜像文件的大小。另外，直接使用 “-b backfile” 参数也与 “-o backing_file=backfile” 效果相同。 size 选项用于指定镜像文件的大小，其默认单位是字节（bytes），也可以支持k（或K）、M、G、T来分别表示KB、MB、GB、TB大小。另外，镜像文件的大小（size）也并非必须写在命令的最后，它也可以被写在 “-o” 选项中作为其中一个选项。 # qemu-img create -f qcow2 -o backing_file=sdb.qcow2 sdc.qcow2 10G qemu-img: warning: Deprecated use of backing file without explicit backing format (detected format of qcow2) Formatting 'sdc.qcow2', fmt=qcow2 cluster_size=65536 extended_l2=off compression_type=zlib size=10737418240 backing_file=sdb.qcow2 backing_fmt=qcow2 lazy_refcounts=off refcount_bits=16 # qemu-img create -f raw sdd.raw 10G Formatting 'sdd.raw', fmt=raw size=10737418240 ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:2:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"commit 语法: [-f fmt] [-t cache] filename 提交 filename 文件中的更改到后端支持镜像文件（创建时通过 backing_file 指定的）中去。 # qemu-img commit sdc.qcow2 Image committed. ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:3:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"convert 语法: convert [-c] [-p] [-f fmt] [-t cache] [-O output_fmt] [-o options] [-s snapshot_name] [-S sparse_size] filename [filename2 [...]] output_filename 将fmt格式的 filename 镜像文件根据 options 选项转换为格式为 output_fmt 的名为 output_filename 的镜像文件。它支持不同格式的镜像文件之间的转换，比如可以用 VMware 用的vmdk 格式文件转换为 qcow2 文件，这对从其他虚拟化方案转移到 KVM上 的用户非常有用。一般来说，输入文件格式 fmt 由 qemu-img 工具自动检测到，而输出文件格式 output_fmt 根据自己需要来指定，默认会被转换为与 raw 文件格式（且默认使用稀疏文件的方式存储以节省存储空间）。 其中，\"-c\" 参数是对输出的镜像文件进行压缩，不过只有 qcow2 和 qcow 格式的镜像文件才支持压缩，而且这种压缩是只读的，如果压缩的扇区被重写，则会被重写为未压缩的数据。同样可以使用 “-o options” 来指定各种选项，如：后端镜像、文件大小、是否加密等等。使用 backing_file 选项来指定后端镜像，让生成的文件是 copy-on-write的增量文件，这时必须让转换命令中指定的后端镜像与输入文件的后端镜像的内容是相同的，尽管它们各自后端镜像的目录、格式可能不同。 如果使用 qcow2、qcow、cow 等作为输出文件格式来转换raw格式的镜像文件（非稀疏文件格式），镜像转换还可以起到将镜像文件转化为更小的镜像，因为它可以将空的扇区删除使之在生成的输出文件中并不存在。 # qemu-img convert -p -f qcow2 -O raw sdc.qcow2 sdc.raw (100.00/100%) # qemu-img convert -c -p -f raw -O qcow2 sdc.raw sdcc.qcow2 (100.00/100%) ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:4:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"info 语法: [-f fmt] filename 展示 filename 镜像文件的信息。如果文件是使用稀疏文件的存储方式，也会显示出它的本来分配的大小以及实际已占用的磁盘空间大小。如果文件中存放有客户机快照，快照的信息也会被显示出来。 # qemu-img info sdc.qcow2 image: sdc.qcow2 file format: qcow2 virtual size: 10 GiB (10737418240 bytes) disk size: 256 KiB cluster_size: 65536 backing file: sdb.qcow2 backing file format: qcow2 Format specific information: compat: 1.1 compression type: zlib lazy refcounts: false refcount bits: 16 corrupt: false extended l2: false ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:5:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"snapshot 语法: snapshot [-l | -a snapshot | -c snapshot | -d snapshot] filename “-l” 选项是查询并列出镜像文件中的所有快照 “-a snapshot” 是让镜像文件使用某个快照 “-c snapshot” 是创建一个快照 “-d” 是删除一个快照。 # qemu-img snapshot -l sdb.qcow2 Snapshot list: ID TAG VM SIZE DATE VM CLOCK ICOUNT 1 sdb-ss1 0 B 2021-01-17 09:14:46 00:00:00.000 0 # qemu-img snapshot -c sdb-ss2 sdb.qcow2 # qemu-img snapshot -l sdb.qcow2 Snapshot list: ID TAG VM SIZE DATE VM CLOCK ICOUNT 1 sdb-ss1 0 B 2021-01-17 09:14:46 00:00:00.000 0 2 sdb-ss2 0 B 2021-01-17 09:15:11 00:00:00.000 0 # qemu-img snapshot -c sdb-ss3 sdb.qcow2 # qemu-img snapshot -l sdb.qcow2 Snapshot list: ID TAG VM SIZE DATE VM CLOCK ICOUNT 1 sdb-ss1 0 B 2021-01-17 09:14:46 00:00:00.000 0 2 sdb-ss2 0 B 2021-01-17 09:15:11 00:00:00.000 0 3 sdb-ss3 0 B 2021-01-17 09:15:21 00:00:00.000 0 # qemu-img snapshot -d sdb-ss2 sdb.qcow2 # qemu-img snapshot -l sdb.qcow2 Snapshot list: ID TAG VM SIZE DATE VM CLOCK ICOUNT 1 sdb-ss1 0 B 2021-01-17 09:14:46 00:00:00.000 0 3 sdb-ss3 0 B 2021-01-17 09:15:21 00:00:00.000 0 ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:6:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"rebase 语法: rebase [-f fmt] [-t cache] [-p] [-u] -b backing_file [-F backing_fmt] filename 改变镜像文件的后端镜像文件，只有 qcow2 和 qed 格式支持rebase命令。使用 “-b backing_file” 中指定的文件作为后端镜像，后端镜像也被转化为 “-F backing_fmt” 中指定的后端镜像格式。 它可以工作于两种模式之下，一种是安全模式（Safe Mode）也是默认的模式，qemu-img会去比较原来的后端镜像与现在的后端镜像的不同进行合理的处理；另一种是非安全模式（Unsafe Mode），是通过 “-u” 参数来指定的，这种模式主要用于将后端镜像进行了重命名或者移动了位置之后对前端镜像文件的修复处理，由用户去保证后端镜像的一致性。 # qemu-img rebase -f qcow2 -p -b sdc.qcow2 sdd.qcow2 qemu-img: warning: Deprecated use of backing file without explicit backing format, use of this image requires potentially unsafe format probing (100.00/100%) ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:7:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"resize 语法: resize filename [+ | -]size 改变镜像文件的大小，使其不同于创建之时的大小。\"+\" 和 “-” 分别表示增加和减少镜像文件的大小，而 size 也是支持 K、M、G、T 等单位的使用。缩小镜像的大小之前，需要在客户机中保证里面的文件系统有空余空间，否则会数据丢失，另外，qcow2 格式文件不支持缩小镜像的操作。在增加了镜像文件大小后，也需启动客户机到里面去应用 “fdisk”、“parted” 等分区工具进行相应的操作才能真正让客户机使用到增加后的镜像空间。不过使用 resize 命令时需要小心（最好做好备份），如果失败的话，可能会导致镜像文件无法正常使用而造成数据丢失。 # qemu-img resize sdd.qcow2 +2G Image resized. qemu-img 支​持​格​式​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:8:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"raw Raw 磁​盘​映​像​格​式​（默​认​）。​这​个​格​式​的​优​点​是​可​以​简​单​、​容​易​地​导​出​到​其​它​模​拟​器​中​。​如​果​您​的​文​件​系​统​支​持​中​断​（例​如​在​ Linux 中​的​ ext2 或​者​ ext3 以​及​ Windows 中​的​ NTFS），那​么​只​有​写​入​的​字​段​会​占​用​空​间​。​使​用​ qemu-img info 了​解​ Unix/Linux 中​映​像​或​者​ ls -ls 使​用​的​实​际​大​小​。​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:9:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"qcow2 QEMU 映​像​格​式​，最​万​能​的​格​式​。​使​用​它​可​获​得​较​小​映​像​（如​果​您​的​系​统​不​支​持​中​断​，例​如​在​ Windows 中​，它​会​很​有​用​）、​额​外​的​ AES 加​密​法​、​zlib 压​缩​以​及​对​多​ VM 快​照​的​支​持​。​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:10:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"qcow 旧​的​ QEMU 映​像​格​式​。​只​用​于​与​旧​版​本​兼​容​。​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:11:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"cow 写​入​映​像​格​式​的​用​户​模​式​ Linux 副​本​。​包​含​ cow 格​式​的​目​的​只​是​为​了​与​前​面​的​版​本​兼​容​。​它​无​法​在​ Windows 中​使​用​。​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:12:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"vmdk VMware 3 和​ 4 兼​容​映​像​格​式​。​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:13:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["虚拟化"],"content":"cloop Linux 压​缩​回​送​映​像​，只​有​在​重​复​使​用​直​接​压​缩​的​ CD-ROM 映​像​时​有​用​，比​如​在​ Knoppix CD-ROM 中​。​ ","date":"2021-01-17","objectID":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/:14:0","tags":["kvm","linux"],"title":"qemu-img命令使用","uri":"/qemu-img%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/"},{"categories":["分布式"],"content":"本篇提供一个实现分布式工作流的思路。 系统组成部分： api (网关接口) : 为用户提供工作流的api接口 discovery (服务发现) : 用于服务的注册和发现 scheduler (调度中心) : 整体工作流的调度 broker (消息队列) : 订阅发布和数据传输 node (工作节点) : 每个工作单元的提供者和执行者 实现思路： node 启动时上传每个工作单元的基本信息: 包含工作单元输入输出、名称及其他内容 scheduler 保存这些信息并提供显示 scheduler 接收来自前端的数据并转化成工作流的信息，并执行 实现细节： scheduler 动态生成工作流信息，在 broker 中启动 topic 一个订阅者接收工作流的动态信息 scheduler 根据工作单元信息寻找 node 并传输信息 node 执行对应的工作单元发布信息到 broker 中工作流 topic scheduler 接收 topic 中的信息，如果中间发生错误，执行回滚操作 node 需要的输入参数保存在 context.Context 中，返回参数则 publish 到 topic 中 // 工作单元的接口 type WorkUnit interface { Do(ctx) error Undo(ctx) error String() string } type workflow struct{ units []WorkUnit } func Builder(ctx context.Context) *workflow { return \u0026workflow{} } func (w *workflow) Execute(ctx context.Context) error { undos := make([]func(ctx context.Context) error, 0) var err error defer func() { // 发生错误则逐个回滚 if err != nil { for _, undo := range undos { undo() } } } for _, unit := range w.units { err = unit.Do() if err != nil { // 中间某步错误就结束 return } // 回滚操作入栈 undos = append(undos, unit.Undo) } } ","date":"2021-01-10","objectID":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%AE%9E%E7%8E%B0/:0:0","tags":["golang","想法"],"title":"分布式的工作流实现","uri":"/%E5%88%86%E5%B8%83%E5%BC%8F%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%AE%9E%E7%8E%B0/"},{"categories":["开发"],"content":"链接 libpcap ","date":"2021-01-09","objectID":"/golang%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E6%B5%81%E9%87%8F/:0:0","tags":["golang"],"title":"Golang监控进程流量","uri":"/golang%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%E6%B5%81%E9%87%8F/"},{"categories":["虚拟化"],"content":" 本篇文章介绍 KVM 虚拟机的管理，包括虚拟机的创建、修改、启动、删除等内容 安装虚拟机 ","date":"2021-01-06","objectID":"/kvm_vm/:0:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"使用 virt-install 安装 virt-install 是一个命令行工具，专门用于安装 kvm 虚拟机。执行以下命令： virt-install \\ --name centos \\ --ram 1024 \\ --disk path=/data/kvm/centos.img,size=20 \\ --vcpus 1 \\ --os-type linux --os-variant rhel7 \\ --network bridge=br0 \\ --graphics vnc,listen=0.0.0.0,port=5999 --noautoconsole \\ --console pty,target_type=serial \\ --cdrom CentOS-7-x86_64-DVD-1810.iso 进入安装流程： # virsh list --all Id 名称 状态 ---------------------------------------------------- 2 centos running 可以使用 vnc 客户端连接虚拟机。 参数说明： -–name 指定虚拟机的名字 –-ram 指定内存分配多少 –-disk path 指定虚拟磁盘放到哪里，size=30 指定磁盘大小为30G,这样磁盘文件格式为raw，raw格式不能做快照，后面有说明，需要转换为qcow2格式，如果要使用qcow2格式的虚拟磁盘，需要事先创建qcow2格式的虚拟磁盘。 参考 http://www.361way.com/kvm-qcow2-preallocation-metadata/3354.html 示例:qemu-img create -f qcow2 -o preallocation=metadata /data/test02.img 7G; –disk path=/data/test02.img,format=qcow2,size=7,bus=virtio –-vcpus 指定分配cpu几个 -–os-type 指定系统类型为linux –-os-variant 指定系统版本 -–network 指定网络类型 -–graphics 指定安装通过哪种类型，可以是vnc，也可以没有图形，在这里我们没有使用图形直接使用文本方式 -–console 指定控制台类型 -–location 指定安装介质地址，可以是网络地址，也可以是本地的一个绝对路径，（–location ‘/mnt/’, 其中/mnt/下就是我们挂载的光盘镜像mount /dev/cdrom /mnt)如果是绝对路径，那么后面还需要指定一个安装介质，比如NFS –extra-args 额外参数，需要和 –location 配置使用 –cdrom 指定操作系统镜像位置 ","date":"2021-01-06","objectID":"/kvm_vm/:1:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"错误处理 安装过程中出现三个错误: ","date":"2021-01-06","objectID":"/kvm_vm/:2:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"错误一 第一个错误如下: CPU mode 'custom' for x86_64 kvm domain on x86_64 host is not supported by hypervisor 解决方式是重启宿主机 ","date":"2021-01-06","objectID":"/kvm_vm/:2:1","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"错误二 第二个错误如下： Creating storage file centos.img | 20 GB 00:00 ERROR internal error Process exited while reading console log output: char device redirected to /dev/pts/4 2016-01-27T08:56:58.986952Z ...: Permission denied Domain installation does not appear to have been successful. If it was, you can restart your domain by running: virsh --connect qemu:///system start centos65 otherwise, please restart your installation. 解决方式修改 /etc/libvirt/qemu.conf 配置文件，添加 user 和 group 配置： # /etc/libvirt/qemu.conf # ... user = \"root\" # ... group = \"root\" 重启服务: systemctl restart libvirtd ","date":"2021-01-06","objectID":"/kvm_vm/:2:2","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"错误三 第三个错误是执行命令 virsh console centos 时卡住: # virsh console centos 连接到域 centos 换码符为 ^] 解决方式如下： 确认 ttyS0 存在在 /etc/securetty 文件中，没有就执行以下命令: echo \"ttyS0\" \u003e\u003e /etc/securetty 修改 /etc/default/grub 文件： # GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=cl/root rd.lvm.lv=cl/swap rhgb quiet” # 改成 GRUB_CMDLINE_LINUX=\"crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet net.ifnames=0 console=ttyS0,115200\" 重新生成 grub 文件： grub2-mkconfig -o /boot/grub2/grub.cfg 启动 serial-getty 服务: systemctl start serial-getty@ttyS0.service systemctl enable serial-getty@ttyS0.service 操作虚拟机 KVM 在 Hypervisor 中被称作域(domain)。使用 virsh 命令可以很有效的管理域。 virsh 中管理域的命令: 命令 功能描述 list 获取当前节点上的所有域的列表 domstate \u003cID or Name or UUID\u003e 获取一个域的运行状态 dominfo \u003cID\u003e 获取一个域的基本信息 domid \u003cName or UUID\u003e 根据域的名称或UUID返回域的ID domname \u003cID or UUID\u003e 根据域的ID或UUID返回域的名称 dommemstat \u003cID\u003e 获取一个域的内存使用情况的统计信息 setmem \u003cID\u003e \u003cmem-size\u003e 设置一个域的内存大小(默认单位为KB) vcpupin \u003cID\u003e \u003cvCPU\u003e \u003cpCPU\u003e 将一个域的 vCPU 绑定到某个物理 CPU 上运行 setvcpus \u003cID\u003e \u003cvCPU-num\u003e 设置一个域的 vCPU 的个数 vncdisplay \u003cID\u003e 获取一个域的 VNC 连接 IP 地址的端口 create \u003cdom.xml\u003e 根据域的 XML 配置文件创建一个域(客户机) suspend \u003cID\u003e 暂停一个域 resume \u003cID\u003e 唤醒一个域 shutdown \u003cID\u003e 让一个域执行关机操作 reboot \u003cID\u003e 让一个域执行重启操作 reset \u003cID\u003e 强制重启一个域，相当于在物理机上按带电源 “reset” 按钮 (可能会破坏该域的文件系统) destroy \u003cID\u003e 立即销毁一个域，相当于直接拔掉物理机机器的电源线（可能会破坏该域的文件系统） save \u003cID\u003e \u003cfile.img\u003e 保存一个运行中的域的状态到一个文件中 restore \u003cfile.img\u003e 从一个被保存的文件中恢复一个域的运行 migrate \u003cID\u003e \u003cdest_url\u003e 将一个域迁移到另外一个目的地址 dumpxml \u003cID\u003e 以 XML 格式转存出一个域的信息到标准输出中 attach-device \u003cID\u003e \u003cdevice.xml\u003e 向一个域添加 XML 文件中的设备(热插拔) detach-device \u003cID\u003e \u003cdevice.xml\u003e 将 XML 文件中的设备从一个域中移除 console \u003cID\u003e 连接到一个域的控制台 ","date":"2021-01-06","objectID":"/kvm_vm/:2:3","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"虚拟机生命周期 # 启动虚拟机 virsh start centos # 关闭虚拟机 virsh shutdown centos # 重启虚拟机 virsh reboot centos # 销毁虚拟机 virsh destroy centos # 暂停虚拟机 virsh suspend centos # 恢复虚拟机 virsh resume centos # 删除虚拟机 virsh undefine centos rm -fr /etc/libvirt/qemu/centos.xml ","date":"2021-01-06","objectID":"/kvm_vm/:3:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"限制和修改虚拟机 cpu 先关闭虚拟机，修改虚拟机 xml 文件: # 设置 cpu 最大个数为 4 个，当前为 1 \u003cvcpu placement='static' current='1'\u003e4\u003c/vcpu\u003e 开启虚拟机后，动态设置虚拟机 cpu # 最大个数不能超过指定值 virsh setvcpus centos 2 ","date":"2021-01-06","objectID":"/kvm_vm/:4:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"限制和修改虚拟机内存 修改虚拟机内存最大值需要先关闭虚拟机 # 最大值不能超过宿主机内存最大值 virsh setmaxmem centos 4G 动态设置虚拟机内存 virsh setmem centos 2G ","date":"2021-01-06","objectID":"/kvm_vm/:5:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"在线添加和删除虚拟机硬盘 先创建硬盘: # qemu-img create -f qcow2 disk1.qcow2 2G Formatting 'disk1.qcow2', fmt=qcow2 cluster_size=65536 extended_l2=off compression_type=zlib size=2147483648 lazy_refcounts=off refcount_bits=16 创建 disk.xml 文件 $ vim disk.xml \u003cdisk type='file' device='disk'\u003e \u003cdriver name='qemu' type='qcow2'/\u003e \u003csource file='/data/kvm/disk1.qcow2'/\u003e \u003ctarget dev='vdb' bus='virtio'/\u003e \u003caddress type='pci' domain='0x0000' bus='0x00' slot='0x08' function='0x0'/\u003e \u003c/disk\u003e 添加硬盘设备: virsh attach-device centos disk.xml 卸载硬盘设备 virsh dettach-device centos disk.xml ","date":"2021-01-06","objectID":"/kvm_vm/:6:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"在线添加和删除虚拟机网卡 添加 bridge 网卡 virsh attach-interface centos --type bridge --source br0 卸载网卡 virsh detach-interface centos --type bridge --mac 52:54:00:d9:90:bb ","date":"2021-01-06","objectID":"/kvm_vm/:7:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"修改虚拟机 vnc 先关闭虚拟机 virsh stop centos 修改虚拟机文件 # irsh edit centos \u003cgraphics type='vnc' port='6000' autoport='no' listen='0.0.0.0' passwd='123456'\u003e \u003clisten type='address' address='0.0.0.0'/\u003e \u003c/graphics\u003e 注: 虚拟机 vnc 的端口必须在 5900 - 65535 之间 加载配置文件 virsh define /etc/libvirt/qemu/centos.xml 最后启动虚拟机 virsh start centos ","date":"2021-01-06","objectID":"/kvm_vm/:8:0","tags":["kvm","linux"],"title":"KVM之虚拟机管理","uri":"/kvm_vm/"},{"categories":["虚拟化"],"content":"KVM 概述 KVM (Kernal-base Virtual Machine) 基于内核的虚拟机。是一种通过修改 linux 内核实现虚拟化功能的半虚拟化技术。由于是在内核基础上运行，所有具有接近物理机的高性能。 KVM 和 Qemu Qemu（quick emulator）开源的软件虚拟化实现，通过软件来模拟硬件的功能，但缺点是性能低。通过和 KVM 相结合来提高性能。现在的版本已经内置 KVM。 全虚拟化和半虚拟化 全虚拟化是指不需要修改操作系统内核实现虚拟化功能，半虚拟化则需要修改内核来实现虚拟化。 KVM 就是一种半虚拟化实现。 全虚拟化又分为软件全虚拟化 (Qemu) 和硬件全虚拟化(Xen)。 KVM 工具集合 libvirt：操作和管理KVM虚机的虚拟化 API，使用 C 语言编写，可以由 Python,Ruby, Perl, PHP, Java 等语言调用。可以操作包括 KVM，vmware，XEN，Hyper-v, LXC 等在内的多种 Hypervisor。 Virsh：基于 libvirt 的 命令行工具 （CLI） Virt-Manager：基于 libvirt 的 GUI 工具 virt-v2v：虚机格式迁移工具 virt-* 工具：包括 Virt-install （创建KVM虚机的命令行工具）， Virt-viewer （连接到虚机屏幕的工具），Virt-clone（虚机克隆工具），virt-top 等 sVirt：安全工具 KVM 文章 KVM介绍 KVM源码分析 ","date":"2021-01-04","objectID":"/kvm_detail/:0:0","tags":["kvm","linux"],"title":"KVM介绍","uri":"/kvm_detail/"},{"categories":["虚拟化"],"content":"本文介绍在 CentOS7.9 上编译安装 qemu-5.2.0 安装 Python3 编译安装 qemu-5.2.0 依赖 Python3.6 及以上的版本。所以首先安装 Python3.6。这里选择编译安装。 ","date":"2020-12-27","objectID":"/centos7_install_qemu/:0:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"下载 Python3.6.12 从 Python 官网下载 Python3.6.12 源码包： wget https://www.python.org/ftp/python/3.6.12/Python-3.6.12.tar.xz ","date":"2020-12-27","objectID":"/centos7_install_qemu/:1:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"解压 tar -xvf Python-3.6.12.tar.gz ","date":"2020-12-27","objectID":"/centos7_install_qemu/:2:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"安装 openssl pip 下载是需要 ssl 支持，所以下载 openssl yum install -y openssl openssl-devel zlib-devel bzip2-devel bzip2 ","date":"2020-12-27","objectID":"/centos7_install_qemu/:3:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"编译安装 cd Python-3.6.12 ./configure --prefix=/usr/local/python3 --enable-optimizations make -j8 build_all \u0026\u0026 make -j8 install ","date":"2020-12-27","objectID":"/centos7_install_qemu/:4:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"设置软链接 ln -s /usr/local/python3/bin/python3 /usr/bin/python3 ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 ","date":"2020-12-27","objectID":"/centos7_install_qemu/:5:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"验证 # python3 Python 3.6.12 (default, Dec 27 2020, 07:52:33) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. \u003e\u003e\u003e 安装 ninja qemu-5.2.0 编译时使用构建工具 ninja 下载 ninja git clone git://github.com/ninja-build/ninja.git \u0026\u0026 cd ninja ./configure.py --bootstrap cp ninja /usr/bin/ 使用 ninja --version, 验证 ninja 版本: # ninja --version 1.10.2.git 编译安装 qemu-5.2.0 完成以上步骤之后就可以开始安装qemu了。其实可以通过 yum 安装，但是会缺少一些二进制文件。 ","date":"2020-12-27","objectID":"/centos7_install_qemu/:6:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"安装依赖 首先安装 qemu-5.2.0 所需的依赖，这里追加一个小提示： CentOS7 编译安装软件时经常需要安装对应的依赖。编译过程中如果发现缺少依赖，则编译后报错并退出，这时候就需要安装依赖包。以qemu-5.2.0安装为例，编译时提示缺少 glib2 包。这时候不是下载 glib2，而是下载对应的开发包，CentOS里是 glib2-devel，Ubuntu 下则是 glib2-dev。 yum install -y pkgconfig-devel glib2-devel pixman-devel 这里提供的依赖可能补全，编译过程中如果提示缺少依赖，请根据以上给出的提示安装对应依赖。 ","date":"2020-12-27","objectID":"/centos7_install_qemu/:7:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"下载 qemu-5.2.0 在 qemu 官网下载源码包 wget https://download.qemu.org/qemu-5.2.0.tar.xz ","date":"2020-12-27","objectID":"/centos7_install_qemu/:8:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"编译安装 tar xvJf qemu-5.2.0.tar.xz cd qemu-5.2.0 ./configure --enable-debug --target-list=x86_64-softmmu --enable-kvm make \u0026\u0026 make install ","date":"2020-12-27","objectID":"/centos7_install_qemu/:9:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["虚拟化"],"content":"验证 # qemu- qemu-edid qemu-img qemu-nbd qemu-storage-daemon qemu-ga qemu-io qemu-pr-helper qemu-system-x86_64 ","date":"2020-12-27","objectID":"/centos7_install_qemu/:10:0","tags":["kvm","linux"],"title":"CentOS7 安装 qemu-5.2.0","uri":"/centos7_install_qemu/"},{"categories":["开发"],"content":"在 Windows 使用 Go 开发项目是，为了实现统一的配置和格式管理，需要进行一下的配置。 开发环境选择 Go 语言的开发环境统一使用 Jetbrain 公司的 Goland。之后需要进行一些配置。 修改统一的文件换行符为 \\n 。 settings \u003e Editor \u003e Code Style 添加格式化工具 goimports。goimports 同时内置了 gofmt 的功能。可以格式化 Go 代理、自动导入依赖包等。 settings \u003e Editor \u003e Code Style \u003e Go 设置文件自动格式化 settings \u003e Tools \u003e File Watch 配置远程主机代码同步（可选） Tools \u003e Deployment \u003e Configuration Git 配置 文本文件所使用的换行符，在不同的系统平台上是不一样的。 UNIX/Linux 使用的是 0x0A（LF） ，早期的 Mac OS 使用的是 0x0D（CR） ，后来的 OS X 在更换内核后与 UNIX 保持一致了。但 DOS/Windows 一直使用 0x0D0A（CRLF） 作为换行符。 跨平台协作开发是常有的，不统一的换行符确实对跨平台的文件交换带来了麻烦。最大的问题是，在不同平台上，换行符发生改变时，Git 会认为整个文件被修改，这就造成我们没法 diff，不能正确反映本次的修改。还好 Git 在设计时就考虑了这一点，其提供了一个 autocrlf 的配置项，用于在提交和检出时自动转换换行符，该配置有三个可选项： true: 提交时转换为 LF，检出时转换为 CRLF false: 提交检出均不转换 input: 提交时转换为LF，检出时不转换 用如下命令即可完成配置： # 提交时转换为LF，检出时转换为CRLF git config --global core.autocrlf true # 提交时转换为LF，检出时不转换 git config --global core.autocrlf input # 提交检出均不转换 git config --global core.autocrlf false 如果把 autocrlf 设置为 false 时，那另一个配置项 safecrlf 最好设置为 ture。该选项用于检查文件是否包含混合换行符，其有三个可选项： true: 拒绝提交包含混合换行符的文件 false: 允许提交包含混合换行符的文件 warn: 提交包含混合换行符的文件时给出警告 配置方法： # 拒绝提交包含混合换行符的文件 git config --global core.safecrlf true # 允许提交包含混合换行符的文件 git config --global core.safecrlf false # 提交包含混合换行符的文件时给出警告 git config --global core.safecrlf warn 为了防止混乱，直接使用以下配置。 $ git config --global core.autocrlf false $ git config --global core.safecrlf false 以上配置需要注意: *.bat、*.ps 的换行修改为 CRLF；*.sh 文件修改为 LF，其他的所有文件统一为 LF。 ","date":"2020-10-29","objectID":"/windows%E4%B8%8A%E4%BD%BF%E7%94%A8go%E8%AF%AD%E8%A8%80%E5%BC%80%E5%8F%91/:0:0","tags":["windows","golang"],"title":"Windows 上使用 Go 语言","uri":"/windows%E4%B8%8A%E4%BD%BF%E7%94%A8go%E8%AF%AD%E8%A8%80%E5%BC%80%E5%8F%91/"},{"categories":["数据库"],"content":"安装 这里直接使用 docker 安装 postgresql-13 docker run --name postgresql13 -e POSTGRES_PASSWORD=123456 -p 54322:5432 -d postgres:13 安装成功后会绑定主机端口 54322。直接进入 postgresql13 容器，使用 pgsql。 [root@localhost ~]# docker exec -it 3e3b03e3 /bin/bash root@3e3b03e3e442:/# psql -h localhost -p 5432 -U postgres psql (13.0 (Debian 13.0-1.pgdg100+1)) Type \"help\" for help. postgres=# psql 是 pgsql 的客户端命令，使用参数如下： -h：指定 pgsql 的地址 -p：指定 pgsql 的绑定端口 -U：指定登录的用户名，默认为 postgres。后面可以紧接 “database”，直接进入指定的数据库。 数据库的操作 postgresql 支持的数据库操作有 增、删、查、改 ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:0:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"创建数据库 创建数据库的命令为： create database \u003cdatabasename\u003e [encoding 'UTF-8']  postgres=#createdatabasetestencoding'UTF-8';CREATEDATABASE ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:1:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"查询数据库 查询数据库的命令有两种：第一种是 \\l ，只能在 psql 中使用： postgres=#\\lListofdatabasesName|Owner|Encoding|Collate|Ctype|Accessprivileges-----------+----------+----------+------------+------------+----------------------- postgres|postgres|UTF8|en_US.utf8|en_US.utf8|template0|postgres|UTF8|en_US.utf8|en_US.utf8|=c/postgres+|||||postgres=CTc/postgrestemplate1|postgres|UTF8|en_US.utf8|en_US.utf8|=c/postgres+|||||postgres=CTc/postgrestest|postgres|UTF8|en_US.utf8|en_US.utf8|testdb|postgres|UTF8|en_US.utf8|en_US.utf8|(5rows) 另一种命令为： select * from pg_databse  postgres=#selectdatnamefrompg_database;datname----------- postgrestemplate1template0testdbtest(5rows) ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:2:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"修改数据库 修改数据库使用关键字 alter  postgres=#alterdatabasetestxrenametotest;ALTERDATABASE ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:3:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"删除数据库 postgres=#dropdatabasetest;DROPDATABASE ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:4:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"选择数据库 选择数据和切换数据的命令是相同的，使用命令 \\c databasename  postgres=#\\ctest;Youarenowconnectedtodatabase\"test\"asuser\"postgres\".test=#\\cpostgres;Youarenowconnectedtodatabase\"postgres\"asuser\"postgres\". 表的操作 ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:5:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"创建表 创建 postgresql 表的语法为： CREATETABLEtable_name(column1datatype,column2datatype,column3datatype,.....columnNdatatype,PRIMARYKEY(oneormorecolumns)); 创建一张名为 COMPANY 的表： testdb=#CREATETABLECOMPANY(IDINTPRIMARYKEYNOTNULL,NAMETEXTNOTNULL,AGEINTNOTNULL,ADDRESSCHAR(50),SALARYREAL);CREATETABLE ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:6:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"查询表 查询表使用 \\d ： testdb=#\\dListofrelationsSchema|Name|Type|Owner--------+---------+-------+---------- public|company|table|postgrespublic|person|table|postgres 但是这种方式只能在 psql 命令中中使用，还可以使用 select 命令： testdb=#select*frompg_tableswhereschemaname='public';schemaname|tablename|tableowner|tablespace|hasindexes|hasrules|hastriggers|rowsecurity------------+-----------+------------+------------+------------+----------+-------------+------------- public|person|postgres||f|f|f|fpublic|company|postgres||t|f|f|f(2rows ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:7:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"查看表结构 查看表结构也是使用 \\d 命令： Table\"public.company\"Column|Type|Collation|Nullable|Default---------+---------------+-----------+----------+--------- id|integer||notnull|name|text||notnull|age|integer||notnull|address|character(50)|||salary|real|||Indexes:\"company_pkey\"PRIMARYKEY,btree(id) 也可以使用 sql 实现： testdb=#SELECTa.attnum,a.attnameASfield,t.typnameAStype,a.attlenASlength,a.atttypmodASlengthvar,a.attnotnullASnotnull,b.descriptionAScommentFROMpg_classc,pg_attributeaLEFTJOINpg_descriptionbONa.attrelid=b.objoidANDa.attnum=b.objsubid,pg_typetWHEREc.relname='company'ANDa.attnum\u003e0ANDa.attrelid=c.oidANDa.atttypid=t.oidORDERBYa.attnum;attnum|field|type|length|lengthvar|notnull|comment--------+---------+--------+--------+-----------+---------+--------- 1|id|int4|4|-1|t|2|name|text|-1|-1|t|3|age|int4|4|-1|t|4|address|bpchar|-1|54|f|5|salary|float4|4|-1|f|(5rows) ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:8:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"修改表结构 ALTER TABLE 语句用于添加、修改、删除表中的列：在现有表中添加列： ALTERTABLEtable_nameADDcolumn_namedatatype; 在现有表中删除列： ALTERTABLEtable_nameDROPCOLUMNcolume_name; 在现有表中修改字段类型： ALTERTABLEtable_nameALTERCOLUMNcolume_nameTYPEdatatype; 向表中的列添加 NOT NULL 约束： ALTERTABLEtable_nameMODIFYcolume_namedatatypeNOTNULL; 添加约束，支持的约束有 UNIQUE 、 PRIMARY KEY 、 CHECK  ALTERTABLEtable_nameADDCONSTRAINTMyUniqueConstraintUNIQUE(colume_name1,colume_name2...); 删除约束，支持的约束有 UNIQUE 、 PRIMARY KEY 、 CHECK ALTERTABLEtable_nameDROPCONSTRAINTMyUniqueConstraintUNIQUE; ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:9:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["数据库"],"content":"删除表 DROP 用于删除表： testdb=#droptablecompany;DROPTABLE JSON 类型的支持 PostgreSQL 支持存储 JSON 类型的数据，提供了两种类型： json 和 jsonb 。 json数据类型存储输入文本的精准拷贝，处理函数必须在每 次执行时必须重新解析该数据。 jsonb数据被存储在一种分解好的 二进制格式中，它在输入时要稍慢一些，因为需要做附加的转换。但是 jsonb在处理时要快很多，因为不需要解析。jsonb也支持索引，jsonb不保留空格、不 保留对象键的顺序并且不保留重复的对象键。 关于 JSONB 的详细信息可以参考 JSON 类型，这里只介绍 JSONB 类型数据的使用。 创建 JSONB 类型的表 CREATETABLEposts(IDINTPRIMARYKEYNOTNULL,specJSONB); 插入数据，使用的关键字为 INSERT INTO 。 -- 插入第一条数据 insertintopostsvalues(1,'{\"name\": \"first posts\", \"content\": \"This is a simple post\", \"author\": \"a\", \"time\": \"2020/10/15\"}');-- 插入第二条数据 insertintopostsvalues(2,'{\"name\": \"jsonb\", \"content\": \"jsonb is PostgreSQL inner type\", \"author\": \"bb\", \"time\": \"2020/10/12\", \"tag\": [\"database\", \"PgSQL\"]}'); 添加 key/value 索引： -- 给所有 key/values 添加索引 CREATEINDEXidx_posts_specONpostsUSINGgin(spec);-- 给指定的 key/values 添加索引 CREATEINDEXidx_posts_spec_authorONpostsUSINGgin((spec-\u003e'author')); 数据查询 SELECT ，全表查询： testdb=#select*fromposts;id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 1|{\"name\":\"first posts\",\"time\":\"2020/10/15\",\"author\":\"a\",\"content\":\"This is a simple post\"}2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}(2rows) 查询 JSONB 内的数据： -- spec-\u003e'name' 输出的数据格式为原生格式 testdb=#selectid,spec-\u003e'name'fromposts;id|?column?----+--------------- 1|\"first posts\"2|\"jsonb\"(2rows)-- spec-\u003e\u003e'name' 输出格式为 TEXT testdb=#selectid,spec-\u003e\u003e'name'fromposts;id|?column?----+------------- 1|firstposts2|jsonb(2rows)testdb=#insertintopostsvalues(3,'{\"name\": \"other\", \"content\": \"other data\", \"author\": \"bb\", \"other\": {\"name\": \"other\"}}');INSERT01-- 使用 -\u003e 操作符查询多级 json 格式的数据 testdb=#selectid,spec-\u003e'name'asspec_name,spec-\u003e'other'-\u003e'name'asspec_other_namefromposts;id|spec_name|spec_other_name----+---------------+----------------- 1|\"first posts\"|2|\"jsonb\"|3|\"other\"|\"other\"-- 使用 ? 查询 key 是否存在 testdb=#selectid,specfrompostswherespec?'tag';id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}(1row)-- 使用 ? 查询 values testdb=#selectid,specfrompostswherespec-\u003e'author'?'bb';id|spec----+------------------------------------------------------------------------------------------------------------------------------------ 2|{\"tag\":[\"database\",\"PgSQL\"],\"name\":\"jsonb\",\"time\":\"2020/10/12\",\"author\":\"bb\",\"content\":\"jsonb is PostgreSQL inner type\"}3|{\"name\":\"other\",\"other\":{\"name\":\"other\"},\"author\":\"bb\",\"content\":\"other data\"}(2rows)-- 使用 @\u003e 来精确查询 testdb=#selectid,specfrompostswherespec@\u003e'{\"other\": {\"name\": \"other\"}}'::jsonb;id|spec----+---------------------------------------------------------------------------------------- 3|{\"name\":\"other\",\"other\":{\"name\":\"other\"},\"author\":\"bb\",\"content\":\"other data\"}(1row) JSONB 支持的其他函数和操作符可以参考 这里。 ","date":"2020-10-13","objectID":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:10:0","tags":["postgreSQL","database"],"title":"postgresql 实战一：安装和使用","uri":"/pgsql%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["笔记"],"content":"golang cgo 到 Windows 的交叉编译 本篇记录在 MaxOS 下 cgo 交叉编译的解决方案。因为在项目中使用 go-sqlite3 ，编译 go-sqlite3 中需要使用到 cgo。在 MacOS 下编译 Go 原生 Linux 和 Windows 的程序使用以下命令： # 交叉编译到 linux GOOS=linux GOARCH=amd64 go build main.go # 交叉编译到 windows GOOS=windows GOARCH=amd64 go build -o main.exe main.go 如果使用 cgo 的话，还需要添加 CGO_ENABLED 参数： CGO_ENABLED=1 GOOS=windows GOARCH=amd64 go build -o main.exe main.go 但是这种编译 go-sqlite3 的代码会出现以下错误： # runtime/cgo gcc_libinit_windows.c:7:10: fatal error: 'windows.h' file not found 因为 Windows 中使用 MinGW，MacOS 下如果交叉编译需要安装 C/C++ 交叉编译工具： brew install FiloSottile/musl-cross/musl-cross brew install mingw-w64 安装完工具之后就可以使用命令： CGO_ENABLED=1 CC=x86_64-w64-mingw32-gcc CXX=x86_64-w64-mingw32-g++ GOOS=windows GOARCH=amd64 go build -a -v -o store.exe store/sqlite.exe 注意参数： CXX=x86_64-w64-mingw32-g++ ，如果缺少这个参数时，可能会出现错误： # runtime/cgo gcc: error: unrecognized command line option ‘-mthreads’; did you mean ‘-pthread’? ","date":"2020-09-10","objectID":"/golang%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91/:0:0","tags":["golang"],"title":"Golang跨平台编译","uri":"/golang%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BC%96%E8%AF%91/"},{"categories":["运维"],"content":"SCST 是 iscsi 的一种实现方式，它既可以使用 iscsi 协议共享本地磁盘，同时也支持 FC 协议。FC 协议需要硬件 FC HBA 卡的支持。 SCST 和 FC 的环境搭建如下看这里 。 环境配置 接下来 SCST 和 FC 的使用。首先需要有 scst 的环境： 保证 linux 内核中加载了 qla。使用 scstadm 查看所支持的驱动： 如果使用 FC 去共享磁盘，scst 需要创建和 FC 设备对应的 target。FC 设备和 target 属于一对一关系，而且创建 target 的名称要和 FC 设备的 ID 相同。查看 FC 设备的 ID 可以用以下的方式： 1.查看内核中 qla2x00t (/sys/kernel/scst_tgt/targets/qla2x00t) 目录下的内容 2.直接查看 FC 设备的 port_id (/sys/class/fc_host/hostx/port_name)， 配置 FC ","date":"2020-08-06","objectID":"/scst%E7%BB%93%E5%90%88fc/:0:0","tags":["iscsi"],"title":"Scst结合FC","uri":"/scst%E7%BB%93%E5%90%88fc/"},{"categories":["运维"],"content":"SCST 服务端配置 创建 target, FC 设备和 target 一对一。 scstadmin -add_target 50:01:10:a0:00:16:bf:30 -driver qla2x00t 创建 device 对应本地的块文件 scstadmin -open_dev fc1 -handler vdisk_fileio -attributes filename=/dev/sdc 创建 group，scst 中的 group 用于限定共享的对象。 scstadmin -add_group group1 -target 50:01:10:a0:00:16:bf:30 -driver qla2x00t 创建 lun，因为 scst target 和 FC 设置是一对一关系，所以当需要在同一个 FC 下共享多个磁盘给不同的客户端时就需要在同一个 target 下创建多个 lun。 scstadmin -add_lun 0 -target 50:01:10:a0:00:16:bf:30 -driver qla2x00t -group group1 -device fc1 指定共享的客户端，这里需要知道客户端 FC 设备对应的 ID。查看 /sys/class/fc_host/hostx/port_name scstadmin -add_init 50:01:10:a0:00:16:bf:34 --target 50:01:10:a0:00:16:bf:30 -driver qla2x00t -group group1 -device fc1 启动 target scstadmin -enable_target 50:01:10:a0:00:16:bf:30 --driver qla2x00t 最后将改动写入配置文件 scstadmin -write_config /etc/scst.conf （如果对应的客户端已经属于某个已存在的 group，则复用这个 group，并选择不存在的 lun id） ","date":"2020-08-06","objectID":"/scst%E7%BB%93%E5%90%88fc/:1:0","tags":["iscsi"],"title":"Scst结合FC","uri":"/scst%E7%BB%93%E5%90%88fc/"},{"categories":["运维"],"content":"客户端配置 扫描 scst 主机 echo \"- - -\" \u003e /sys/class/scst_host/host3/scan 其中 \"- - -\" 这三个值代表通道，SCSI目标ID和LUN。破折号充当通配符，表示“重新扫描所有内容”。host3 和 /sys/class/fc_host/host3 相对应。执行命令后客户端增加了一块磁盘。 ","date":"2020-08-06","objectID":"/scst%E7%BB%93%E5%90%88fc/:2:0","tags":["iscsi"],"title":"Scst结合FC","uri":"/scst%E7%BB%93%E5%90%88fc/"},{"categories":["微服务","代码"],"content":"GRPC 简介 grpc 是由 google 开发的一款开源，高性能 rpc（远程进程调用协议）使用 Protocol Buffers 作为数据交换格式。 GRPC 安装 golang 使用 grpc 要安装 grpc-go, protoc 和 对应的插件。 ","date":"2020-07-31","objectID":"/grpc1/:0:0","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"安装grpc-go go get -u github.com/golang/protobuf/{proto,protoc-gen-go} go get -u google.golang.org/grpc 如果是国内用户无法连接到 google.golang.org 的话可以使用 VPN。或者直接从 github.com 直接下载源代码再编译安装 git clone https://github.com/grpc/grpc-go.git $GOPATH/src/google.golang.org/grpc go get -u google.golang.org/grpc ","date":"2020-07-31","objectID":"/grpc1/:1:0","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"安装 protoc golang 要使用 grpc，还需要使用 protoc 工具。因为 golang 不能直接识别 .proto 文件，需要使用 protoc 工具将 .proto 转化成 golang 代码。下面介绍几个平台下安装 protobuf 的方法。 ","date":"2020-07-31","objectID":"/grpc1/:2:0","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"macos macos 下安装直接使用 brew 命令即可。 brew install protobuf ","date":"2020-07-31","objectID":"/grpc1/:2:1","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"linux linux 下需要先从 github.com 下载 protobuf 源码或者二进制文件，下载地址。二进制安装的话就下载 protobuf-all-*.tar.gz 包，解压后进入生成的目录。之后执行命令： make \u0026\u0026 make install ","date":"2020-07-31","objectID":"/grpc1/:2:2","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"windows 下载 protobuf.all-*.zip 包，解压后再配置环境变量，将 protobuf\\bin 配置到 $PATH 变量中。 GRPC使用 ","date":"2020-07-31","objectID":"/grpc1/:2:3","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"新建项目 新建一个 grpc 项目，如下: ../sample └── pb └── echo.proto echo.proto 的内容为: syntax = \"proto3\"; // protobuf 语法版本，默认为 proto2 // // 这个是注释 // .proto 所在的包路径 package sample.pb;option go_package = \"pb\";// EchoRequest grpc 请求报文格式. message EchoRequest { string message = 1;}// EchoResponse grpc 响应报文格式. message EchoResponse { string message = 1;}// 定义 Echo 服务. service Echo { // UnaryEcho 一元请求. rpc UnaryEcho(EchoRequest) returns (EchoResponse) {} // ServerStreamingEcho 服务端 stream 请求. rpc ServerStreamingEcho(EchoRequest) returns (stream EchoResponse) {} // ClientStreamingEcho 客户端 stream 请求. rpc ClientStreamingEcho(stream EchoRequest) returns (EchoResponse) {} // BidirectionalStreamingEcho 双向 stream. rpc BidirectionalStreamingEcho(stream EchoRequest) returns (stream EchoResponse) {}} 执行以下命令将 .proto 转化为 golang 代码: cd sample # protoc -I\u003cimport路径\u003e \u003c...-I$PATH\u003e --go_out=plugins=grpc:\u003c输出路径\u003e *.proto protoc -I. --go_out=plugins=grpc:. pb/echo.proto 简单描述下 protoc 命令的功能。 -I : *.proto 中导入的包的路径，导入的路径为全路径格式。. 表示当前路径。 –go_out=plugins=grpc: ：指定 _.proto 输出的格式和路径，生成 _.go 文件的路径为 和 *.proto 的拼接。执行成功后成为文件 echo.pb.go 文件: ../sample └── pb ├── echo.pb.go └── echo.proto ","date":"2020-07-31","objectID":"/grpc1/:3:0","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"Server package main import ( \"context\" \"errors\" \"google.golang.org/grpc\" \"io\" \"log\" \"mysite/sample/pb\" \"net\" ) type server struct { pb.EchoServer } // 简单请求 func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: \"echo: \" + request.Message}, nil } // 服务端流式 func (s *server) ServerStreamingEcho(request *pb.EchoRequest, stream pb.Echo_ServerStreamingEchoServer) error { _ = stream.Send(\u0026pb.EchoResponse{Message: \"hello\"}) _ = stream.Send(\u0026pb.EchoResponse{Message: \" \"}) _ = stream.Send(\u0026pb.EchoResponse{Message: \"client\"}) return nil } // 客户端流式 func (s *server) ClientStreamingEcho(stream pb.Echo_ClientStreamingEchoServer) error { for { recv, err := stream.Recv() // block 直到有数据输出 if errors.Is(err, io.EOF) { // 表示消息传输完毕 break } if err != nil { log.Printf(\"recv error: %v\", err) return err } // client 断开连接 log.Printf(\"recv data: %v\", recv.Message) } // SendAndClose 只存在于客户端 stream 请求 // 发送完关闭 stream return stream.SendAndClose(\u0026pb.EchoResponse{Message: \"bye\"}) } // 双向流式 func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { // 如果服务端 stream 方法退出，客户端请求也直接断开 for { recv, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv error: %v\", err) return err } if recv.Message == \"bye\" { log.Printf(\"client send done!\") break } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + recv.Message}); err != nil { log.Printf(\"send message error: %v\", err) return err } } return nil } func main() { addr := \"127.0.0.1:50001\" // grpc 为 http2 请求，传输层协议为 tcp lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"binding at %v: %v\", addr, err) } gRPCServer := grpc.NewServer() pb.RegisterEchoServer(gRPCServer, \u0026server{}) if err := gRPCServer.Serve(lis); err != nil { log.Fatalf(\"start grpc: %v\", err) } } ","date":"2020-07-31","objectID":"/grpc1/:4:0","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"Client package main import ( \"context\" \"errors\" \"fmt\" \"google.golang.org/grpc\" \"io\" \"log\" \"mysite/sample/pb\" ) // 简单请求 func unaryEcho(cli pb.EchoClient, msg string) { recv, err := cli.UnaryEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err != nil { log.Fatalf(\"unaryEcho %v\", err) } log.Println(\"recv data =\u003e \" + recv.Message) } // 服务端流式 func serverStreamingEcho(cli pb.EchoClient, msg string) { stream, err := cli.ServerStreamingEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err != nil { log.Fatalf(\"serverStreamingEcho %v\", err) } ctx := stream.Context() for { select { case \u003c-ctx.Done(): log.Println(\"serverStreamingEcho done!\") break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err == nil { log.Println(\"serverStreaming reply =\u003e \", msg.Message) } } } // 客户端流式 func clientStreamingEcho(cli pb.EchoClient) { stream, err := cli.ClientStreamingEcho(context.Background()) if err != nil { log.Printf(\"connect client Streaming: %v\\n\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \"hello\"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \" \"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } err = stream.Send(\u0026pb.EchoRequest{Message: \"world\"}) if err != nil { log.Printf(\"clientStreamingEcho send data: %v\", err) return } if recv, err := stream.CloseAndRecv(); err == nil { fmt.Printf(\"recv data: %v\\n\", recv.Message) } } // 双向流式 func bidirectionalStreamingEcho(cli pb.EchoClient) { stream, err := cli.BidirectionalStreamingEcho(context.Background()) if err != nil { log.Printf(\"bidirectionalStreamingEcho error: %v\\n\", err) return } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 1\"}) recv, err := stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 2\"}) recv, err = stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"dataset 3\"}) recv, err = stream.Recv() if err == nil { fmt.Printf(\"recv from bidirectionalStreamingEcho =\u003e %v\\n\", recv.Message) } stream.Send(\u0026pb.EchoRequest{Message: \"bye\"}) stream.CloseSend() } func main() { addr := \"127.0.0.1:50001\" ctx, cancel := context.WithCancel(context.Background()) defer cancel() conn, err := grpc.DialContext(ctx, addr, grpc.WithInsecure()) if err != nil { log.Fatalf(\"connect %v: %v\", addr, err) } cli := pb.NewEchoClient(conn) unaryEcho(cli, \"hello\") serverStreamingEcho(cli, \"hello\") clientStreamingEcho(cli) bidirectionalStreamingEcho(cli) } ","date":"2020-07-31","objectID":"/grpc1/:5:0","tags":["golang","grpc"],"title":"GPRC 实战","uri":"/grpc1/"},{"categories":["微服务","代码"],"content":"grpc 除了提供四种请求类型之外，还支持很多高级功能：keepalive、请求重试、负载均衡、用户验证等。接下来一一介绍。 GRPC 进阶功能 每个grpc请求都是 stream。 ","date":"2020-07-31","objectID":"/grpc2/:0:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"Keepalive Keepalive 能够让 grpc 的每个 stream 保持长连接状态，适合一些执行时间长的请求。Keepalive 支持在服务端和客户端配置，且只有服务端配置后，客户端的配置才会真正有效。先给出实例的代码在来说明 grpc keepalive 的使用情况：server 实现： // ... var kaep = keepalive.EnforcementPolicy{ MinTime: 5 * time.Second, // If a client pings more than once every 5 seconds, terminate the connection PermitWithoutStream: true, // Allow pings even when there are no active streams } var kasp = keepalive.ServerParameters{ MaxConnectionIdle: 15 * time.Second, // If a client is idle for 15 seconds, send a GOAWAY MaxConnectionAge: 30 * time.Second, // If any connection is alive for more than 30 seconds, send a GOAWAY MaxConnectionAgeGrace: 5 * time.Second, // Allow 5 seconds for pending RPCs to complete before forcibly closing connections Time: 5 * time.Second, // Ping the client if it is idle for 5 seconds to ensure the connection is still active Timeout: 1 * time.Second, // Wait 1 second for the ping ack before assuming the connection is dead } // server implements EchoServer. type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: req.Message}, nil } func main() { address := \"50001\" lis, err := net.Listen(\"tcp\", address) if err != nil { log.Fatalf(\"failed to listen: %v\", err) } // 创建 grpc server 时配置服务端的 keepalive s := grpc.NewServer(grpc.KeepaliveEnforcementPolicy(kaep), grpc.KeepaliveParams(kasp)) pb.RegisterEchoServer(s, \u0026server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } client 端实现： // ... var kacp = keepalive.ClientParameters{ Time: 10 * time.Second, // send pings every 10 seconds if there is no activity Timeout: time.Second, // wait 1 second for ping ack before considering the connection dead PermitWithoutStream: true, // send pings even without active streams } func main() { conn, err := grpc.Dial(\"50001\", grpc.WithInsecure(), grpc.WithKeepaliveParams(kacp)) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := pb.NewEchoClient(conn) ctx, cancel := context.WithTimeout(context.Background(), 3*time.Minute) defer cancel() fmt.Println(\"Performing unary request\") res, err := c.UnaryEcho(ctx, \u0026pb.EchoRequest{Message: \"keepalive demo\"}) if err != nil { log.Fatalf(\"unexpected error from UnaryEcho: %v\", err) } fmt.Println(\"RPC response:\", res) } keepalive 的实现核心在于 keepalive.EnforcementPolicy 和 keepalive.ServerParameters。首先是 keepalive.ServerParameters。它包含几个属性： MaxConnectionIdle : 最大空闲连接时间，默认为无限制。这段时间为客户端 stream 请求为0 或者建立连接。超出这段时间后，serve 会发送一个 GoWay，强制 client stream 断开。 MaxConnectionAge：最大连接时间，默认为无限制。stream 连接超出这个值是发送一个 GoWay。 MaxConnectionAgeGrace ：超出MaxConnectionAge之后的宽限时长，默认无限制，最小为 1s。 Time ：如果一段时间客户端存活但没有 pings 请求，服务端发送一次 ping 请求，默认是 2hour。 Timeout：服务端发送 ping 请求超时的时间，默认20s。 keepalive.EnforcementPolicy在服务端强制执行策略，如果客户端违反改策略则断开连接。它有两个属性： MinTime : 如果在指定时间内收到 pings 请求大于一次，强制断开连接，默认 5min。 PermitWithoutStream：没有活动的 stream 也允许pings。默认关闭。 keepalive.ClientParameters是在客户端这侧使用的 keepalive 配置： Time ：pings 请求间隔时间，默认无限制，最小为 10s。 Timeout ：pings 超时时间，默认是 20s。 PermitWithoutStream：没有活动的 stream 也允许pings。默认关闭。 ","date":"2020-07-31","objectID":"/grpc2/:1:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"请求重试 grpc 支持请求重试，在客户端配置好规则之后，客户端会在请求失败之后尝试重新发起请求。 var ( retryPolicy = `{ \"methodConfig\": [{ \"name\": [{\"service\": \"mysite.pb.Echo\"}], \"waitForReady\": true, \"retryPolicy\": { \"MaxAttempts\": 3, \"InitialBackoff\": \".01s\", \"MaxBackoff\": \"1s\", \"BackoffMultiplier\": 2.0, \"RetryableStatusCodes\": [ \"UNAVAILABLE\" ] } }]}` ) // use grpc.WithDefaultServiceConfig() to set service config func retryDial() (*grpc.ClientConn, error) { return grpc.Dial(*addr, grpc.WithInsecure(), grpc.WithDefaultServiceConfig(retryPolicy)) } // ... retry 配置只需要在客户端设置即可生效。主要是配置ServerConfig，格式为该链接 MaxAttempts ：重试的最大次数，最大值是5。 InitialBackoff : 初始化重试间隔时间，第一次重试去 Randon(0,initialBackoff)。 MaxBackoff : 最大重试间隔时间，多次重试是，间隔时间取 random(0,min(initial_backoff*backoff_multiplier**(n-1), max_backoff))。 RetryableStatusCodes : 设置需要重试的状态码。 ","date":"2020-07-31","objectID":"/grpc2/:2:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"负载均衡 grpc 支持客户端负载均衡策略，负载均衡在 grpc name_resolver 的基础上实现： const ( exampleScheme = \"example\" exampleServiceName = \"lb.example.grpc.io\" ) // ... func main() { // ... // round_robin 指定负载均衡策略为轮询策略 roundrobinConn, err := grpc.Dial( fmt.Sprintf(\"%s:///%s\", exampleScheme, exampleServiceName), grpc.WithBalancerName(\"round_robin\"), // This sets the initial balancing policy. grpc.WithInsecure(), grpc.WithBlock(), ) // ... } // 配置 name resolver type exampleResolverBuilder struct{} func (*exampleResolverBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) { r := \u0026exampleResolver{ target: target, cc: cc, addrsStore: map[string][]string{ exampleServiceName: addrs, }, } r.start() return r, nil } func (*exampleResolverBuilder) Scheme() string { return exampleScheme } type exampleResolver struct { target resolver.Target cc resolver.ClientConn addrsStore map[string][]string } func (r *exampleResolver) start() { addrStrs := r.addrsStore[r.target.Endpoint] addrs := make([]resolver.Address, len(addrStrs)) for i, s := range addrStrs { addrs[i] = resolver.Address{Addr: s} } r.cc.UpdateState(resolver.State{Addresses: addrs}) } func (*exampleResolver) ResolveNow(o resolver.ResolveNowOptions) {} func (*exampleResolver) Close() {} func init() { resolver.Register(\u0026exampleResolverBuilder{}) } 主要是要实现 resolver.Builder接口 // Builder creates a resolver that will be used to watch name resolution updates. type Builder interface { // Build creates a new resolver for the given target. // // gRPC dial calls Build synchronously, and fails if the returned error is // not nil. Build(target Target, cc ClientConn, opts BuildOptions) (Resolver, error) // Scheme returns the scheme supported by this resolver. // Scheme is defined at \u003chttps://github.com/grpc/grpc/blob/master/doc/naming.md\u003e. Scheme() string } 上面的实现方式不支持动态增减服务端地址，可以使用 etcd 实现负载均衡： type etcdBuilder struct { prefix string endpoints []string } func ETCDBuilder(prefix string, endpoints []string) resolver.Builder { return \u0026etcdBuilder{prefix, endpoints} } func (b *etcdBuilder) Build(target resolver.Target, cc resolver.ClientConn, opts resolver.BuildOptions) (resolver.Resolver, error) { cli, err := clientv3.New(clientv3.Config{ Endpoints: b.endpoints, DialTimeout: 3 * time.Second, }) if err != nil { return nil, fmt.Errorf(\"connect to etcd endpoints error\") } ctx, cancel := context.WithCancel(context.Background()) rlv := \u0026etcdResolver{ cc: cc, cli: cli, ctx: ctx, cancel: cancel, watchKeyPrefix: b.prefix, freq: 5 * time.Second, t: time.NewTimer(0), rn: make(chan struct{}, 1), im: make(chan []resolver.Address), wg: sync.WaitGroup{}, } rlv.wg.Add(2) go rlv.watcher() go rlv.FetchBackendsWithWatch() return rlv, nil } func (b *etcdBuilder) Scheme() string { return \"etcd\" } type etcdResolver struct { retry int freq time.Duration ctx context.Context cancel context.CancelFunc cc resolver.ClientConn cli *clientv3.Client t *time.Timer watchKeyPrefix string rn chan struct{} im chan []resolver.Address wg sync.WaitGroup } func (r *etcdResolver) ResolveNow(opt resolver.ResolveNowOptions) { select { case r.rn \u003c- struct{}{}: default: } } func (r *etcdResolver) Close() { r.cancel() r.wg.Wait() r.t.Stop() } func (r *etcdResolver) watcher() { defer r.wg.Done() for { select { case \u003c-r.ctx.Done(): return case addrs := \u003c-r.im: if len(addrs) \u003e 0 { r.retry = 0 r.t.Reset(r.freq) r.cc.UpdateState(resolver.State{Addresses: addrs}) continue } case \u003c-r.t.C: case \u003c-r.rn: } result := r.FetchBackends() if len(result) == 0 { r.retry++ r.t.Reset(r.freq) } else { r.retry = 0 r.t.Reset(r.freq) } r.cc.UpdateState(resolver.State{Addresses: result}) } } func (r *etcdResolver) FetchBackendsWithWatch() { defer r.wg.Done() for { select { case \u003c-r.ctx.Done(): return case _ = \u003c-r.cli.Watch(r.ctx, r.watchKeyPrefix, clientv3.WithPrefix()): result := r.FetchBackends() r.im \u003c- result } } } func (r *etcdResolver) FetchBackends() []resolver.Address { ctx, cancel := context.WithTimeout(context.Background()","date":"2020-07-31","objectID":"/grpc2/:3:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"grpc 加密传输 以上的请求中，grpc 都是通过明文传输数据。但这种方式是很容易泄露数据内容的，grpc 支持 TLS 格式的加密通讯，来保存数据传输的安全性。 ","date":"2020-07-31","objectID":"/grpc2/:4:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"TLS 证书 我们首先来生成 TLS 证书 openssl ecparam -genkey -name secp384r1 -out server.key openssl req -new -x509 -sha256 -key server.key -out server.pem -days 3650 这里需要填写相关信息 Country Name (2 letter code) []: State or Province Name (full name) []: Locality Name (eg, city) []: Organization Name (eg, company) []: Organizational Unit Name (eg, section) []: Common Name (eg, fully qualified host name) []: mysite Email Address []: 填写完成后就生成对应的证书： ssl ├── server.key └── server.pem 服务端实现 // ... const PORT = \"50001\" func main() { // 通过 credentials 加载服务端的TLS证书 c, err := credentials.NewServerTLSFromFile(\"../ssl/server.pem\", \"../ssl/server.key\") if err != nil { log.Fatalf(\"credentials.NewServerTLSFromFile err: %v\", err) } // 添加 credentials 配置 server := grpc.NewServer(grpc.Creds(c)) pb.RegisterSearchServiceServer(server, \u0026SearchService{}) lis, err := net.Listen(\"tcp\", \":\"+PORT) if err != nil { log.Fatalf(\"net.Listen err: %v\", err) } server.Serve(lis) } 客户端实现 const PORT = \"9001\" func main() { // 添加 credentials 配置 c, err := credentials.NewClientTLSFromFile(\"../ssl/server.pem\", \"mysite\") if err != nil { log.Fatalf(\"credentials.NewClientTLSFromFile err: %v\", err) } // 客户端开启证书验证 conn, err := grpc.Dial(\":\"+PORT, grpc.WithTransportCredentials(c)) if err != nil { log.Fatalf(\"grpc.Dial err: %v\", err) } defer conn.Close() client := pb.NewSearchServiceClient(conn) resp, err := client.Search(context.Background(), \u0026pb.SearchRequest{ Request: \"gRPC\", }) if err != nil { log.Fatalf(\"client.Search err: %v\", err) } log.Printf(\"resp: %s\", resp.GetResponse()) } ","date":"2020-07-31","objectID":"/grpc2/:4:1","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"CA TLS 证书 TLS 证书的安全性还不够高，特别在证书生成之后，server.key文件的传输就成为一个问题。所以 CA 来签发 TLS 证书来解决这个问题。使用开源工具 cfssl 生成对应的证书：1.ca 配置 cat \u003c\u003c EOF | tee ca-config.json { \"signing\": { \"default\": { \"expiry\": \"87600h\" }, \"profiles\": { \"mysite\": { \"expiry\": \"87600h\", \"usages\": [ \"signing\", \"key encipherment\", \"server auth\", \"client auth\" ] } } }} EOF 配置 mysite 机构证书可以进行服务端和客户端双向验证。2.ca 证书 cat \u003c\u003c EOF | tee ca-csr.json { \"CN\": \"mysite CA\", \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ]} EOF 3.服务端证书 cat \u003c\u003c EOF | tee server-csr.json { \"CN\": \"mysite\", \"hosts\": [ \"127.0.0.1\" ], \"key\": { \"algo\": \"rsa\", \"size\": 2048 }, \"names\": [ { \"C\": \"CN\", \"L\": \"Beijing\", \"ST\": \"Beijing\" } ]} EOF 生成 mysite ca 证书和私钥，初始化 ca cfssl gencert -initca ca-csr.json | cfssljson -bare ca 生成server证书 cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=mysite -hostname=mysite server-csr.json | cfssljson -bare server 最后的结果为: ../ssl ├── ca-config.json ├── ca-csr.json ├── ca-key.pem ├── ca.csr ├── ca.pem ├── server-csr.json ├── server-key.pem ├── server.csr └── server.pem 接下来是代码实现，先是服务端： // ... type ecServer struct { pb.UnimplementedEchoServer } func (s *ecServer) UnaryEcho(ctx context.Context, req *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: req.Message}, nil } func main() { lis, err := net.Listen(\"tcp\", \"127.0.0.1:50001\") if err != nil { log.Fatalf(\"failed to listen: %v\", err) } // Create tls based credential. cert, err := tls.LoadX509KeyPair(\"ssl/server.pem\", \"ssl/server-key.pem\") if err != nil { log.Fatalf(\"tls.LoadX509KeyPair err: %v\", err) } certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(\"ssl/ca.pem\") if err != nil { log.Fatalf(\"ioutil.ReadFile err: %v\", err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\"certPool.AppendCertsFromPEM err\") } creds := credentials.NewTLS(\u0026tls.Config{ Certificates: []tls.Certificate{cert}, ClientAuth: tls.RequireAndVerifyClientCert, ClientCAs: certPool, }) s := grpc.NewServer(grpc.Creds(creds)) // Register EchoServer on the server. pb.RegisterEchoServer(s, \u0026ecServer{}) log.Println(\"server start\") if err := s.Serve(lis); err != nil { log.Fatalf(\"failed to serve: %v\", err) } } 然后是客户端： // ... func callUnaryEcho(client pb.EchoClient, message string) { ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) defer cancel() resp, err := client.UnaryEcho(ctx, \u0026pb.EchoRequest{Message: message}) if err != nil { log.Fatalf(\"client.UnaryEcho(_) = _, %v: \", err) } fmt.Println(\"UnaryEcho: \", resp.Message) } func main() { // Create tls based credential. cert, err := tls.LoadX509KeyPair(\"ssl/server.pem\", \"ssl/server-key.pem\") if err != nil { log.Fatalf(\"tls.LoadX509KeyPair err: %v\", err) } certPool := x509.NewCertPool() ca, err := ioutil.ReadFile(\"ssl/ca.pem\") if err != nil { log.Fatalf(\"ioutil.ReadFile err: %v\", err) } if ok := certPool.AppendCertsFromPEM(ca); !ok { log.Fatalf(\"certPool.AppendCertsFromPEM err\") } creds := credentials.NewTLS(\u0026tls.Config{ Certificates: []tls.Certificate{cert}, ServerName: \"mysite\", RootCAs: certPool, }) // Set up a connection to the server. conn, err := grpc.Dial(\"127.0.0.1:50001\", grpc.WithTransportCredentials(creds)) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() // Make a echo client and send an RPC. rgc := pb.NewEchoClient(conn) callUnaryEcho(rgc, \"hello world\") } ","date":"2020-07-31","objectID":"/grpc2/:4:2","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"拦截器 grpc 支持服务端和客户端的拦截器，可以在请求发起或返回前进行处理，而不用修改原来的代码。接下来来看服务端和客户端各自怎么使用拦截器： // unary 请求拦截器 func UnaryInterceptor(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler, ) (resp interface{}, err error) { var ip string p, ok := peer.FromContext(ctx) if ok { ip = p.Addr.String() } md, _ := metadata.FromIncomingContext(ctx) start := time.Now() resp, err = handler(ctx, req) end := time.Now() log.Printf(\"%10s | %14s | %10v | md=%v | reply = %v\", ip, info.FullMethod, end.Sub(start), md, resp) return } // stream 请求拦截器 func StreamInterceptor(srv interface{}, ss grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler, ) (err error) { var ip string p, ok := peer.FromContext(ss.Context()) if ok { ip = p.Addr.String() } err = handler(srv, ss) log.Printf(\"stream %v | %v | %s\\\\n\", srv, ip, info.FullMethod) return } type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: request.Message}, nil } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv failed: %v\\\\n\", err) } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + msg.Message}); err != nil { log.Printf(\"send to client: %v\\\\n\", err) } } return nil } func main() { addr := \"127.0.0.1:50001\" lis, err := net.Listen(\"tcp\", addr) if err != nil { log.Fatalf(\"network at %v: %v\\\\n\", addr, err) } s := grpc.NewServer(grpc.ChainUnaryInterceptor(UnaryInterceptor), grpc.ChainStreamInterceptor(StreamInterceptor)) pb.RegisterEchoServer(s, \u0026server{}) if err := s.Serve(lis); err != nil { log.Fatalf(\"start server at %v: %v\\\\n\", addr, err) } } grpc 中的拦截器分两种，一元请求的拦截器和流式请求的拦截器。其中流式请求的连接器同时作用于服务端流式、客户端流式和双向流式三种请求模式。 接下来是客户端： func clientUnaryInterceptor( ctx context.Context, method string, req, reply interface{}, cc *grpc.ClientConn, invoker grpc.UnaryInvoker, opts ...grpc.CallOption, ) (err error) { ctx = metadata.AppendToOutgoingContext(ctx, \"username\", \"OOB\") err = invoker(ctx, method, req, reply, cc, opts...) return } func clientStreamInterceptor(ctx context.Context, desc *grpc.StreamDesc, cc *grpc.ClientConn, method string, streamer grpc.Streamer, opts ...grpc.CallOption, ) (stream grpc.ClientStream, err error) { // before stream stream, err = streamer(ctx, desc, cc, method, opts...) // after stream return } func callUnaryEcho(cc pb.EchoClient, msg string) { reply, err := cc.UnaryEcho(context.Background(), \u0026pb.EchoRequest{Message: msg}) if err == nil { log.Printf(\"reply =\u003e %v\\\\n\", reply) } } func callBidirectionalEcho(cc pb.EchoClient, msg string) { stream, err := cc.BidirectionalStreamingEcho(context.TODO()) if err != nil { log.Fatalf(\"call BidirectionalEcho: %v\\\\n\", err) } _ = stream.Send(\u0026pb.EchoRequest{Message: msg}) _ = stream.CloseSend() ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } reply, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Fatalf(\"stream recv: %v\\\\n\", err) } log.Printf(\"stream reply =\u003e %v\\\\n\", reply.Message) } } func main() { addr := \"127.0.0.1:50001\" ctx, cancel := context.WithCancel(context.Background()) defer cancel() conn, err := grpc.DialContext( ctx, addr, grpc.WithInsecure(), grpc.WithChainUnaryInterceptor(clientUnaryInterceptor), grpc.WithChainStreamInterceptor(clientStreamInterceptor)) if err != nil { log.Fatalf(\"connect %v: %v\\\\n\", addr, err) } cc := pb.NewEchoClient(conn) callUnaryEcho(cc, \"unary\") callBidirectionalEcho(cc, \"start\") } grpc 的拦截器同时支持单个拦截器和链式拦截器。 ","date":"2020-07-31","objectID":"/grpc2/:5:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"grpc 添加 pprof 接口 grpc 本身是使用 http2 作为底层协议，所以它也能和 golang 的 pprof 结合提供 pprof 接口。下面给出代码： type server struct { pb.UnimplementedEchoServer } func (s *server) UnaryEcho(ctx context.Context, request *pb.EchoRequest) (*pb.EchoResponse, error) { return \u0026pb.EchoResponse{Message: request.Message}, nil } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { ctx := stream.Context() for { select { case \u003c-ctx.Done(): break default: } msg, err := stream.Recv() if errors.Is(err, io.EOF) { break } if err != nil { log.Printf(\"recv failed: %v\\\\n\", err) } if err := stream.Send(\u0026pb.EchoResponse{Message: \"reply: \" + msg.Message}); err != nil { log.Printf(\"send to client: %v\\\\n\", err) } } return nil } func main() { addr := \"127.0.0.1:50001\" // 这里可以添加服务段启动配置和各种拦截器 s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026server{}) mux := http.NewServeMux() mux.HandleFunc(\"/debug/pprof/\", pprof.Index) mux.HandleFunc(\"/debug/pprof/cmdline\", pprof.Cmdline) mux.HandleFunc(\"/debug/pprof/profile\", pprof.Profile) mux.HandleFunc(\"/debug/pprof/symbol\", pprof.Symbol) mux.HandleFunc(\"/debug/pprof/trace\", pprof.Trace) // 启动 http2 服务，golang http 启动时添加证书会自动转化为 http2 服务。 // 将 Content-Type 为 application/grpc 请求转交给 grpc 即可。 err := http.ListenAndServeTLS( addr, \"ssl/server.pem\", \"ssl/server-key.pem\", http.HandlerFunc(func(rw http.ResponseWriter, r *http.Request) { if r.ProtoMajor == 2 \u0026\u0026 strings.Contains(r.Header.Get(\"Content-Type\"), \"application/grpc\") { log.Println(\"call grpc service\") s.ServeHTTP(rw, r) } else { mux.ServeHTTP(rw, r) } })) if err != nil { log.Fatalf(\"start server at %v: %v\", addr, err) } } ","date":"2020-07-31","objectID":"/grpc2/:6:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["微服务","代码"],"content":"grpc 请求断开处理 grpc 的请求没有自己设置请求的超时时间，而是将这部分的处理交给 golang 的 context 包。通过 context 的功能实现客户端的登录超时，请求超时。服务端代码： type server struct { pb.UnimplementedEchoServer } func (s *server) BidirectionalStreamingEcho(stream pb.Echo_BidirectionalStreamingEchoServer) error { // 该函数内是 stream 的整个生命周期，该函数退出后，stream 的上下文结束 // 每个stream函数相互独立 // 服务端的 stream 不能直接发起请求终止，但可以通过提前结束该函数，停止该 stream for { in, err := stream.Recv() if err != nil { fmt.Printf(\"server: error receiving from stream: %v\\n\", err) if err == io.EOF { return nil } return err } fmt.Printf(\"echoing message %q\\n\", in.Message) stream.Send(\u0026pb.EchoResponse{Message: in.Message}) } } func main() { lis, err := net.Listen(\"tcp\", \"127.0.0.1:10050\") if err != nil { log.Fatalf(\"failed to listen: %v\", err) } fmt.Printf(\"server listening at port %v\\n\", lis.Addr()) s := grpc.NewServer() pb.RegisterEchoServer(s, \u0026server{}) s.Serve(lis) } 客户端: func sendMessage(stream pb.Echo_BidirectionalStreamingEchoClient, msg string) error { fmt.Printf(\"sending message %q\\n\", msg) return stream.Send(\u0026pb.EchoRequest{Message: msg}) } func recvMessage(stream pb.Echo_BidirectionalStreamingEchoClient, wantErrCode codes.Code) { res, err := stream.Recv() if status.Code(err) != wantErrCode { log.Fatalf(\"stream.Recv() = %v, %v; want _, status.Code(err)=%v\", res, err, wantErrCode) } if err != nil { fmt.Printf(\"stream.Recv() returned expected error %v\\n\", err) return } fmt.Printf(\"received message %q\\n\", res.Message) } func main() { addr := \"127.0.0.1:10050\" // 建立连接 // 建立连接的 ctx 和请求的 ctx 是独立的 conn, err := grpc.DialContext(context.Background(), addr, grpc.WithInsecure()) if err != nil { log.Fatalf(\"did not connect: %v\", err) } defer conn.Close() c := pb.NewEchoClient(conn) // Initiate the stream with a context that supports cancellation. ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second) stream, err := c.BidirectionalStreamingEcho(ctx) if err != nil { log.Fatalf(\"error creating stream: %v\", err) } // Send some test messages. if err := sendMessage(stream, \"hello\"); err != nil { log.Fatalf(\"error sending on stream: %v\", err) } if err := sendMessage(stream, \"world\"); err != nil { log.Fatalf(\"error sending on stream: %v\", err) } // Ensure the RPC is working. recvMessage(stream, codes.OK) recvMessage(stream, codes.OK) fmt.Println(\"cancelling context\") cancel() // This Send may or may not return an error, depending on whether the // monitored context detects cancellation before the call is made. sendMessage(stream, \"closed\") // This Recv should never succeed. recvMessage(stream, codes.Canceled) } GRPC 性能优化 虽然 grpc 的官方自诩是高性能的框架，但是 grpc 内部使用大量的反射，使得 grpc 在性能上并不算很好，所以还是有必要优化。grpc 的优化思路比较简单，不需要直接修改源码，只需要在 protoc 命令生成 golang 代码是，将 golang/protobuf 换成第三方的 gogo/protobuf 。gogo库基于官方库开发，增加了很多的功能，包括： 快速的序列化和反序列化 更规范的Go数据结构 goprotobuf兼容 可选择的产生一些辅助方法，减少使用中的代码输入 可以选择产生测试代码和benchmark代码 其它序列化格式 比如etcd、k8s、dgraph、docker swarmkit都使用它。基于速度和定制化的考虑，gogo有三种产生代码的方式 gofast: 速度优先，不支持其它gogoprotobuf extensions。 go get github.com/gogo/protobuf/protoc-gen-gofast protoc --gofast_out=. myproto.proto gogofast类似gofast,但是会导入gogoprotobuf gogofaster类似gogofast, 不会产生XXX_unrecognized指针字段，可以减少垃圾回收时间。 gogoslick类似gogofaster,但是可以增加一些额外的方法gostring和equal等等。 go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/{binary} //protoc-gen-gogofast、protoc-gen-gogofaster 、protoc-gen-gogoslick go get github.com/gogo/protobuf/gogoproto protoc -I=. -I=$GOPATH/src -I=$GOPATH/src/github.com/gogo/protobuf/protobuf --{binary}_out=. myproto.proto protoc-gen-gogo: 最快的速度，最多的可定制化 你可以通过扩展定制序列化: 扩展. go get github.com/gogo/protobuf/proto go get github.com/gogo/protobuf/jsonpb go get github.com/gogo/protobuf/protoc-gen-gogo go get github.com/gogo/protobuf/gogoproto gogo同样支持grpc: protoc --gofast_out=plugins=grpc:. my.proto。同时还有 protobuf 对应的教程 。 ","date":"2020-07-31","objectID":"/grpc2/:7:0","tags":["golang","grpc"],"title":"GPRC 进阶","uri":"/grpc2/"},{"categories":["运维"],"content":"SCST 共享的磁盘支持在线扩容。操作如下： scst 服务端 首先有一块 zfs 存储卷，现在将其容量从 15G 扩展到 20G。 zfs set volsize=20G tank/vol 修改 scst 中 device 的 size 属性 scstadmin -set_dev_attr device1 -attributes size=21474836480 -noprompt iscsi 客户端 重新扫描 target iscsiadm -m node --target \u003ctarget_name\u003e -R 扩展磁盘容量，如果磁盘存储 mount 状态则先 umount。 resize2fs /dev/sdX e2fsck -f /dev/sdX resize2fs /dev/sdX 重新挂载，使用 df 即可发现磁盘的容量被修改。 FC 客户端 重新扫描 FC host echo \"- - -\" \u003e /sys/class/scst_host/hostX/scan 扩展磁盘容量如上。 ","date":"2020-04-09","objectID":"/scst%E5%9C%A8%E7%BA%BF%E6%89%A9%E5%AE%B9/:0:0","tags":["iscsi"],"title":"Scst在线扩容","uri":"/scst%E5%9C%A8%E7%BA%BF%E6%89%A9%E5%AE%B9/"},{"categories":["运维"],"content":"安装 scst 安装 scst wget https://ncu.dl.sourceforge.net/project/scst/scst-3.2.0.7058.tar.bz2 yum install bzip2 bunzip2 scst-3.2.0.7058.tar.bz2 tar xf scst-3.2.0.7058.tar 编译安装scst make 2perf make scst make scst_install make iscsi make iscsi_install make scstadm make scstadm_install 查看是否被加载到内核了 lsmod |grep scst modinfo scst 启动 scst modprobe scst modprobe scst_vdisk modprobe scst_disk modprobe scst_user modprobe scst_modisk modprobe scst_processor modprobe scst_raid modprobe scst_tape modprobe scst_cdrom modprobe scst_changer modprobe iscsi-scst iscsi-scstd 创建流程 创建 target scstadmin -add_target iqn.1994-05.com.redhat:pv -driver iscsi 创建 block scstadmin -open_dev pv -handler vdisk_blockio -attributes filename=/dev/zvol/tank/pv 创建 group 做访问控制 scstadmin -add_group pv -driver iscsi -target iqn.1994-05.com.redhat:pv 添加客户端 scstadmin -add_init iqn.1994-05.com.redhat:48d51365d2b -driver iscsi -target iqn.1994-05.com.redhat:pv -group pv 添加 lun scstadmin -add_lun 0 -driver iscsi -target iqn.1994-05.com.redhat:pv -group pv -device pv 启用 target scstadmin -enable_target iqn.1994-05.com.redhat:pv -driver iscsi 使用 iscsi driver scstadmin -set_drv_attr iscsi -attributes enabled=1 -noprompt 写入到配置文件 scstadmin -write_config /etc/scst.conf 删除流程 禁用 target scstadmin -disable_target iqn.1994-05.com.redhat:pv -driver iscsi -noprompt 删除 target scstadmin -rem_target iqn.1994-05.com.redhat:pv -driver iscsi -noprompt 删除 block scstadmin -close_dev pv -handler vdisk_blockio -noprompt ","date":"2020-04-08","objectID":"/scst%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/:0:0","tags":["iscsi"],"title":"Scst 安装和使用","uri":"/scst%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/"},{"categories":["其他"],"content":"一、介绍 oh-my-zsh 是一款命令行工具，在zsh的基础上添加了许多的新功能。接下来就来安装并使用他。 二、安装 oh-my-zsh oh-my-zsh 是在 zsh 的基础上使用的，所以要就安装zsh。一般linux发行版默认使用bash。以下环境为CentOS7。使用 yum 安装 zsh $ yum install zsh 安装完成后，替换默认的 bash 为 zsh。需要在 root 用户下使用 $ chsh -s /bin/zsh Changing shell for root. Shell changed. # 在新终端中验证 $ echo $SHELL /bin/zsh 执行以下命令自动安装 oh-my-zsh $ wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh # 省略输出... $ source .zshrc # .zshrc 为 zsh 的配置文件 三、配置 oh-my-zsh 接下来还要添加额外的功能。oh-my-zsh 支持很多强大的功能，这些功能都是以插件的方式实现。插件放在目录~/.oh-my-zsh/plugins 下。要让插件开始工作还需要在 .zshrc 中配置相关参数。 plugins=(git textmate ruby autojump osx mvn gradle) ","date":"2020-02-09","objectID":"/%E5%AE%89%E8%A3%85oh-my-zsh/:0:0","tags":["linux","终端"],"title":"linux 安装 oh-my-zsh","uri":"/%E5%AE%89%E8%A3%85oh-my-zsh/"},{"categories":["其他"],"content":"autojump 作用目录间快速跳转,不用再一直 cd 了 😁**使用 **使用 autojump 的缩写 j``cd 命令进入 ~/user/github/Youthink 文件夹，下一次再想进入 Yourhink 文件夹的时候,直接 j youthink 即可, 或者只输入 youthink 的一部分 youth 都行删除无效路径 $ j --purge 无效路径 需要额外下载 autojump 并配置首先安装 autojump，如果你用 Mac，可以使用 brew 安装： $ brew install autojump 如果是 Linux，可以使用 git 安装，比如： $ git clone git://github.com/joelthelion/autojump.git 进入目录，执行 $ ./install.sh 最后把以下代码加入 .zshrc： [[ -s ~/.autojump/etc/profile.d/autojump.sh ]] \u0026\u0026 . ~/.autojump/etc/profile.d/autojump.sh ","date":"2020-02-09","objectID":"/%E5%AE%89%E8%A3%85oh-my-zsh/:1:0","tags":["linux","终端"],"title":"linux 安装 oh-my-zsh","uri":"/%E5%AE%89%E8%A3%85oh-my-zsh/"},{"categories":["其他"],"content":"zsh-syntax-highlighting 作用平常用的ls、cd 等命令输入正确会绿色高亮显示，输入错误会显示其他的颜色。 安装 $ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 在 ~/.zshrc 中配置 plugins=(其他的插件 zsh-syntax-highlighting) 使配置生效 source ~/.zshrc ","date":"2020-02-09","objectID":"/%E5%AE%89%E8%A3%85oh-my-zsh/:2:0","tags":["linux","终端"],"title":"linux 安装 oh-my-zsh","uri":"/%E5%AE%89%E8%A3%85oh-my-zsh/"},{"categories":["其他"],"content":"zsh-autosuggestions 作用 如图输入命令时，会给出建议的命令（灰色部分）按键盘 → 补全 如果感觉 → 补全不方便，还可以自定义补全的快捷键，比如我设置的逗号补全 bindkey ',' autosuggest-accept 在 .zshrc 文件添加这句话即可。安装 $ git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions 在 ~/.zshrc 中配置 plugins=(其他的插件 zsh-autosuggestions) 使配置生效 source ~/.zshrc ","date":"2020-02-09","objectID":"/%E5%AE%89%E8%A3%85oh-my-zsh/:3:0","tags":["linux","终端"],"title":"linux 安装 oh-my-zsh","uri":"/%E5%AE%89%E8%A3%85oh-my-zsh/"},{"categories":["笔记"],"content":" Aix为6.1版本 使用iscsi存储 首先需要创建一个iscsi target，并共享到IBM Aix上。 ","date":"2019-10-22","objectID":"/aix1/:0:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"检查iscsi是否被安装 $ lslpp -L | grep -i iscsi devices.common.IBM.iscsi.rte 6.1.5.0 C F Common iSCSI Files devices.iscsi.disk.rte 6.1.5.0 C F iSCSI Disk Software ... ","date":"2019-10-22","objectID":"/aix1/:1:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"配置iscsi $ vi /etc/iscsi/targets ... # 添加target 172.16.1.169 3260 iqn.2018-11.com.howlink.wbrt.portal.backup ","date":"2019-10-22","objectID":"/aix1/:2:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"重新扫盘 $ cfgmgr -l iscsi0 cfgmgr: 0514-621 WARNING: The following device packages are required for device support but are not currently installed. devices.iscsi.array ","date":"2019-10-22","objectID":"/aix1/:3:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"查看iscsi盘 $ lsdev -Cc disk | grep iSCSI hdisk18 Available Other iSCSI Disk Drive ","date":"2019-10-22","objectID":"/aix1/:4:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"创建物理卷 $ chdev -l hdisk18 -a pv=yes ","date":"2019-10-22","objectID":"/aix1/:5:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"创建vg $ mkvg -y wbrt_portal_bg hdisk18 ","date":"2019-10-22","objectID":"/aix1/:6:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"创建lv $ mklv -t jfs2 -y wbrt_portal_bl wbrt_portal_bg 700 注:lv的大小可以使用命令 $ lsvg wbrt_portal_bg | grep \"TOTAL PPs\" | awk -F' ' '{ print $6}' 703 但不要全部使用，需要一些剩余空间。 ","date":"2019-10-22","objectID":"/aix1/:7:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"创建挂载目录 $ mkdir /mnt/iscsi ","date":"2019-10-22","objectID":"/aix1/:8:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"格式化并挂载 $ crfs -v jfs2 -m /mnt/iscsi -d wbrt_portal_bl $ mount /mnt/iscsi 删除存储盘 ","date":"2019-10-22","objectID":"/aix1/:9:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"卸载磁盘 $ umount /mnt/iscsi ","date":"2019-10-22","objectID":"/aix1/:10:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"lv $ rmlv wbrt_portal_bl ","date":"2019-10-22","objectID":"/aix1/:11:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"删除文件系统 $ rmfs -r /dev/wbrt_portal_bl ","date":"2019-10-22","objectID":"/aix1/:12:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"删除vg $ reducevg -d wbrt_portal_bg hdisk18 ","date":"2019-10-22","objectID":"/aix1/:13:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"删除物理盘 $ rmdev -dl hdisk18 -R ","date":"2019-10-22","objectID":"/aix1/:14:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["笔记"],"content":"删除iscsi target $ vi /etc/iscsi/targets ... # 添加target # 172.16.1.169 3260 iqn.2018-11.com.howlink.wbrt.portal.backup 重读磁盘 $ cfgmgr -l iscsi0 ","date":"2019-10-22","objectID":"/aix1/:15:0","tags":["aix"],"title":"Aix添加和删除Iscsi存储卷","uri":"/aix1/"},{"categories":["云计算"],"content":"环境版本说明： 三台vmware虚拟机，系统版本CentOS7.6。 Kubernetes 1.16.0，当前最新版。 flannel v0.11 docker 18.09 使用kubeadm可以简单的搭建一套k8s集群环境，而不用关注安装部署的细节，而且现在k8s的版本更新频率很快，所以这种方法十分推荐。 相关准备 注：本节相关操作要在所有节点上执行。 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:0:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"硬件环境 使用三台vmware虚拟机，配置网络，并保证可以联网。 k8s-master 4G 4核 CentOS7 192.168.10.20 k8s-node1 2G 2核 CentOS7 192.168.10.21 k8s-node2 2G 2核 CentOS7 192.168.10.22 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:1:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"主机划分 k8s-master作为集群管理节点：etcd kubeadm kube-apiserver kube-scheduler kube-controller-manager kubelet flanneld docker k8s-node1作为工作节点：kubeadm kubelet flanneld docker k8s-node2作为工作节点：kubeadm kubelet flanneld docker ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:2:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"准备工作 安装必要的rpm软件： yum install -y wget vim net-tools epel-release 关闭防火墙 systemctl disable firewalld systemctl stop firewalld 关闭selinux # 临时禁用selinux setenforce 0 # 永久关闭 修改/etc/sysconfig/selinux文件设置 sed -i 's/SELINUX=permissive/SELINUX=disabled/' /etc/sysconfig/selinux sed -i \"s/SELINUX=enforcing/SELINUX=disabled/g\" /etc/selinux/config 禁用交换分区 swapoff -a # 永久禁用，打开/etc/fstab注释掉swap那一行。 sed -i 's/.*swap.*/#\u0026/' /etc/fstab 修改 /etc/hosts cat \u003c\u003cEOF \u003e\u003e /etc/host 192.168.10.20 k8s-master 192.168.10.21 k8s-node1 192.168.10.22 k8s-node2 EOF 修改内核参数 cat \u003c\u003cEOF \u003e /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system 安装docker18.09 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:3:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"配置yum源 ## 配置默认源 ## 备份 mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup ## 下载阿里源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo ## 刷新 yum makecache fast ## 配置k8s源 cat \u003c\u003cEOF \u003e /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 EOF ## 重建yum缓存 yum clean all yum makecache fast yum -y update ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:4:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"安装docker 下载docker的yum源文件 yum -y install yum-utils device-mapper-persistent-data lvm2 yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 这里指定docker版本，可以先查看支持的版本 [root@localhost ~]# yum list docker-ce --showduplicates |sort -r * updates: mirrors.aliyun.com Loading mirror speeds from cached hostfile Loaded plugins: fastestmirror * extras: mirrors.aliyun.com * epel: hkg.mirror.rackspace.com docker-ce.x86_64 3:19.03.2-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.1-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.0-3.el7 docker-ce-stable docker-ce.x86_64 3:18.09.9-3.el7 docker-ce-stable ... * base: mirrors.aliyun.com 目前最新版本为19.03，指定下载18.09 yum install -y docker-ce-18.09.9-3.el7 systemctl enable docker systemctl start docker ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:5:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"修改docker的启动参数 cat \u003e /etc/docker/daemon.json \u003c\u003cEOF { \"registry-mirrors\": [\"https://xxxx.mirror.aliyuncs.com\"], \"exec-opts\": [\"native.cgroupdriver=systemd\"], \"log-driver\": \"json-file\", \"log-opts\": { \"max-size\": \"100m\" }, \"storage-driver\": \"overlay2\", \"storage-opts\": [ \"overlay2.override_kernel_check=true\" ] } EOF systemctl restart docker 安装k8s ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:6:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"管理节点配置 先在k8s-master上安装管理节点 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:7:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"下载kubeadm，kubelet yum install -y kubeadm kubelet ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:7:1","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"初始化kubeadm 这里不直接初始化，因为国内用户不能直接拉取相关的镜像，所以这里想查看需要的镜像版本 [root@k8s-master ~]# kubeadm config images list k8s.gcr.io/kube-apiserver:v1.16.0 k8s.gcr.io/kube-controller-manager:v1.16.0 k8s.gcr.io/kube-scheduler:v1.16.0 k8s.gcr.io/kube-proxy:v1.16.0 k8s.gcr.io/pause:3.1 k8s.gcr.io/etcd:3.3.15-0 k8s.gcr.io/coredns:1.6.2 根据需要的版本，直接拉取国内镜像，并修改tag # vim kubeadm.sh #!/bin/bash ## 使用如下脚本下载国内镜像，并修改tag为google的tag set -e KUBE_VERSION=v1.16.0 KUBE_PAUSE_VERSION=3.1 ETCD_VERSION=3.3.15-0 CORE_DNS_VERSION=1.6.2 GCR_URL=k8s.gcr.io ALIYUN_URL=registry.cn-hangzhou.aliyuncs.com/google_containers images=(kube-proxy:${KUBE_VERSION} kube-scheduler:${KUBE_VERSION} kube-controller-manager:${KUBE_VERSION} kube-apiserver:${KUBE_VERSION} pause:${KUBE_PAUSE_VERSION} etcd:${ETCD_VERSION} coredns:${CORE_DNS_VERSION}) for imageName in ${images[@]} ; do docker pull $ALIYUN_URL/$imageName docker tag $ALIYUN_URL/$imageName $GCR_URL/$imageName docker rmi $ALIYUN_URL/$imageName done 运行脚本，拉取镜像 sh ./kubeadm.sh master节点执行 sudo kubeadm init \\ --apiserver-advertise-address 192.168.10.20 \\ --kubernetes-version=v1.16.0 \\ --pod-network-cidr=10.244.0.0/16 注：这里的pod-network-cidr，最好不要改动，和以下的步骤是关联的。 结果返回 ... ... mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config ... ## 添加节点需要执行以下命令，可以使用命令 kubeadm token create --print-join-command 来获取 kubeadm join 192.168.10.20:6443 --token lixsl8.v1auqmf91ty0xl0k \\ --discovery-token-ca-cert-hash sha256:c3f92a6ed9149ead327342f48a545e7e127a455d5b338129feac85893d918a55 如果是要安装多个master节点，则初始化命令使用 kubeadm init --apiserver-advertise-address 192.168.10.20 --control-plane-endpoint 192.168.10.20 --kubernetes-version=v1.16.0 --pod-network-cidr=10.244.0.0/16 --upload-certs 添加master节点使用命令: kubeadm join 192.168.10.20:6443 --token z34zii.ur84appk8h9r3yik --discovery-token-ca-cert-hash sha256:dae426820f2c6073763a3697abeb14d8418c9268288e37b8fc25674153702801 --control-plane --certificate-key 1b9b0f1fdc0959a9decef7d812a2f606faf69ca44ca24d2e557b3ea81f415afe 注：这里的token会不同，不要直接复制。kubeadm init成功后会输出添加master节点的命令 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:7:2","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"工作节点配置 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:8:0","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"下载kubeadm kubelet 三台节点都要运行 yum install -y kubeadm kubelet ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:8:1","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"添加节点 三台节点都要运行，这里先忽略错误 kubeadm join 192.168.10.20:6443 --token lixsl8.v1auqmf91ty0xl0k \\ --discovery-token-ca-cert-hash sha256:c3f92a6ed9149ead327342f48a545e7e127a455d5b338129feac85893d918a55 \\ --ignore-preflight-errors=all 如果添加节点失败，或是想重新添加，可以使用命令 kubeadm reset 注：不要在轻易master上使用，它会删除所有kubeadm配置 这时在节点上就可以使用命令查看添加的节点信息了 [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master NotReady master 45m v1.16.0 k8s-node1 NotReady \u003cnone\u003e 26s v1.16.0 k8s-node2 NotReady \u003cnone\u003e 12s v1.16.0 但节点的状态就是 NotReady，还需要一些操作 ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:8:2","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"安装flanneld 在master上操作，拷贝配置，令kubectl可用 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 下载flannel配置文件 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml 因为kube-flannel.yml文件中使用的镜像为quay.io的，国内无法拉取，所以同样的先从国内源上下载，再修改tag，脚本如下 # vim flanneld.sh #!/bin/bash set -e FLANNEL_VERSION=v0.11.0 # 在这里修改源 QUAY_URL=quay.io/coreos QINIU_URL=quay-mirror.qiniu.com/coreos images=(flannel:${FLANNEL_VERSION}-amd64 flannel:${FLANNEL_VERSION}-arm64 flannel:${FLANNEL_VERSION}-arm flannel:${FLANNEL_VERSION}-ppc64le flannel:${FLANNEL_VERSION}-s390x) for imageName in ${images[@]} ; do docker pull $QINIU_URL/$imageName docker tag $QINIU_URL/$imageName $QUAY_URL/$imageName docker rmi $QINIU_URL/$imageName done 运行脚本，这个脚本需要在每个节点上执行 sh flanneld.sh 安装flanneld kubectl apply -f kube-flanneld.yaml flanneld默认安装在kube-system Namespace中，使用以下命令查看: # kubectl -n kube-system get pods NAME READY STATUS RESTARTS AGE coredns-5644d7b6d9-h9bxt 0/1 Pending 0 57m coredns-5644d7b6d9-pkhls 0/1 Pending 0 57m etcd-k8s-master 1/1 Running 0 57m kube-apiserver-k8s-master 1/1 Running 0 57m kube-controller-manager-k8s-master 1/1 Running 0 57m kube-flannel-ds-amd64-c4hnf 1/1 Running 1 38s kube-flannel-ds-amd64-djzmx 1/1 Running 0 38s kube-flannel-ds-amd64-mdg8b 1/1 Running 1 38s kube-flannel-ds-amd64-tjxql 0/1 Terminating 0 5m34s kube-proxy-4n5dr 0/1 ErrImagePull 0 13m kube-proxy-dc68d 1/1 Running 0 57m kube-proxy-zplgt 0/1 ErrImagePull 0 13m kube-scheduler-k8s-master 1/1 Running 0 57m 出现错误，原因是两个工作节点不能拉取pause和kube-proxy镜像，可以直接从master上打包，在node上使用 ## master上执行 docker save -o pause.tar k8s.gcr.io/pause:3.1 docker save -o kube-proxy.tar k8s.gcr.io/kube-proxy ## node上执行 docker load -i pause.tar docker load -i kube-proxy.tar 重新安装flanneld kubectl delete -f kube-flannel.yml kubectl create -f kube-flannel.yml ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:8:3","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["云计算"],"content":"修改kubelet 使用kubeadm添加node后，节点一直处于NotReady状态，报错信息为： runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized Addresses: 解决方式是修改/var/lib/kubelet/kubeadm-flags.env文件，删除参数 --network-plugin=cni cat \u003c\u003c EOF \u003e /var/lib/kubelet/kubeadm-flags.env KUBELET_KUBEADM_ARGS=\"--cgroup-driver=systemd --pod-infra-container-image=k8s.gcr.io/pause:3.1\" EOF systemctl restart kubelet [root@k8s-master ~]# kubectl get nodes NAME STATUS ROLES AGE VERSION k8s-master Ready master 79m v1.16.0 k8s-node1 Ready \u003cnone\u003e 34m v1.16.0 k8s-node2 Ready \u003cnone\u003e 34m v1.16.0 错误解决 关于错误cni config uninitialized Addresses，这里之前是直接删除参数--network-plugin=cni，但这样只能让节点状态修改为 ready，但是在Pod之间网络依然不可用。 正确的解决方法：修改kube-flannel.yaml，在111行添加参数cniVersion： vim kube-flanneld.yaml { \"name\": \"cbr0\", \"cniVersion\": \"0.3.1\", .... 安装flannel ## 如果之前安装了，先删除 ## kubectl delete -f kube-flannel.yaml kubectl apply -f kube-flannel.yaml ","date":"2019-10-19","objectID":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/:8:4","tags":["k8s"],"title":"使用kubeadm安装kubernetes1.16","uri":"/%E4%BD%BF%E7%94%A8kubeadm%E5%AE%89%E8%A3%85kubernetes1.16/"},{"categories":["分布式"],"content":"etcd 有如下的使用场景： 服务发现（Service Discovery） 消息发布与订阅 负载均衡 分布式通知与协调 分布式锁 分布式队列 集群监控于Leader竞选。 一、服务发现 etcd 的常见使用场景之一就是服务发现。实现思路如下：先准备 etcd 服务端，服务端的程序在第一次启动之后会连接到 etcd 服务器并设置一个格式为 ip:port 的键值对，并绑定一个 lease。之后的服务端内部维护一个定时器，每隔一段时间就更新服务端注册中心的 lease 的 TTL。另外一个组件就是服务发现组件，discovery 会 watch 服务端的 key。每次该 key 变化时，discovery 就可以检测到时间并做出对应的操作。代码的实现如下： // server.go package main import ( \"context\" \"crypto/md5\" \"encoding/json\" \"errors\" \"flag\" \"fmt\" \"github.com/coreos/etcd/clientv3\" \"github.com/coreos/etcd/etcdserver/api/v3rpc/rpctypes\" \"log\" \"net\" \"os\" \"os/signal\" \"strings\" \"syscall\" \"time\" ) var ( prefix = \"register\" client *clientv3.Client stopSignal = make(chan struct{}, 1) srvKey string ) var ( serv = flag.String(\"name\", \"hello\", \"service name\") port = flag.Int(\"port\", 30000, \"service port\") endpoint = flag.String(\"endpoints\", \"http://127.0.0.1:2379\", \"etcd endpoints\") ) type SvConfig struct { Name string `json:\"name\"` Host string `json:\"host\"` Port int `json:\"port\"` } func Register(endpoints string, config *SvConfig, interval time.Duration, ttl int) error { // 解析服务端的值 srvValue, _ := json.Marshal(config) srvKey = fmt.Sprintf(\"%s/%x\", prefix, md5.Sum(srvValue)) var err error client, err = clientv3.New(clientv3.Config{ Endpoints: strings.Split(endpoints, \",\"), DialTimeout: time.Second * 2, }) if err != nil { return fmt.Errorf(\"register service failed: %v\", err) } go func() { timer := time.NewTicker(interval) for { resp, _ := client.Grant(context.TODO(), int64(ttl)) _, err = client.Get(context.TODO(), srvKey) if err != nil { // 捕获 key 不存在的场合 if errors.Is(err, rpctypes.ErrKeyNotFound) { _, err = client.Put(context.TODO(), srvKey, string(srvValue), clientv3.WithLease(resp.ID)) if err != nil { log.Printf(\"register service %s at %s:%d\\n\", config.Name, config.Host, config.Port) } } } else { // 如果key存在就更新ttl _, err = client.Put(context.TODO(), srvKey, string(srvValue), clientv3.WithLease(resp.ID)) } select { case \u003c-stopSignal: return case \u003c-timer.C: } } }() return err } func Unregister() error { stopSignal \u003c- struct{}{} stopSignal = make(chan struct{}, 1) _, err := client.Delete(context.TODO(), srvKey) return err } func main() { flag.Parse() // 绑定服务地址和端口 lis, err := net.Listen(\"tcp\", fmt.Sprintf(\"127.0.0.1:%d\", *port)) if err != nil { panic(err) } config := \u0026SvConfig{ Name: *serv, Host: \"127.0.0.1\", Port: *port, } Register(*endpoint, config, time.Second*10, 15) ch := make(chan os.Signal, 1) signal.Notify(ch, syscall.SIGTERM, syscall.SIGINT, syscall.SIGKILL, syscall.SIGHUP, syscall.SIGQUIT) go func() { \u003c-ch Unregister() os.Exit(1) }() log.Printf(\"service %s start at %d\", *serv, *port) // server todo for { lis.Accept() } } // discovery.go package main import ( \"context\" \"encoding/json\" \"flag\" \"fmt\" \"github.com/coreos/etcd/clientv3\" \"log\" \"net\" \"os\" \"os/signal\" \"strings\" \"syscall\" \"time\" ) var ( prefix = \"register\" client *clientv3.Client ) var ( port = flag.Int(\"port\", 30001, \"service port\") endpoint = flag.String(\"endpoints\", \"http://127.0.0.1:2379\", \"etcd endpoints\") ) type SvConfig struct { Name string `json:\"name\"` Host string `json:\"host\"` Port int `json:\"port\"` } func watcher() error { var err error client, err = clientv3.New(clientv3.Config{ Endpoints: strings.Split(*endpoint, \",\"), DialTimeout: time.Second * 3, }) if err != nil { return fmt.Errorf(\"connect etcd cluster failed: %v\", err.Error()) } go func() { resp := client.Watch(context.TODO(), prefix, clientv3.WithPrefix()) for ch := range resp { for _, event := range ch.Events { switch event.Type { case clientv3.EventTypePut: if event.IsCreate() { srv := parseSrv(event.Kv.Value) log.Printf(\"discovery service %s at %s:%d\", srv.Name, srv.Host, srv.Port) } case clientv3.EventTypeDelete: log.Printf(\"delete service %s\", event.Kv.Key) } } } }() return err } func parseSrv(text []byte) *SvConfig { svc := \u0026SvConfig{} json.Unmarshal(text, \u0026svc) return svc } func main() { flag.Parse() // 绑定服务地址和端口 lis, err := net.Listen(\"tcp\", fmt.Sprintf(\"127.0.0.1:%d\", *port)) if err != nil { panic(err) } ch := make(chan os","date":"2019-09-11","objectID":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/:0:0","tags":["golang","etcd"],"title":"etcd的使用实例","uri":"/etcd%E7%9A%84%E4%BD%BF%E7%94%A8%E5%AE%9E%E4%BE%8B/"},{"categories":["分布式","代码"],"content":"关于 etcd 的安装和介绍看 这里 。官方的实例可以看 这里 一、连接 首先是关于 golang 如何连接 etcd ，先是简单的连接。 package main import ( \"github.com/coreos/etcd/clientv3\" \"log\" \"time\" ) func connect() { cli, err := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) if err != nil { log.Fatal(\"connect etcd cluster: \" + err.Error()) } cli.Close() } 还有带 https 和 开启用户验证的连接 func connectTlsAuth() { tlsInfo := transport.TLSInfo{ CertFile: \"/tmp/cert.pem\", KeyFile: \"/tmp/key.pem\", TrustedCAFile: \"/tmp/ca.pem\", } tlsConfig, err := tlsInfo.ClientConfig() if err != nil { log.Fatal(\"parse tls config file: \" + err.Error()) } cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, DialTimeout: time.Second * 3, TLS: tlsConfig, Username: \"root\", Password: \"root\", }) if err != nil { log.Fatal(\"connect etcd cluster: \" + err.Error()) } cli.Close() } 二、KV 操作 ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:0:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.1 简单的 curd 在连接基础上，接下来就可以对key做操作了。对key做 curd func kv() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() // etcdctl put foo 1 _, err := cli.Put(ctx, \"foo\", \"1\") if err != nil { log.Fatal(\"put key:\" + err.Error()) } // etcdctl get foo --prefix // 带参数的请求 resp, err := cli.Get(ctx, \"foo\", clientv3.WithPrefix()) if err != nil { log.Fatal(\"get key: \" + err.Error()) } for _, v := range resp.Kvs { log.Printf(\"get %s =\u003e %s\\n\", v.Key, string(v.Value)) } kvcli := clientv3.NewKV(cli) // etcdctl del foo _, err = kvcli.Delete(ctx, \"foo\") if err != nil { log.Fatal(\"delete key: \" + err.Error()) } } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:1:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.2 事务 使用事务如下： func txn() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() kvc := clientv3.NewKV(cli) _, err := kvc.Put(ctx, \"foo\", \"xyz\") if err != nil { log.Fatal(\"put key: \" + err.Error()) } _, err = kvc.Txn(ctx). // txn value comparisons are lexical If(clientv3.Compare(clientv3.Value(\"foo\"), \"\u003e\", \"abc\")). // the \"Then\" runs, since \"xyz\" \u003e \"abc\" Then(clientv3.OpPut(\"foo\", \"XYZ\")). // the \"Else\" does not run Else(clientv3.OpPut(\"foo\", \"ABC\")). Commit() if err != nil { log.Fatal(\"run txn: \" + err.Error()) } } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:2:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.3 批量操作 批量指定操作 func do() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() ops := []clientv3.Op{ clientv3.OpPut(\"key1\", \"123\"), clientv3.OpGet(\"key1\"), clientv3.OpPut(\"key2\", \"456\"), } for _, op := range ops { if _, err := cli.Do(ctx, op); err != nil { log.Fatal(err.Error()) } } } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:3:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.3 watch 监视key func watch() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() go func() { timer := time.NewTicker(time.Second) for { select { case \u003c-timer.C: // change foo value every second _, _ = cli.Put(context.TODO(), \"foo\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo1\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo2\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo3\", time.Now().String()) _, _ = cli.Put(context.TODO(), \"foo4\", time.Now().String()) } } }() //rch := cli.Watch(ctx, \"foo\") rch := cli.Watch(ctx, \"foo\", clientv3.WithPrefix()) //rch := cli.Watch(ctx, \"foo\", clientv3.WithRange(\"foo4\")) for wresp := range rch { for _, ev := range wresp.Events { fmt.Printf(\"%s %q: %q\\n\", ev.Type, ev.Kv.Key, ev.Kv.Value) } } } func watchWithProcessNotify() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() rch := cli.Watch(ctx, \"foo\", clientv3.WithProgressNotify()) wresp := \u003c- rch fmt.Printf(\"wresp.Header.Revision: %d\\n\", wresp.Header.Revision) fmt.Println(\"wresp.IsProgressNotify:\", wresp.IsProgressNotify()) } 三、lease ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:4:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.1 创建 lease func grant() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() // etcdctl lease grant 5 // grant lease 5s resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } // after 5 seconds, the key 'foo' will be removed _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(\"put key with lease: \" + err.Error()) } } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:5:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.2 删除 lease func revoke() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err) } // revoking lease expires the key attached to its lease ID _, err = cli.Revoke(ctx, resp.ID) if err != nil { log.Fatal(err) } } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:6:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.3 续租 func keepAlive() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() resp, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Put(ctx, \"foo\", \"bar\", clientv3.WithLease(resp.ID)) if err != nil { log.Fatal(err) } ch, err := cli.KeepAlive(ctx, resp.ID) if err != nil { log.Fatal(err.Error()) } ka := \u003c- ch fmt.Println(\"ttl:\", ka.TTL) // 官方提示：多数情况下使用 KeepAlive 来代替 KeepAliveOnce kaa, err := cli.KeepAliveOnce(ctx, resp.ID) if err != nil { log.Fatal(err) } fmt.Println(\"ttl:\", kaa.TTL) } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:7:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"2.4 查询 lease func leases() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() _, err := cli.Grant(ctx, 5) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Grant(ctx, 10) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } _, err = cli.Grant(ctx, 15) if err != nil { log.Fatal(\"grant lease: \" + err.Error()) } resp, err := cli.Lease.Leases(ctx) if err != nil { log.Fatal(err) } for _, lease := range resp.Leases { ttl, err := cli.Lease.TimeToLive(ctx, lease.ID, clientv3.WithAttachedKeys()) if err == nil { fmt.Printf(\"lease: %d, ttl: %d, grantedTTL: %d\\n\", ttl.ID, ttl.TTL, ttl.GrantedTTL) } } } 四、访问控制 func auth() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() auth := clientv3.NewAuth(cli) // create role if _, err := auth.RoleAdd(ctx, \"root\"); err != nil { log.Fatal(err) } // create role if _, err := auth.UserAdd(ctx, \"root\", \"123\"); err != nil { log.Fatal(err) } // grant role root to user root if _, err := auth.UserGrantRole(ctx, \"root\", \"root\"); err != nil { log.Fatal(err) } if _, err := auth.UserChangePassword(ctx, \"root\", \"123\"); err != nil { log.Fatal(err) } if _, err := auth.RoleAdd(ctx, \"guest\"); err != nil { log.Fatal(err) } if _, err := auth.UserAdd(ctx, \"xingyys\", \"\"); err != nil { log.Fatal(err) } if _, err := auth.UserGrantRole(ctx, \"xingyys\", \"guest\"); err != nil { log.Fatal(err) } // 不知道为什么，需要在grant后更新密码 // 否则密码无效 if _, err := auth.UserChangePassword(ctx, \"xingyys\", \"123\"); err != nil { log.Fatal(err) } // 添加指定key的访问权限 // read, write, readwrite if _, err := auth.RoleGrantPermission(ctx, \"guest\", \"foo\", \"zoo\", clientv3.PermissionType(clientv3.PermReadWrite)); err != nil { log.Fatal(err) } if _, err := auth.AuthEnable(ctx); err != nil { log.Fatal(err) } authCli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, Username: \"xingyys\", Password: \"123\", }) defer authCli.Close() _, _ = authCli.Put(ctx, \"foo\", \"1\") resp, _ := authCli.Get(ctx, \"foo\") for _, v := range resp.Kvs { log.Printf(\"%s =\u003e %q\\n\", v.Key, v.Value) } _, err := authCli.Txn(ctx). If(clientv3.Compare(clientv3.Value(\"zoo1\"), \"\u003e\", \"abc\")). Then(clientv3.OpPut(\"zoo1\", \"XYZ\")). Else(clientv3.OpPut(\"zoo1\", \"ABC\")). Commit() log.Println(err) } 五、集群 func member() { cli, _ := clientv3.New(clientv3.Config{ // etcd 集群的地址集合 Endpoints: []string{\"192.168.10.10:2379\"}, // 请求超时时间 DialTimeout: time.Second * 3, }) defer cli.Close() ctx, cancel := context.WithCancel(context.Background()) defer cancel() cluster := clientv3.NewCluster(cli) resp, err := cluster.MemberList(ctx) if err != nil { log.Fatal(err) } for _, member := range resp.Members { fmt.Printf(\"ID: %d | Name: %s | ClientURL: %q | PeerURL: %q\\n\", member.ID, member.Name, member.ClientURLs, member.PeerURLs) } //_, _ = cluster.MemberAdd(ctx, []string{\"192.168.10.10:2370\", \"192.168.10.11:2379\"}) //_, _ = cluster.MemberRemove(ctx, // id) //_, _ = cluster.MemberUpdate(ctx, // id, // peer) } 六、并发 ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:8:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"6.1 锁 func lock() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, }) if err != nil { log.Fatal(err) } defer cli.Close() // 注册session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/lock\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/lock\") // acquired lock for s1 if err := m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s1\") m2Locked := make(chan struct{}) go func() { defer close(m2Locked) // wait util s1 is locks /lock if err := m2.Lock(context.TODO()); err != nil { log.Fatal(err) } }() if err := m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"release lock for s1\") \u003c-m2Locked fmt.Println(\"acquired lock for s2\") } func tryLock() { cli, err := clientv3.New(clientv3.Config{ Endpoints: []string{\"192.168.10.10:2379\"}, }) if err != nil { log.Fatal(err) } defer cli.Close() // 注册session s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() m1 := concurrency.NewMutex(s1, \"/lock\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() m2 := concurrency.NewMutex(s2, \"/lock\") // acquire lock for s1 if err = m1.Lock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s1\") if err = m2.TryLock(context.TODO()); err == nil { log.Fatal(\"should not acquire lock\") } if err == concurrency.ErrLocked { fmt.Println(\"cannot acquire lock for s2, as already locked in another session\") } if err = m1.Unlock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"released lock for s1\") if err = m2.TryLock(context.TODO()); err != nil { log.Fatal(err) } fmt.Println(\"acquired lock for s2\") } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:9:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"6.2 领导选举 func election() { cli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"192.168.10.10:2379\"}}) if err != nil { log.Fatal(err) } defer cli.Close() // create two separate sessions for election competition s1, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s1.Close() e1 := concurrency.NewElection(s1, \"/my-election/\") s2, err := concurrency.NewSession(cli) if err != nil { log.Fatal(err) } defer s2.Close() e2 := concurrency.NewElection(s2, \"/my-election/\") // create competing candidates, with e1 initially losing to e2 var wg sync.WaitGroup wg.Add(2) electc := make(chan *concurrency.Election, 2) go func() { defer wg.Done() // delay candidacy so e2 wins first time.Sleep(3 * time.Second) if err := e1.Campaign(context.Background(), \"e1\"); err != nil { log.Fatal(err) } electc \u003c- e1 }() go func() { defer wg.Done() if err := e2.Campaign(context.Background(), \"e2\"); err != nil { log.Fatal(err) } electc \u003c- e2 }() cctx, cancel := context.WithCancel(context.TODO()) defer cancel() e := \u003c-electc fmt.Println(\"completed first election with\", string((\u003c-e.Observe(cctx)).Kvs[0].Value)) // resign so next candidate can be elected if err := e.Resign(context.TODO()); err != nil { log.Fatal(err) } e = \u003c-electc fmt.Println(\"completed second election with\", string((\u003c-e.Observe(cctx)).Kvs[0].Value)) wg.Wait() } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:10:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["分布式","代码"],"content":"6.3 软件事务内存 func stm() { cli, err := clientv3.New(clientv3.Config{Endpoints: []string{\"192.168.10.10:2379\"}}) if err != nil { log.Fatal(err) } defer cli.Close() // set up \"accounts\" totalAccounts := 5 for i := 0; i \u003c totalAccounts; i++ { k := fmt.Sprintf(\"accts/%d\", i) if _, err = cli.Put(context.TODO(), k, \"100\"); err != nil { log.Fatal(err) } } exchange := func(stm concurrency.STM) error { from, to := rand.Intn(totalAccounts), rand.Intn(totalAccounts) if from == to { // nothing to do return nil } // read values fromK, toK := fmt.Sprintf(\"accts/%d\", from), fmt.Sprintf(\"accts/%d\", to) fromV, toV := stm.Get(fromK), stm.Get(toK) fromInt, toInt := 0, 0 fmt.Sscanf(fromV, \"%d\", \u0026fromInt) fmt.Sscanf(toV, \"%d\", \u0026toInt) // transfer amount xfer := fromInt / 2 fromInt, toInt = fromInt-xfer, toInt+xfer // write back stm.Put(fromK, fmt.Sprintf(\"%d\", fromInt)) stm.Put(toK, fmt.Sprintf(\"%d\", toInt)) return nil } // concurrently exchange values between accounts var wg sync.WaitGroup wg.Add(10) for i := 0; i \u003c 10; i++ { go func() { defer wg.Done() if _, serr := concurrency.NewSTM(cli, exchange); serr != nil { log.Fatal(serr) } }() } wg.Wait() // confirm account sum matches sum from beginning. sum := 0 accts, err := cli.Get(context.TODO(), \"accts/\", clientv3.WithPrefix()) if err != nil { log.Fatal(err) } for _, kv := range accts.Kvs { v := 0 fmt.Sscanf(string(kv.Value), \"%d\", \u0026v) sum += v } fmt.Println(\"account sum is\", sum) } ","date":"2019-09-10","objectID":"/go%E7%BB%93%E5%90%88etcd/:11:0","tags":["golang","etcd"],"title":"Go 结合 etcd","uri":"/go%E7%BB%93%E5%90%88etcd/"},{"categories":["数据库"],"content":"查看是否开启闪回 SQL\u003eselectflashback_onfromv$database;FLASHBACK_ON------------------ NO 查看是否配置了db_recover_file_dest SQL\u003eshowparameterdb_recoveryNAMETYPEVALUE------------------------------------ ----------- ------------------------------ db_recovery_file_deststringdb_recovery_file_dest_sizebiginteger0 没有配置的话，先创建对应的目录，注意目录的权限和oracle数据库的一致 mkdir /u01/flashback chown oracle:oinstall /u01/flashback SQL\u003ealtersystemsetdb_recovery_file_dest_size=30Gscope=both;SQL\u003ealtersystemsetdb_recovery_file_dest='/u01/flashback'scope=both;Systemaltered. 关闭 oracle SQL\u003eshutdownimmediate;Databaseclosed.Databasedismounted.ORACLEinstanceshutdown. 启动到 mount 状态 SQL\u003estartupmount;ORACLEinstancestarted.TotalSystemGlobalArea1603411968bytesFixedSize2253664bytesVariableSize905972896bytesDatabaseBuffers687865856bytesRedoBuffers7319552bytesDatabasemounted. 开启 archeve log SQL\u003ealterdatabasearchivelog;Databasealtered. 开启闪回功能 SQL\u003ealterdatabaseflashbackon;Databasealtered. 启动数据库到 open 状态 SQL\u003ealterdatabaseopen;Databasealtered. SQL\u003eselectflashback_onfromv$database;FLASHBACK_ON------------------ YES ","date":"2019-08-21","objectID":"/%E5%BC%80%E5%90%AForacle%E7%9A%84%E9%97%AA%E5%9B%9E%E5%8A%9F%E8%83%BD/:0:0","tags":["oracle"],"title":"开启oracle的闪回功能","uri":"/%E5%BC%80%E5%90%AForacle%E7%9A%84%E9%97%AA%E5%9B%9E%E5%8A%9F%E8%83%BD/"},{"categories":["笔记"],"content":"最近在学习Java语言，从而也学习了SpringFramework 这个大名鼎鼎的框架。从而做一些的记录。 题外话: 学习过几种不同的语言，后来知道所有的编程语言里所有的概念翻来覆去都是一样的事物，只是它们被不同的术语所描述，加上大部分中文翻译，又扯上一些专有名词，让一些本来简单的概念变得复杂而深奥。不知是因人的有限，还是那些书籍的作者有意为之，其实很多的东西本来都是很简单了，这些奇怪的名词反而让初学者糊涂起来。如果有刚开始学习编程的同学看到这里，也请注意了，不要被一些概念和名字带偏了，究其本质，也就那样。 Spring 基本概念 其实编程语言和框架的发展都是为了实际使用而来的，既然是使用，怎么使用，怎么简单的使用，怎么用更舒服就成为了其发展的主要动力了。Java框架的发展也是如此，所以spring代替了Java EE，再到后来 Spring Boot 的热门，皆是如此。因此框架的作者就会想法设法简化一些不必要和繁琐的东西。而 Spring 的核心思想就是：简化 Java 开发。 为了达到这个目的，就有了以下的四个策略： 基于POJO的轻量级和最小入侵性编程 通过依赖注入和面向接口实现松耦合 基于切面的惯例进行声明式编程 通过切面和模板减少样板式代码 ","date":"2019-08-19","objectID":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/:0:0","tags":["java","spring"],"title":"Spring框架的核心总结","uri":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/"},{"categories":["笔记"],"content":"POJO 这个名称就是符合上面提到的问题。POJO (Plain Old Java Object) …… 其实就是个普通Java 类，没有其他的东西了，只不过是作者为了应付那些反对叫嚣的人而扯出来的花里胡哨的名称。 因为作者的意图就是不让框架本身的API干扰到业务代码中一些定义的类，这样可以尽量是业务的代码更加干净，耦合度低，容易修改和测试，也就是所以的“最小入侵性”。但是绝对的干净还是做不到的，所以一般的业务代码上就常常出现了注解。 ","date":"2019-08-19","objectID":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/:1:0","tags":["java","spring"],"title":"Spring框架的核心总结","uri":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/"},{"categories":["笔记"],"content":"依赖注入和控制反转 又是看起来就 高大上 的词汇。依赖注入(dependency injection)和控制反转(inversion of control) 这两者其实就是同一个东西，只是它们的表述不同而已。因为一般的应用中，要完成一个实际的功能，基本不可能只有一个类，而是多个类同时使用，使用中就会互相影响。用一个例子来说明吧，我们做一个功能，需要A类和B类，现在需要用A类创建B，修改B，删除B，A是依赖B的，但是做的功能只是输入B的信息而已，这样太麻烦了，而且它们之间联系太多，如果B需要修改，那A也就要修改。所以在 spring 中，A如果需要B，它不是直接创建B，而是找 spring，这就是将 B 的控制给了 spring， 实现控制反转。对spring 来说，当A需要B时，它为A提供，这就是依赖注入，看！只是表述不同而已。 spring 的出现，解耦和不同类之间的依赖，谁需要谁，都需要找 spring了。 ","date":"2019-08-19","objectID":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/:2:0","tags":["java","spring"],"title":"Spring框架的核心总结","uri":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/"},{"categories":["笔记"],"content":"AOP 又是 spring 的核心概念。 AOP (aspect-oriented programming) 面向切面编程……，面向…..编程 这类又容易让人混乱，其实就是它们的关注点不同而已。程序员写代码的思想，或者习惯。 面向过程编程: 我就看实现一个功能需要什么步骤，然后用代码表示出这些步骤就好了，我不管代码的重用，耦合性问题。关注点是 步骤、过程。 面向对象编程: 我需要实现该功能，但是我需要考虑到流程的结构，代码重用，耦合问题。我需要先建立一个对象，对这个对象实例化实现功能。关注点是 对象。 面向切面编程: 这个是在 spring 里第一次见到的，它关注于应用中的 核心业务 模块，而设法将一些次要的，辅助的功能统一管理，如日志、安全、验证等。 spring Bean 而在 spring 中实现了 ioc 的就是这个 bean。它是spring中的容器，用来管理构成应用的组件和业务代码类。它是spring的核心。 ","date":"2019-08-19","objectID":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/:3:0","tags":["java","spring"],"title":"Spring框架的核心总结","uri":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/"},{"categories":["笔记"],"content":"Bean的创建 创建 Bean 有三种不同的方式： 使用 xml 配置文件创建 使用 java 注解创建 使用 java Config 创建 ","date":"2019-08-19","objectID":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/:4:0","tags":["java","spring"],"title":"Spring框架的核心总结","uri":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/"},{"categories":["笔记"],"content":"Bean 的生命周期 具体过程为： Spring 对 bean 进行实例化 Spring 将值和 bean 的引用注入到 bean 对应的属性中 如果 bean 实现了 BeanNameAware 接口， Spring 将 bean 的 ID 传递给 setBeanName() 方法 如果 bean 实现了BeanFactoryAware接口， Spring 将调用 setBeanFactory() 方法，将 BeanFactory 容器实例传入 如果 bean 实现了ApplicationContextAware接口， Spring 将调用 setApplicationContext() 方法，将 bean 所在的应用上下文引用传进来 如果 bean 实现了BeanPostProcesser接口， Spring 将调用它们的 postProcessBeforeInitialization() 方法 如果 bean 实现了InitializationBean 接口，Spring 将调用它们的 afterPropertiesSet() 方法。类似地，如果 bean 使用 init-method 声明了初始化方法，该方法也会被调用 如果 bean 实现了BeanPostProcessor接口，Spring 将调用它们的 postProcessAfterInitialization() 方法 此时，bean 已经准备就绪，可以被应用程序使用了，它们将一直驻留在应用上下文中，直到该应用上下文被销毁 如果 bean 实现了 DisposableBean 接口，Spring 将调用它们的 destroy() 接口方法。同样，如果 bean 使用 destroy-method 声明了销毁方法，该方法也会被调用 ","date":"2019-08-19","objectID":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/:5:0","tags":["java","spring"],"title":"Spring框架的核心总结","uri":"/spring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%A0%B8%E5%BF%83%E6%80%BB%E7%BB%93/"},{"categories":["微服务"],"content":"在spring cloud 2.x以后,由于zuul一直停滞在1.x版本,所以spring官方就自己开发了一个项目 Spring Cloud Gateway.作为spring cloud微服务的网关组件. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA spring cloud gateway 入门 根据官方的简介,它是spring mvc基础之上,旨在提供一个简单有效的路由管理方式,如 安全，监控/指标，和限流等. ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"相关概念 Route（路由）：这是网关的基本构建部分。它由一个 ID，一个目标 URI，一组断言和一组过滤器定义。如果断言为真，则路由匹配。 Predicate（断言）：这是一个 Java 8 的 Predicate。输入类型是一个 ServerWebExchange。我们可以使用它来匹配来自 HTTP 请求的任何内容，例如 headers 或参数。 Filter（过滤器）：这是org.springframework.cloud.gateway.filter.GatewayFilter的实例，我们可以使用它修改请求和响应。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"工作流程 客户端向 Spring Cloud Gateway 发出请求。如果 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。 Spring Cloud Gateway 的特征： 基于 Spring Framework 5，Project Reactor 和 Spring Boot 2.0 动态路由 Predicates 和 Filters 作用于特定路由 集成 Hystrix 断路器 集成 Spring Cloud DiscoveryClient 易于编写的 Predicates 和 Filters 限流 路径重写 注: 以上引自: http://www.ityouknow.com ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"简单使用 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"添加依赖 \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-gateway\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:3:1","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"配置文件 spring cloud gateway底层使用netty+webflux, 不再依赖web了 server: port: 8080 spring: cloud: gateway: routes: - id: iyk_route uri: http://www.ityouknow.com predicates: - Path=/spring-cloud 说明下该配置: id：自定义的路由 ID，保持唯一 uri：目标服务地址 predicates：路由条件，Predicate 接受一个输入参数，返回一个布尔值结果。该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（比如：与，或，非）。 filters：过滤规则 同样的,转发功能也可以使用代码来实现: // 直接写在启动类中 @Bean public RouteLocator customRouteLocator(RouteLocatorBuilder builder) { return builder.routes() .route(\"path_route\", r -\u003e r.path(\"/about\") .uri(\"http://ityouknow.com\")) .build(); } 注: 虽然两种方法都可以,但还是建议写在配置文件中 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:3:2","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"路由规则 Spring Cloud Gateway 是通过 Spring WebFlux 的 HandlerMapping 做为底层支持来匹配到转发路由，Spring Cloud Gateway 内置了很多 Predicates 工厂，这些 Predicates 工厂通过不同的 HTTP 请求参数来匹配，多个 Predicates 工厂可以组合使用。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"predicates Predicate 来源于 Java 8，是 Java 8 中引入的一个函数，Predicate 接受一个输入参数，返回一个布尔值结果。该接口包含多种默认方法来将 Predicate 组合成其他复杂的逻辑（比如：与，或，非）。可以用于接口请求参数校验、判断新老数据是否有变化需要进行更新操作。 在 Spring Cloud Gateway 中 Spring 利用 Predicate 的特性实现了各种路由匹配规则，有通过 Header、请求参数等不同的条件来进行作为条件匹配到对应的路由。网上有一张图总结了 Spring Cloud 内置的几种 Predicate 的实现。 接下来我们就来看看这些规则的具体使用方法: ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:1","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"时间匹配 predicate 支持设置一个时间,以这个时间为分界线,这个时间前的不能访问,这个时间之后的可以访问. spring: cloud: gateway: routes: - id: time_route uri: http://example.com predicates: - After=2019-08-17T12:00:00+08:00[Asia/Shanghai] Spring 是通过 ZonedDateTime 来对时间进行的对比，ZonedDateTime 是 Java 8 中日期时间功能里，用于表示带时区的日期与时间信息的类，ZonedDateTime 支持通过时区来设置时间，中国的时区是：Asia/Shanghai。 After Route Predicate 是指在这个时间之后的请求都转发到目标地址。上面的示例是指，请求时间在 2018年1月20日6点6分6秒之后的所有请求都转发到地址http://example.com。+08:00是指时间和UTC时间相差八个小时，时间地区为Asia/Shanghai。 添加完路由规则之后，访问地址http://localhost:8080会自动转发到http://example.com。 Before Route Predicate 刚好相反，在某个时间之前的请求的请求都进行转发。我们把上面路由规则中的 After 改为 Before，如下： spring: cloud: gateway: routes: - id: before_route uri: http://example.com predicates: - Before=2019-08-17T12:00:00+08:00[Asia/Shanghai] 既然有这个时间前After和这个时间后Before,predicate还支持在一段时间之内匹配,那就需要使用Between spring: cloud: gateway: routes: - id: after_route uri: http://example.com predicates: - Between=2019-08-17T08:00:00+08:00[Asia/Shanghai], 2019-08-17T09:00:00+08:00[Asia/Shanghai] 这个功能刚好可以使用在一些抢购活动中. ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:2","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"Cookie 匹配 Cookie Route Predicate 可以接收两个参数，一个是 Cookie name ,一个是正则表达式，路由规则会通过获取对应的 Cookie name 值和正则表达式去匹配，如果匹配上就会执行路由，如果没有匹配上则不执行。 spring: cloud: gateway: routes: - id: cookie_route uri: http://example.com predicates: - Cookie=a,b.c 这表示请求的cookie需要携带 a=b.c 才可以访问,否则就报404错误,可以使用 curl http://localhost:8080 --cookie \"a=b.c\" ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:3","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"Header 匹配 Header Route Predicate 和 Cookie Route Predicate 一样，也是接收 2 个参数，一个 header 中的属性名称和一个正则表达式，这个属性值和正则表达式匹配则执行。 spring: cloud: gateway: routes: - id: header_route uri: http://example.com predicates: - Header=X-Request-Id, \\d+ 同样的可以使用命令url http://localhost:8080 --header \"X-Request-Id:11\"来测试. ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:4","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"Host 匹配 Host Route Predicate 接收一组参数，一组匹配的域名列表，这个模板是一个 ant 分隔的模板，用.号作为分隔符。它通过参数中的主机地址作为匹配规则 spring: cloud: gateway: routes: - id: header_route uri: http://example.com predicates: - Host=**.example.com ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:5","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"请求方法匹配 可以通过请求方式GET，POST，PATH和DELETE方法进行匹配： spring: cloud: gateway: routes: - id: method_route uri: https://example.org predicates: - Method=GET ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:6","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"请求路径匹配 predicate接受两个参数，一个PathMatcher 表达式 和一个可选参数 matchOptionalTrailingSeparator spring: cloud: gateway: routes: - id: host_route uri: https://example.org predicates: - Path=/foo/{segment},/bar/{segment} 能匹配到/foo/1, /foo/bar 或 /bar/baz等路径。 同时也可以使用代码获取： Map\u003cString, String\u003e uriVariables = ServerWebExchangeUtils.getPathPredicateVariables(exchange); String segment = uriVariables.get(\"segment\"); ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:7","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"请求参数匹配 Query Route Predicate 支持传入两个参数，一个是属性名一个为属性值，属性值可以是正则表达式。 spring: cloud: gateway: routes: - id: query_route uri: https://example.org predicates: - Query=baz ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:8","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"ip地址匹配 RemoteAddr Route Predicate 支持匹配相应的ip地址，如(IPv4 or IPv6)，或者一个网段192.168.0.1/16，一个地址192.168.0.1 spring: cloud: gateway: routes: - id: remoteaddr_route uri: https://example.org predicates: - RemoteAddr=192.168.1.1/24 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:9","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"权重匹配 Weight Route Predicate 接受两个参数，分组和权重： spring: cloud: gateway: routes: - id: weight_high uri: https://weighthigh.org predicates: - Weight=group1, 8 - id: weight_low uri: https://weightlow.org predicates: - Weight=group1, 2 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:10","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"组合使用 除此之外，这些匹配还可以组合起来使用 spring: cloud: gateway: routes: - id: host_foo_path_headers_to_httpbin uri: http://example.com predicates: - Host=**.foo.org - Path=/headers - Method=GET - Header=X-Request-Id, \\d+ - Query=foo, ba. - Query=baz - Cookie=chocolate, ch.p - After=2019-08-18T12:00:00+08:00[Asia/Shanghai] 各种 Predicates 同时存在于同一个路由时，请求必须同时满足所有的条件才被这个路由匹配。 一个请求满足多个路由的谓词条件时，请求只会被首个成功匹配的路由转发 服务化 前面已经介绍了spring cloud gateway 的简单使用，现在我们就把它融入到微服务中， ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:4:11","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"添加依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-client\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:5:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"配置文件 修改配置文件，添加discovery的配置 server: port: 8888 spring: application: name: gateway cloud: gateway: discovery: locator: enabled: true eureka: client: service-url: defaultZone: http://localhost:8000/eureka/ logging: level: org.springframework.cloud.gateway: debug 配置说明： spring.cloud.gateway.discovery.locator.enabled：是否与服务注册于发现组件进行结合，通过 serviceId 转发到具体的服务实例。默认为 false，设为 true 便开启通过服务中心的自动根据 serviceId 创建路由的功能。 eureka.client.service-url.defaultZone指定注册中心的地址，以便使用服务发现功能 logging.level.org.springframework.cloud.gateway 调整相 gateway 包的 log 级别，以便排查问题 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:6:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"启动类 @SpringBootApplication @EnableDiscoveryClient public class GatewayApplication { public static void main(String[] args) { SpringApplication.run(GatewayApplication.class, args); } } 修改完成后启动项目，访问注册中心地址 http://localhost:8000/ 即可看到名为GATEWAY的服务。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:7:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"测试 将 spring cloud gateway 注册到服务中心之后，网关会自动代理所有的在注册中心的服务，访问这些服务的语法为：http://网关地址:端口/服务中心注册serviceId/具体的url。 假如 producer 有一个 hello 服务，那使用 gateway 访问就变成 http://localhost:8888/producer/hello。 基于Filter实现的功能 Spring Cloud Gateway 的 Filter 的生命周期有两个：“pre” 和 “post”。 PRE： 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的 HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 Spring Cloud Gateway 的 Filter 分为两种：GatewayFilter 与 GlobalFilter。GlobalFilter 会应用到所有的路由上，而 GatewayFilter 将应用到单个路由或者一个分组的路由上。 Spring Cloud Gateway 内置了9种 GlobalFilter，比如 Netty Routing Filter、LoadBalancerClient Filter、Websocket Routing Filter 等，具体大家参考官网内容。 利用 GatewayFilter 可以修改请求的 Http 的请求或者响应，或者根据请求或者响应做一些特殊的限制。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:8:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"修改请求参数 我们可以使用 AddRequestParameter GatewayFilter来在转发时添加请求的参数。 application.xml spring: cloud: gateway: routes: - id: add_request_parameter_route uri: http://example.org filters: - AddRequestParameter=foo, bar 这样以来就会给每个请求都加上foo=bar ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:9:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"路由转发 我们在配置中，指定转发的对象都是直接使用uri的，但是我们知道微服务中服务提供者通常都是动态变化的，所以为了应对这样的情况，可以修改uri为指定应用的名称。 #格式为：lb://应用注册服务名 uri: lb://producer 这里其实默认使用了全局过滤器 LoadBalancerClient ，当路由配置中 uri 所用的协议为 lb 时（以uri: lb://producer为例），gateway 将使用 LoadBalancerClient 把 spring-cloud-producer 通过 eureka 解析为实际的主机和端口，并进行负载均衡。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:10:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"修改请求路径 StripPrefix Filter 是一个请求路径截取的功能，我们可以利用这个功能来做特殊业务的转发 application.xml spring: cloud: gateway: routes: - id: nameRoot uri: http://nameservice predicates: - Path=/name/** filters: - StripPrefix=2 上面这个配置的例子表示，当请求路径匹配到/name/**会将包含name和后边的字符串接去掉转发， StripPrefix=2就代表截取路径的个数，这样配置后当请求/name/bar/foo后端匹配到的请求路径就会变成http://nameservice/foo。 PrefixPath Filter 的作用和 StripPrefix 正相反，是在 URL 路径前面添加一部分的前缀。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:11:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"路由限流 为了应对服务中限速的需求，spring cloud gateway 提供了结合 redis 数据库的限流方案，它需要添加对应的依赖包spring-boot-starter-data-redis-reactive pom.xml \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-data-redis-reactive\u003c/artifactId\u003e \u003c/dependency\u003e application.yml spring: application: name: gateway redis: host: localhost password: port: 6379 cloud: gateway: discovery: locator: enabled: true routes: - id: requestratelimiter_route uri: http://example.org filters: - name: RequestRateLimiter args: redis-rate-limiter.replenishRate: 10 redis-rate-limiter.burstCapacity: 20 key-resolver: \"#{@userKeyResolver}\" predicates: - Method=GET filter 名称必须是 RequestRateLimiter redis-rate-limiter.replenishRate：允许用户每秒处理多少个请求 redis-rate-limiter.burstCapacity：令牌桶的容量，允许在一秒钟内完成的最大请求数 key-resolver：使用 SpEL 按名称引用 bean 添加配置类Config.java @Component public class Config { // 根据请求参数中的 user 字段来限流 @Primary @Bean public KeyResolver userKeyResolver() { return exchange -\u003e Mono.just(exchange.getRequest().getQueryParams().getFirst(\"user\")); } // 设置根据请求 IP 地址来限流 @Bean public KeyResolver ipKeyResolver() { return exchange -\u003e Mono.just(exchange.getRequest().getRemoteAddress().getHostName()); } } ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:12:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"熔断器 同样的，使用Filter的特性，我们也可以实现熔断器的功能。首先添加依赖包： pom.xml \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e 然后添加熔断器的配置 application.yml spring: cloud: gateway: routes: - id: hystrix_route uri: lb://producer predicates: - Path=/consumingserviceendpoint filters: - Hystrix=myCommandName - name: Hystrix args: name: fallbackcmd fallbackUri: forward:/incaseoffailureusethis 配置后gateway 将使用 myCommandName 作为名称生成 HystrixCommand 对象来进行熔断管理，fallbackUri: forward:/incaseoffailureusethis配置了 fallback 时要会调的路径，当调用 Hystrix 的 fallback 被调用时，请求将转发到/incaseoffailureuset这个 URI。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:13:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"路由重试 RetryGatewayFilter 是 Spring Cloud Gateway 对请求重试提供的一个 GatewayFilter Factory 添加配置 application.yml spring: cloud: gateway: routes: - id: retry_test uri: http://localhost:8080/flakey predicates: - Host=*.retry.com filters: - name: Retry args: retries: 3 statuses: BAD_GATEWAY backoff: firstBackoff: 10ms maxBackoff: 50ms factor: 2 basedOnPreviousValue: false retries：应尝试的重试次数 statuses：应该重试的HTTP状态代码，取值参考org.springframework.http.HttpStatus methods：应该重试的HTTP方法，取值参考org.springframework.http.HttpMethod series：要重试的一系列状态代码，取值参考org.springframework.http.HttpStatus.Series exceptions：应该重试的异常列表 backoff：重试时间间隔。 在firstBackoff x（因子n）的间隔之后执行重试，其中n是重试的次数。 如果配置了maxBackoff，则应用的最大间隔将限制为maxBackoff。 如果basedOnPreviousValue为true，则使用prevBackoff x factor计算间隔。 ","date":"2019-08-18","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/:14:0","tags":["java","spring"],"title":"Spring Cloud微服务实践七","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%83/"},{"categories":["微服务"],"content":"本篇我们就来认识下spring cloud中的zuul组件. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA zuul简介 ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"关于zuul 其实在前面的内容中,我们已经搭建了一个微服务平台,也实现了该有的功能.但是一般的微服务架构中还会有api gateway.那么api gateway(网关)又是做什么用的呢? 1、简化客户端调用复杂度 在微服务架构模式下后端服务的实例数一般是动态的，对于客户端而言很难发现动态改变的服务实例的访问地址信息。因此在基于微服务的项目中为了简化前端的调用逻辑，通常会引入API Gateway作为轻量级网关，同时API Gateway中也会实现相关的认证逻辑从而简化内部服务之间相互调用的复杂度。 2、数据裁剪以及聚合 通常而言不同的客户端对于显示时对于数据的需求是不一致的，比如手机端或者Web端又或者在低延迟的网络环境或者高延迟的网络环境。 因此为了优化客户端的使用体验，API Gateway可以对通用性的响应数据进行裁剪以适应不同客户端的使用需求。同时还可以将多个API调用逻辑进行聚合，从而减少客户端的请求数，优化客户端用户体验 3、多渠道支持 当然我们还可以针对不同的渠道和客户端提供不同的API Gateway,对于该模式的使用由另外一个大家熟知的方式叫Backend for front-end, 在Backend for front-end模式当中，我们可以针对不同的客户端分别创建其BFF，进一步了解BFF可以参考这篇文章：Pattern: Backends For Frontends 4、遗留系统的微服务化改造 对于系统而言进行微服务改造通常是由于原有的系统存在或多或少的问题，比如技术债务，代码质量，可维护性，可扩展性等等。API Gateway的模式同样适用于这一类遗留系统的改造，通过微服务化的改造逐步实现对原有系统中的问题的修复，从而提升对于原有业务响应力的提升。通过引入抽象层，逐步使用新的实现替换旧的实现。 在Spring Cloud体系中， Spring Cloud Zuul就是提供负载均衡、反向代理、权限认证的一个API gateway。 注: 以上引用于 http://www.ityouknow.com/springcloud/2017/06/01/gateway-service-zuul.html Spring Cloud Zuul路由是微服务架构的不可或缺的一部分，提供动态路由，监控，弹性，安全等的边缘服务。Zuul是Netflix出品的一个基于JVM路由和服务端的负载均衡器。 spring cloud zuul 初使用 在了解了gateway的作用和zuul之后,我们就来实现它: ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"添加依赖 \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-zuul\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"配置文件 spring.application.name=zuul server.port=8888 #这里的配置表示，访问/producer/** 直接重定向到http://localhost:9000/** zuul.routes.producer.path=/producer/** zuul.routes.producer.url=http://localhost:9000/ ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"启动类 @SpringBootApplication @EnableZuulProxy public class ZuulApplication { public static void main(String[] args) { SpringApplication.run(ZuulApplication.class, args); } } ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"测试 编译,启动producer和zuul访问http://localhost:8888/producer/hello?name=xingyys, 返回Hello xingyys ! 服务化 上面的配置有很大的局限性,因为每一个服务都需要单独的添加配置信息,如果服务是动态的,就更不方便了.其实服务和url的映射关系在discovery里已经存在了,所以只需要将Zuul注册到eureka server上去发现其他服务，就可以实现对serviceId的映射.下面我们就来实现它! ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:5:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"添加依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:6:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"配置文件 修改配置文件,添加discovery的配置 spring.application.name=zuul server.port=8888 eureka.client.service-url.defaultZone=http://localhost:8000/eureka/ #这里的配置表示，访问/producer/** 直接重定向到http://localhost:9000/** # zuul.routes.producer.path=/producer/** # zuul.routes.producer.url=http://localhost:9000/ 因为服务和url的映射信息已经存在,所有原来的配置可以删除. ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:7:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"启动类 开启服务注册 @SpringBootApplication @EnableZuulProxy @EnableDiscoveryClient public class ZuulApplication { public static void main(String[] args) { SpringApplication.run(ZuulApplication.class, args); } } ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:8:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"测试 重新编译,启动discovery, producer和zuul,访问http://localhost:8888/producer/hello?name=xingyys, 返回Hello xingyys ! zuul 高级应用 zuul除了之前使用的网关和路由转发之外,还有更多的使用场景,如鉴权,流量转发,请求统计等等. ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:9:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"zuul 的 Filter Filter是Zuul的核心，用来实现对外服务的控制。Filter的生命周期有4个，分别是“PRE”、“ROUTING”、“POST”、“ERROR”，整个生命周期可以用下图来表示。 Zuul大部分功能都是通过过滤器来实现的，这些过滤器类型对应于请求的典型生命周期。 PRE： 这种过滤器在请求被路由之前调用。我们可利用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等。 ROUTING：这种过滤器将请求路由到微服务。这种过滤器用于构建发送给微服务的请求，并使用Apache HttpClient或Netfilx Ribbon请求微服务。 POST：这种过滤器在路由到微服务以后执行。这种过滤器可用来为响应添加标准的HTTP Header、收集统计信息和指标、将响应从微服务发送给客户端等。 ERROR：在其他阶段发生错误时执行该过滤器。 除了默认的过滤器类型，Zuul还允许我们创建自定义的过滤器类型。例如，我们可以定制一种STATIC类型的过滤器，直接在Zuul中生成响应，而不将请求转发到后端的微服务。 ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:10:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"zuul中默认的filter ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:11:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"自定义Filter 如果要自定义Filter,需要继承ZuulFiilter类,并实现以下方法: public class MyFilter extends ZuulFilter { @Override String filterType() { return \"pre\"; //定义filter的类型，有pre、route、post、error四种 } @Override int filterOrder() { return 10; //定义filter的顺序，数字越小表示顺序越高，越先执行 } @Override boolean shouldFilter() { return true; //表示是否需要执行该filter，true表示执行，false表示不执行 } @Override Object run() { return null; //filter需要执行的具体操作 } } 接下来我们来自定义一个Filter,让请求必须带上token public class TokenFilter extends ZuulFilter { private final Logger logger = LoggerFactory.getLogger(TokenFilter.class); @Override public String filterType() { return \"pre\"; // 可以在请求被路由之前调用 } @Override public int filterOrder() { return 0; // filter执行顺序，通过数字指定 ,优先级为0，数字越大，优先级越低 } @Override public boolean shouldFilter() { return true; // 是否执行该过滤器，此处为true，说明需要过滤 } @Override public Object run() throws ZuulException { RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); logger.info(\"---\u003e\u003e\u003e TokenFilter {},{}\", request.getMethod(), request.getRequestURL().toString()); String token = request.getParameter(\"token\"); if (StringUtils.isNotBlank(token)) { ctx.setSendZuulResponse(true); //对请求进行路由 ctx.setResponseStatusCode(200); ctx.set(\"isSuccess\", true); } else { ctx.setSendZuulResponse(false); //不对请求进行路由 ctx.setResponseStatusCode(400); ctx.setResponseBody(\"token is empty\"); ctx.set(\"isSuccess\", false); } return null; } } 将请求添加到拦截列队 @SpringBootApplication @EnableZuulProxy @EnableDiscoveryClient public class ZuulApplication { @Bean public TokenFilter tokenFilter() { return new TokenFilter(); } public static void main(String[] args) { SpringApplication.run(ZuulApplication.class, args); } } 然后我们依次启动discovery,producer和zuul, 访问http://localhost:8888/producer/hello?name=xingyys返回token is empty. 访问http://localhost:8888/producer/hello?name=xingyys\u0026token=xingyys, 返回Hello xingyys !,说明Filter已经生效了. 由此看出,PRE运行在请求前,利用它我们可以结合一个鉴权的第三方库作用户验证. ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:12:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"路由的熔断 有时当请求错误时,我们不希望将异常直接抛给最外层,而是让错误降一级,zuul就提供了此功能,当后端服务异常时,抛出我们预设的信息. zuul使用fallback实现异常的降级,通过自定义的fallback方法,并且将其指定给某个route来实现该route访问出问题的熔断处理。主要继承ZuulFallbackProvider接口来实现，ZuulFallbackProvider默认有两个方法，一个用来指明熔断拦截哪个服务，一个定制返回内容。 public interface ZuulFallbackProvider { /** * The route this fallback will be used for. * @return The route the fallback will be used for. */ public String getRoute(); /** * Provides a fallback response. * @return The fallback response. */ public ClientHttpResponse fallbackResponse(); } 实现类通过实现getRoute方法，告诉Zuul它是负责哪个route定义的熔断。而fallbackResponse方法则是告诉 Zuul 断路出现时，它会提供一个什么返回值来处理请求。 后来Spring又扩展了此类，丰富了返回方式，在返回的内容中添加了异常信息，因此最新版本建议直接继承类FallbackProvider 。 我们以上面的producer服务为例，定制它的熔断返回内容。 @Component public class ProducerFallBack implements FallbackProvider { private final Logger logger = LoggerFactory.getLogger(FallbackProvider.class); // 指定要处理的service @Override public String getRoute() { return \"producer\"; } public ClientHttpResponse fallbackResponse() { return new ClientHttpResponse() { @Override public HttpStatus getStatusCode() throws IOException { return HttpStatus.OK; } @Override public int getRawStatusCode() throws IOException { return 200; } @Override public String getStatusText() throws IOException { return \"OK\"; } @Override public void close() { } @Override public InputStream getBody() throws IOException { return new ByteArrayInputStream(\"The service is unavailable\".getBytes()); } @Override public HttpHeaders getHeaders() { HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); return headers; } }; } @Override public ClientHttpResponse fallbackResponse(String route, Throwable cause) { if (cause != null \u0026\u0026 cause.getCause() != null) { String reason = cause.getCause().getMessage(); logger.info(\"Exception {}\", reason); } return fallbackResponse(); } } 重新编译启动zuul后,我们关闭producer,并访问http://localhost:8888/producer/hello?name=xingyys\u0026token=xingyys, 返回The service is unavailable.可见错误处理成功了. Zuul 目前只支持服务级别的熔断，不支持具体到某个URL进行熔断。 注: 以上大量出自 http://www.ityouknow.com ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:13:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"路由重试 由于本系列的开发环境是spring boot 2.x的, 而zuul还是1.x版本的,以上的功能还是可以使用的.但是路由重试功能经测试不能生效,所以就展示配置和代码. ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:14:0","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.retry\u003c/groupId\u003e \u003cartifactId\u003espring-retry\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:14:1","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"配置 #是否开启重试功能 zuul.retryable=true #对当前服务的重试次数 ribbon.MaxAutoRetries=2 #切换相同Server的次数 ribbon.MaxAutoRetriesNextServer=0 spring cloud 2.x版本已经拥有自己的gateway组件了,所以下一篇我们就来尝试spring cloud gateway ","date":"2019-08-16","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/:14:2","tags":["java","spring"],"title":"Spring Cloud微服务实践六","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%85%AD/"},{"categories":["微服务"],"content":"本篇我们来看看怎么实现spring cloud的配置中心. 在分布式系统中,特别是微服务架构下,可能会存在许多的服务,每个服务都会存在一个或多个的配置文件.那怎么多的配置文件的管理就会成为一个大问题.同时,微服务运行过程中还需要动态的修改配置参数.所以spring cloud config就是在spring cloud微服务架构中解决配置文件的管理,刷新,查看等问题的. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA spring cloud config和git 我们先来一个简单的配置,只有server和config的. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"添加配置文件 创建一个目录,目录下分别添加3个不同的配置文件 neo-config-dev.properties neo-config-pro.properties neo-config-test.properties 里面的配置分别为neo.hello=hello in dev/pro/test 并将目录保存到gitlee/github上. 这里我的地址是 https://gitlee.com/xingyys/config-repo ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"server 端 接下来开始配置server ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"pom \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-config-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:2:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"配置文件 server: port: 8001 spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/xingyys/config-repo # 配置文件保存的目录,用,分隔 search-paths: config-repo username: username password: password # 忽略ssl, 或者自行配置秘钥 skip-ssl-validation: true Spring Cloud Config也提供本地存储配置的方式。我们只需要设置属性spring.profiles.active=native，Config Server会默认从应用的src/main/resource目录下检索配置文件。也可以通过spring.cloud.config.server.native.searchLocations=file:E:/properties/属性来指定配置文件的位置。虽然Spring Cloud Config提供了这样的功能，但是为了支持更好的管理内容和版本控制的功能，还是推荐使用git的方式。 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:2:2","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"启动类 添加注解@EnableConfigServer,启动配置中心服务端功能 @SpringBootApplication @EnableConfigServer public class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); } } ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:2:3","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"测试 直接编译打包就可以测试了,直接访问http://localhost:8001/neo-config/dev返回: { \"name\": \"neo-config\", \"profiles\": [ \"dev\" ], \"label\": null, \"version\": null, \"state\": null, \"propertySources\": [ { \"name\": \"https://gitee.com/xingyys/config-repo/config-repo/neo-config-dev.properties\", \"source\": { \"neo.hello\": \"hello im dev\" } } ] } 上述的返回的信息包含了配置文件的位置、版本、配置文件的名称以及配置文件中的具体内容，说明server端已经成功获取了git仓库的配置信息。 仓库中的配置文件会被转换成web接口，访问可以参照以下的规则： /{application}/{profile}[/{label}] /{application}-{profile}.yml /{label}/{application}-{profile}.yml /{application}-{profile}.properties /{label}/{application}-{profile}.properties 以neo-config-dev.properties为例子，它的application是neo-config，profile是dev。client会根据填写的参数来选择读取对应的配置。 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:2:4","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"client 端 用来获取server端上的配置信息 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"pom \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-config\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-web\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:3:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"配置文件 config client的配置文件为 bootstrap.properties spring.cloud.config.name=neo-config spring.cloud.config.profile=dev spring.cloud.config.uri=http://localhost:8001/ spring.cloud.config.label=master spring.application.name=config-client server.port=8002 spring.application.name：对应{application}部分 spring.cloud.config.profile：对应{profile}部分 spring.cloud.config.label：对应git的分支。如果配置中心使用的是本地存储，则该参数无用 spring.cloud.config.uri：配置中心的具体地址 spring.cloud.config.discovery.service-id：指定配置中心的service-id，便于扩展为高可用配置集群。 这些与spring-cloud相关的属性必须配置在bootstrap.properties中，config部分内容才能被正确加载。因为config的相关配置会先于application.properties，而bootstrap.properties的加载也是先于application.properties。 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:3:2","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"启动类 @SpringBootApplication public class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); } } ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:3:3","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"接口类 @RestController public class HelloController { @Value(\"${neo.hello}\") private String hello; @RequestMapping(\"/hello\") public String from() { return this.hello; } } ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:3:4","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"测试 编译启动config client, 访问http://192.168.1.13:8002/hello返回: hello im dev 配置成功! 配置中心 前面我们已经配置config server和config client,而且也已经可以使用了,但是它还只能单独使用,接下来我们需要对它们进行一些改造,用在微服务架构中. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:3:5","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"注册中心 这里的注册中心直接使用前几篇留下的就可以. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"server 端的改造 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:5:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"添加依赖 ... \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e ... ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:5:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"修改配置文件 ... eureka: client: service-url: defaultZone: http://localhost:8000/eureka/ ... ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:5:2","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"启动类 添加注解@EnableDiscoveryClient: @SpringBootApplication @EnableConfigServer @EnableDiscoveryClient public class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); } } 记得重新编译,启动 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:5:3","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"client 端的改造 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:6:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"添加依赖 ... \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e ... ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:6:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"修改配置文件 同样是 bootstrap.properties spring.cloud.config.name=neo-config spring.cloud.config.profile=dev spring.cloud.config.label=master spring.cloud.config.discovery.enabled=true spring.cloud.config.discovery.serviceId=config-server eureka.client.serviceUrl.defaultZone=http://localhost:8000/eureka/ spring.application.name=config-client server.port=8002 主要是去掉了spring.cloud.config.uri直接指向server端地址的配置，增加了最后的三个配置： spring.cloud.config.discovery.enabled ：开启Config服务发现支持 spring.cloud.config.discovery.serviceId ：指定server端的name,也就是server端spring.application.name的值 eureka.client.serviceUrl.defaultZone ：指向注册中心的地址 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:7:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"启动类 @SpringBootApplication @EnableDiscoveryClient public class ConfigClientApplication { public static void main(String[] args) { SpringApplication.run(ConfigClientApplication.class, args); } } ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:7:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"测试 一次启动 discovery, config-server和config-client, 访问http://127.0.0.1:8000/ 访问http://localhost8002/hello, 返回hello im dev . 结合消息总线 其实上面的配置还有一个问题,就是配置文件更新后,config client不能同步更新,需要重启.针对这个问题,已经有一些的解决方法了,一种是配置 gitlee或github的webhook,另一种就是使用消息总线.我们就来尝试后者. spring cloud中可以和rabbitmq结合实现. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:8:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"安装rabbitmq rabbitmq的安装教程网上有很多,这里为了简单,我们就直接使用docker来安装. 这里我准备了一个虚拟机192.168.1.10, 上面安装了docker # 拉取rabbitmq镜像 docker pull rabbitmq:management # 启动镜像 docker run -d -p 5672:5672 -p 15672:15672 --name rabbitmq rabbitmq:management 执行成功后登录rabbitmq, http://192.168.1.10/15672, 用户名/密码为 guest/guest. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:9:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"client 端的改造 接下来就是修改client端了 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:10:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"添加依赖 ... \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e ... ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:10:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"配置文件 ... ## 添加配置刷新的接口url management.endpoints.web.exposure.include=bus-refresh ## 开启消息跟踪 spring.cloud.bus.trace.enabled=true spring.rabbitmq.host=192.168.1.10 ## rabbitmq登录使用5672, 15672是web端口,别搞错了! spring.rabbitmq.port=5672 spring.rabbitmq.username=guest spring.rabbitmq.password=guest ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:10:2","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"接口 修改接口HelloController, 添加注解@RefreshScope @RestController @RefreshScope public class HelloController { @Value(\"${neo.hello}\") private String hello; @RequestMapping(\"/hello\") public String from() { return this.hello; } } ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:10:3","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"测试 修改配置文件,使用命令curl -X POST http://localhost:8002/actuator/bus-refresh更新,在访问http://localhost:8002/hello 如果返回500错误,请检查rabbitmq连接 ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:10:4","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"改进 server 上面的配置只是针对单个client的,如果要让所有的client都更新,就需要使用curl对每个client操作.所有我们将修改server, 当配置文件修改后,刷新server时,同时刷新所有的client. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:11:0","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"添加依赖 \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-bus-amqp\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:11:1","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"配置文件 server: port: 8001 spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/xingyys/config-repo search-paths: config-repo username: username password: password skip-ssl-validation: true bus: trace: enabled: true rabbitmq: host: 192.168.1.10 port: 5672 username: guest password: guest management: endpoints: web: exposure: include: bus-refresh eureka: client: service-url: defaultZone: http://localhost:8000/eureka/ ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:11:2","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"测试 修改配置文件,执行命令 curl -X POST http://localhost:8001/actuator/bus-refresh. ","date":"2019-08-14","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/:11:3","tags":["java","spring"],"title":"Spring Cloud微服务实践五","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%94/"},{"categories":["微服务"],"content":"spring cloud的hystrix还有一个配搭的库hystrix-dashboard,它是hystrix的一款监控工具,能直观的显示hystrix响应信息,请求成功率等.但是hystrix-dashboard只能查看单机和集群的信息,如果需要将多台的信息汇总起来的话就需要使用turbine. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA hystrix-dashboard hystrix-dashboard只要在上一篇的hystrix的基础上稍微修改下就可以了. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"添加依赖 依赖文件pom.xml需要添加一些信息. \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix-dashboard\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"需改启动类 @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients(basePackages = \"com.xingyys.hystrix.remote\") // 添加以下注解 @EnableHystrixDashboard @EnableCircuitBreaker public class HystrixApplication { public static void main(String[] args) { SpringApplication.run(HystrixApplication.class, args); } } ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"修改配置文件 spring cloud 2.x版本和1.x版本不同,需要修改配置文件 # ...... # application.properties management.endpoints.web.exposure.include=hystrix.stream management.endpoints.web.base-path=/ ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"测试 重新编译后开始测试 浏览器访问http://127.0.0.1:9002/hystrix出现以下页面: 浏览器访问: http://127.0.0.1:9002/hystrix.stream出现以下信息 ping: data: {...} data: {...} 同时在http://192.168.1.13:9002/hystrix页面中检测http://127.0.0.1:9002/hystrix.stream ,点击monitor stream跳转页面: hystrix-dashboard显示的各项信息含义: 到这里,单节点的监控就完成了. 注:如果一直显示Loading…, 刷新 http://127.0.0.1:9002/hello/xxx页面即可. turbine 接下来我们来看看在多台节点中的监控工具Turbine是如何配置. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"创建工程 首先我们还是先来创建一个工程应用,命名为turbine ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:5:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"依赖文件 修改依赖文件pom.xml \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-netflix-turbine\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix-dashboard\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-actuator\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:6:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"配置文件 修改配置文件application.propertoes spring.application.name=turbine server.port=8081 # 配置Eureka中的serviceId列表，表明监控哪些服务 turbine.app-config=node01,node02 # 指定聚合哪些集群，多个使用”,”分割，默认为default。可使用http://.../turbine.stream?cluster={clusterConfig之一}访问 turbine.aggregator.cluster-config=default # 1. clusterNameExpression指定集群名称，默认表达式appName；此时：turbine.aggregator.clusterConfig需要配置想要监控的应用名称； # 2. 当clusterNameExpression: default时，turbine.aggregator.clusterConfig可以不写，因为默认就是default； # 3. 当clusterNameExpression: metadata[‘cluster’]时，假设想要监控的应用配置了eureka.instance.metadata-map.cluster: ABC， # 则需要配置，同时turbine.aggregator.clusterConfig: ABC turbine.cluster-name-expression=new String(\"default\") eureka.client.service-url.defaultZone=http://localhost:8000/eureka # spring cloud 2.x版本需要作的改动 management.endpoints.web.exposure.include=turbine.stream management.endpoints.web.base-path=/ ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:7:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"启动类 @SpringBootApplication @EnableHystrixDashboard // 激活对turbine的支持 @EnableTurbine public class TurbineApplication { public static void main(String[] args) { SpringApplication.run(TurbineApplication.class, args); } } ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:8:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"测试 开始测试前,需要对hystrix应用做修改,添加两个配置文件application-node01.properites和application-node02.properties. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:9:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"application-node01.properites spring.application.name=node01 server.port=9003 # 其他和consumer相同,主要是hystrix的配置 feign.hystrix.enabled=true eureka.client.service-url.defaultZone=http://localhost:8000/eureka/ management.endpoints.web.exposure.include=hystrix.stream management.endpoints.web.base-path=/ ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:10:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"application-node02.properites spring.application.name=node02 server.port=9004 # 其他和consumer相同,主要是hystrix的配置 feign.hystrix.enabled=true eureka.client.service-url.defaultZone=http://localhost:8000/eureka/ management.endpoints.web.exposure.include=hystrix.stream management.endpoints.web.base-path=/ ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:11:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"hystrix启动类 @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients(basePackages = \"com.xingyys.hystrix.remote\") @EnableHystrixDashboard @EnableCircuitBreaker public class HystrixApplication { // spring cloud 2.x需要自己指定 @Bean(name = \"HystrixMetricsStreamServlet\") public ServletRegistrationBean getServlet(){ HystrixMetricsStreamServlet streamServlet = new HystrixMetricsStreamServlet(); ServletRegistrationBean registrationBean = new ServletRegistrationBean(streamServlet); registrationBean.setLoadOnStartup(1); registrationBean.addUrlMappings(\"/actuator/hystrix.stream\"); registrationBean.setName(\"HystrixMetricsStreamServlet\"); return registrationBean; } public static void main(String[] args) { SpringApplication.run(HystrixApplication.class, args); } } 以此启动应用: java -jar target/discovery-0.0.1-SNAPSHOT.jar java -jar target/hystrix-0.0.1-SNAPSHOT.jar --spring.profiles.active=node01 java -jar target/hystrix-0.0.1-SNAPSHOT.jar --spring.profiles.active=node02 java -jar target/turbine-0.0.1-SNAPSHOT.jar 访问http://127.0.0.1:8081/turbine.stream,返回 : ping : ping 访问http://127.0.0.1:8081/hystrix并填写表单,出现以下页面: 注:假如一直在loading,请刷新node01或node02节点的/hello/neo页面,但要保证服务的提供应用关闭. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/:12:0","tags":["java","spring"],"title":"Spring Cloud微服务实践四","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E5%9B%9B/"},{"categories":["微服务"],"content":"上篇文章里我们实现了spring cloud中的服务提供者和使用者.接下来我们就来看看spring cloud中微服务的其他组件. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA 熔断器 spring cloud架构成员中有一个叫\"熔断器\".微服务中一个服务通常存在多级调用情况,在这种情况下就出现了一些严重的问题.假如其中的一个服务故障了,那么调用这个服务的使用者就会处于等待状态中,由于多级联调用,所以后续的调用者也会处于这种情况.因此错误就会在一个系统中被放大,从而出现了服务的\"雪崩效应\".为了应对这种效应,就有了\"熔断器\". 所谓熔断器,就是当服务提供者出现问题时,调用者发现了这个问题,它会快速响应报错. 如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"Hystrix特性 ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"1.断路器机制 断路器很好理解, 当Hystrix Command请求后端服务失败数量超过一定比例(默认50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认5秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况, 如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:1:1","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"2.Fallback Fallback相当于是降级操作. 对于查询操作, 我们可以实现一个fallback方法, 当请求后端服务出现异常的时候, 可以使用fallback方法返回的值. fallback方法的返回值一般是设置的默认值或者来自缓存 ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:1:2","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"3.资源隔离 在Hystrix中, 主要通过线程池来实现资源隔离. 通常在使用的时候我们会根据调用的远程服务划分出多个线程池. 例如调用产品服务的Command放入A线程池, 调用账户服务的Command放入B线程池. 这样做的主要优点是运行环境被隔离开了. 这样就算调用服务的代码存在bug或者由于其他原因导致自己所在线程池被耗尽时, 不会对系统的其他服务造成影响. 但是带来的代价就是维护多个线程池会对系统带来额外的性能开销. 如果是对性能有严格要求而且确信自己调用服务的客户端代码不会出问题的话, 可以使用Hystrix的信号模式(Semaphores)来隔离资源. 这段来自: http://www.ityouknow.com Feign Hystrix spring cloud中熔断器组件是结合Feign库一起使用的.所以它的代码是在上一篇中的consumer基础上添加的. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:1:3","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"创建工程项目 创建一个spring cloud工程项目,命名为hystrix. ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"依赖文件 pom 修改依赖文件 pom.xml \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-hystrix\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"配置文件 修改配置文件 application.properties spring.application.name=hystrix server.port=9002 # 其他和consumer相同,主要是hystrix的配置 feign.hystrix.enabled=true eureka.client.service-url.defaultZone=http://localhost:8000/eureka/ ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"远程调用 // com/xingyys/hystrix/remote/HelloRemote.java // 指定fallback属性 @FeignClient(name = \"producer\", fallback = HelloRemoteHystrix.class) public interface HelloRemote { @RequestMapping(value = \"/hello\") public String hello(@RequestParam(value = \"name\") String name); } ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:5:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"hystrix熔断器 // com/xingyys/hystrix/remote/HelloRemoteHystrix @Component public class HelloRemoteHystrix implements HelloRemote { @Override public String hello(@RequestParam String name) { return \"hello \" + name + \" failed!\"; } } ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:6:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"控制器 // com/xingyys/hystrix/controller/HystrixController.java @RestController public class HystrixController { // @Autowired 也可以, 因为idea的问题, 会显示红色 @Resource HelloRemote helloRemote; @RequestMapping(\"/hello/{name}\") public String hello(@PathVariable(\"name\") String name) { return helloRemote.hello(name); } } ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:7:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"启动类 @SpringBootApplication @EnableDiscoveryClient @EnableFeignClients(basePackages = \"com.xingyys.hystrix.remote\") public class HystrixApplication { public static void main(String[] args) { SpringApplication.run(HystrixApplication.class, args); } } ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:8:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"编译,打包,启动 cd hystrix mvn clean package -Dmaven.test.skip=true java -jar target/hystrix-0.0.1-SNAPSHOT.jar 测试 依次启动discovery,producer,consumer和hystrix 访问http://127.0.0.1:8000,应用列表中新增了HYSTRIX. 访问http://127.0.0.1:9002/hello/xingyys,返回hello xingyys!,consumer的功能依然可用. 然后断开producer,返回http://127.0.0.1:9001/hello/xingyys,原来的consumer已经500错误. 而访问http://127.0.0.1:9002/hello/xingyys返回为:hello xingyys failed!,熔断器功能可用! ","date":"2019-08-11","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/:9:0","tags":["java","spring"],"title":"Spring Cloud微服务实践三","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%89/"},{"categories":["微服务"],"content":"在上一篇,我们已经搭建了spring cloud微服务中的注册中心.但只有一个注册中心还远远不够. 接下来我们就来尝试提供服务. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA 服务提供 假设我们现在有个需求,需要一个接口,当我们传入一个名字,它会返回一句问好的话.如传入body,输入则为hello body!. ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"创建一个spring cloud的工程项目 具体的步骤这里就不在详细介绍了,需要的可以看[spring cloud微服务实践二]里面的内容. 步骤如下: Idea中选择之前的目录firstCloud, 右击\u003eNew\u003eModule, 选择 Spring Initialzr. 工程中 Group Project Metadata中Group为com.xingyys, Artifact为producer 直接next,直到完成. ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"pom 配置 在producer目录下,修改 pom.xml文件,添加依赖: \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.1.7.RELEASE\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cgroupId\u003ecom.xingyys\u003c/groupId\u003e \u003cartifactId\u003eproducer\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003cname\u003eproducer\u003c/name\u003e \u003cdescription\u003eDemo project for Spring Boot\u003c/description\u003e \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003c/project\u003e ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"配置文件 修改 resources下的配置文件 application.properties. spring.application.name=producer server.port=9000 eureka.client.service-url.defaultZone=http://localhost:8000/eureka/ ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"启动类 修改com.xingyys.producer下的 ProducerApplication.java: @SpringBootApplication @EnableDiscoveryClient public class ProducerApplication { public static void main(String[] args) { SpringApplication.run(ProducerApplication.class, args); } } 有了@EnableDiscoveryClient,就表示producer具有注册服务的功能了. ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"添加Controller 这里添加一个controller提供我们需要的服务 com.xingyys.producer/controller/HelloController.java: @RestController public class HelloController { @RequestMapping(\"/hello\") public String hello(@RequestParam String name) { return \"Hello \" + name + \" !\"; } } ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:5:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"编译运行 producer代码和配置文件这样就可以了,接下来运行producer看看效果: cd producer mvn clean package -Dmaven.test.skip=true java -jar target/producer-0.0.1-SNAPSHOT.jar 访问http://localhost:9000/hello?name=xingyys,返回Hello xingyys !,表示注册成功,producer可以提供服务了. 服务调用 既然服务的提供者有了,接着我们就来设置一个服务的使用者. ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:6:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"创建项目 项目命名为consumer,步骤同上,不在说明… ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:7:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"pom配置 \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-openfeign\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:8:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"远程调用 spring cloud使用 feign 进行远程调用. Feign是一个声明式Web Service客户端。使用Feign能让编写Web Service客户端更加简单, 它的使用方法是定义一个接口，然后在上面添加注解，同时也支持JAX-RS标准的注解。Feign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和HttpMessageConverters。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。 // com.xingyys.consumer.remote.HelloRemote.java // name 为 服务端的实例名 @FeignClient(name = \"producer\") public interface HelloRemote { @RequestMapping(value = \"/hello\") public String hello(@RequestParam(value = \"name\") String name); } ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:9:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"创建服务 注意: 这里的服务指的是微服务中对外的暴露的接口 // com.xingyys.consumer.controller.ConsumerController.java @RestController public class ConsumerController { @Autowired HelloRemote helloRemote; @RequestMapping(\"/hello/{name}\") public String hello(@PathVariable(\"name\") String name) { return helloRemote.hello(name); } } ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:10:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"启动类 // ConsumerApplication.java @SpringBootApplication @EnableDiscoveryClient // 注意这里接口和低版本有不同,需要在这里指定远程调用接口的路径 @EnableFeignClients(basePackages = \"com.xingyys.consumer.remote\") public class ConsumerApplication { public static void main(String[] args) { SpringApplication.run(ConsumerApplication.class, args); } } ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:11:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"配置文件 spring.application.name=consumer server.port=9001 eureka.client.service-url.defaultZone=http://localhost:8000/eureka/ ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:12:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"编译运行 cd consumer mvn clean package -Dmaven.test.skip=true java -jar target/consumer-0.0.1-SNAPSHOT.jar ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:13:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"测试 浏览器访问: http://localhost:9001/hello/xingyys,返回Hello xingyys ! ","date":"2019-08-09","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/:14:0","tags":["java","spring"],"title":"Spring Cloud微服务实践二","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%BA%8C/"},{"categories":["微服务"],"content":"最近在学习spring框架.其中spring cloud在微服务方面很火,所以在学习过程中,也做一些记录. 注:这一个系列的开发环境版本为 java1.8, spring boot2.x, spring cloud Greenwich.SR2, IDE为 Intelli IDEA spring cloud的简介 关于spring cloud是什么,做什么的问题这里就不再详细说明了.需要的可以看 这篇文章[http://www.ityouknow.com/springcloud/2017/05/01/simple-springcloud.html] (博客园markdown不支持超链接). 接下来我们就来实践spring cloud的几个核心组件. 注册中心Eureka Eureka是Netflix开源的一款提供服务注册和发现的产品.它是spring cloud最核心的组件之一. 接下来我们看看具体的构建步骤: ","date":"2019-08-08","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/:0:0","tags":["java","spring"],"title":"Spring Cloud微服务实践一","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/"},{"categories":["微服务"],"content":"构建步骤 1.创建spring cloud项目 选择菜单 File\u003eNew\u003eProject, 选择 Spring Initializr,然后 next. 2.输入项目名称 Group 为组织名, Artifact 为项目名, 输出完毕后 next. 3.选择依赖 接下来选择依赖,直接Spring Cloud, 然后 next. 4.选择项目路径 选好路径,直接 next. 5.完成创建 到这里,一个标准的spring cloud项目就出来了 6.补充代码 接下来就是补充代码了. ","date":"2019-08-08","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/:1:0","tags":["java","spring"],"title":"Spring Cloud微服务实践一","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/"},{"categories":["微服务"],"content":"实例代码 1.首先的依赖关系: pom.xml \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003cparent\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-parent\u003c/artifactId\u003e \u003cversion\u003e2.1.6.RELEASE\u003c/version\u003e \u003crelativePath/\u003e \u003c!-- lookup parent from repository --\u003e \u003c/parent\u003e \u003cgroupId\u003ecom.xingyys.firstCloud\u003c/groupId\u003e \u003cartifactId\u003ediscovery\u003c/artifactId\u003e \u003cversion\u003e0.0.1-SNAPSHOT\u003c/version\u003e \u003cname\u003ediscovery\u003c/name\u003e \u003cdescription\u003eDemo project for Spring Cloud Discovery\u003c/description\u003e \u003cproperties\u003e \u003cjava.version\u003e1.8\u003c/java.version\u003e \u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e \u003c/properties\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-starter-netflix-eureka-server\u003c/artifactId\u003e \u003c/dependency\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-test\u003c/artifactId\u003e \u003cscope\u003etest\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cdependencyManagement\u003e \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.cloud\u003c/groupId\u003e \u003cartifactId\u003espring-cloud-dependencies\u003c/artifactId\u003e \u003cversion\u003e${spring-cloud.version}\u003c/version\u003e \u003ctype\u003epom\u003c/type\u003e \u003cscope\u003eimport\u003c/scope\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c/dependencyManagement\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-maven-plugin\u003c/artifactId\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e \u003c/project\u003e 要注意的是spring boot2.x版本和1.x版本在依赖上有一些不同,所以特别注意 properties中的\u003cspring-cloud.version\u003eGreenwich.SR2\u003c/spring-cloud.version\u003e 2.启动代码中添加@EnableEurekaServer注解 @SpringBootApplication @EnableEurekaServer public class DiscoveryApplication { public static void main(String[] args) { SpringApplication.run(DiscoveryApplication.class, args); } } 3.配置文件 application.properties spring.application.name=spring-cloud-eureka server.port=8000 eureka.client.register-with-eureka=false eureka.client.fetch-registry=false eureka.client.serviceUrl.defaultZone=http://localhost:${server.port}/eureka/ eureka.client.register-with-eureka ：表示是否将自己注册到Eureka Server，默认为true。 eureka.client.fetch-registry ：表示是否从Eureka Server获取注册信息，默认为true。 eureka.client.serviceUrl.defaultZone ：设置与Eureka Server交互的地址，查询服务和注册服务都需要依赖这个地址。默认是http://localhost:8761/eureka ；多个地址可使用 , 分隔。 4.编译打包 进入到discovery目录下执行命令: # 忽略测试 mvn clean package -Dmaven.test.skip=true 编译成功后会在 target目录下生成 discovery.xx.jar包 5.运行discovery java -jar target/discovery-0.0.1-SNAPSHOT.jar 都成功的话,浏览器访问 http://localhost:8000: 注册中心的高可用 既然注册中心这么重要,那么单机运行怎么能保证服务的可靠性呢.所以我们就需要对注册中心做集群. Eureka通过互相注册的方式来实现高可用的部署，所以我们只需要将Eureke Server配置其他可用的serviceUrl就能实现高可用部署. 接下来我们就来看看怎么实现吧: ","date":"2019-08-08","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/:2:0","tags":["java","spring"],"title":"Spring Cloud微服务实践一","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/"},{"categories":["微服务"],"content":"双活配置 1.创建application-node1.properties，作为node1服务中心的配置，并将serviceUrl指向node2`, : spring.application.name=discovery-node1 server.port=8001 eureka.client.register-with-eureka=true eureka.client.fetch-registry=true eureka.instance.hostname=node1 eureka.client.serviceUrl.defaultZone=http://node2:8002/eureka/ 2.创建application-node2.properties，作为node2服务中心的配置，并将serviceUrl指向node1: spring.application.name=discovery-node2 server.port=8002 eureka.client.register-with-eureka=true eureka.client.fetch-registry=true eureka.instance.hostname=node2 eureka.client.serviceUrl.defaultZone=http://node1:8001/eureka/ 3.修改hosts 127.0.0.1 node1 127.0.0.1 node2 4.修改代码,添加@EnableEurekaClient注解: @SpringBootApplication @EnableEurekaServer @EnableEurekaClient public class DiscoveryApplication { public static void main(String[] args) { SpringApplication.run(DiscoveryApplication.class, args); } } 5.打包启动 依次执行下面命令 #打包 mvn clean package -Dmaven.test.skip=true # 分别以node1和node2 配置信息启动eureka # --spring.profiles.active 指定启动不同的配置文件 java -jar target/discovery-0.0.1-SNAPSHOT.jar --spring.profiles.active=node1 java -jar target/discovery-0.0.1-SNAPSHOT.jar --spring.profiles.active=node2 成功后访问浏览器就会变成这样: ","date":"2019-08-08","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/:3:0","tags":["java","spring"],"title":"Spring Cloud微服务实践一","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/"},{"categories":["微服务"],"content":"更多集群 如果是三个及以上的节点又要怎么配合呢,其实也是同样的原理.以三个节点为例,每个节点注册为其他节点的client就可以了. 因为spring cloud也支持yaml格式的配置文件,所以三个节点的配置文件可以写在一个yaml文件中: ---spring:application:name:discoveryprofiles:nodes1server:port:8000eureka:instance:hostname:node1client:serviceUrl:defaultZone:http://node2:8001/eureka/,http://node3:8002/eureka/---spring:application:name:discoveryprofiles:nodes2server:port:8001eureka:instance:hostname:node2client:serviceUrl:defaultZone:http://node1:8000/eureka/,http://node3:8002/eureka/---spring:application:name:discoveryprofiles:nodes3server:port:8002eureka:instance:hostname:node3client:serviceUrl:defaultZone:http://node1:8000/eureka/,http://node2:8001/eureka/ 分别启动: java -jar target/discovery-0.0.1-SNAPSHOT.jar --spring.profiles.active=nodes1 java -jar target/discovery-0.0.1-SNAPSHOT.jar --spring.profiles.active=nodes2 java -jar target/discovery-0.0.1-SNAPSHOT.jar --spring.profiles.active=nodes3 浏览器访问: ","date":"2019-08-08","objectID":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/:4:0","tags":["java","spring"],"title":"Spring Cloud微服务实践一","uri":"/spring-cloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E8%B7%B5%E4%B8%80/"},{"categories":["代码"],"content":"需求和思路 在一般的小项目或者一个小软件,例如客户端之类的小程序中,可能会需要数据的持久化.但是使用一般的数据库(Mysql)之类的不合适.使用sqlite3这种嵌入式的是个较好的方法,但是Go语言中sqlite3的库是C语言的,Cgo不支持跨平台编译.正是由于这种需求,才想到使用json格式将数据直接保存在文件中. 具体的思路是怎么样呢? 在Go语言中如果要将数据转化成json格式的话,有两种格式 struct 和 map. 如果同时需要增删查改功能的话,将map作为中间格式是比较合适的.接下来我们就来实现它. 查询操作 这种操作的实现比较简单,直接将文件中的数据读取出来,使用json库反序列化就可以了. 代码如下 : type Product struct { Name string `json:\"name\"` Num int `json:\"num\"` } func findAll() { ps := make([]Product, 0) data, err := ioutil.ReadFile(\"./index.json\") if err != nil { log.Fatal(err) } // 这里参数要指定为变量的地址 err = json.Unmarshal(data, \u0026ps) if err != nil { log.Fatal(err) } fmt.Println(ps) } 添加操作 添加的实现实在查询的基础上的,我们需要先查询文件中的数据库,并转化为map格式,再将struct也转化为map格式(这里要使用反射),合并map,json序列化,最后保存在文件中.代码如下: func create() { fields := make([]map[string]interface{}, 0) p1 := \u0026Product{ Name: \"Blog\", Num: 2, } _, _ = json.Marshal(p1) // 读取文件中的数据,保存为map格式 data, _ := ioutil.ReadFile(\"./index.json\") err := json.Unmarshal(data, \u0026fields) if err != nil { log.Fatal(err) } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") field[key] = field2.Interface() } // 合并map fields = append(fields, field) // 写入文件 out, _ := json.Marshal(fields) _ = ioutil.WriteFile(\"./index.json\", out, 0755) } 条件查询 思路: 将struct转化为map,根据输入的条件查询.查询的结果转化为struct.代码如下: func FindOne() { product := \u0026Product{} p1 := \u0026Product{ Name: \"John\", Num: 23, } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") switch field2.Kind() { case reflect.Int: field[key] = float64(field2.Interface().(int)) case reflect.Int8: field[key] = float64(field2.Interface().(int8)) case reflect.Int16: field[key] = float64(field2.Interface().(int16)) case reflect.Int32: field[key] = float64(field2.Interface().(int32)) case reflect.Int64: field[key] = float64(field2.Interface().(int64)) case reflect.Uint: field[key] = float64(field2.Interface().(uint)) case reflect.Uint8: field[key] = float64(field2.Interface().(uint8)) case reflect.Uint16: field[key] = float64(field2.Interface().(uint16)) case reflect.Uint32: field[key] = float64(field2.Interface().(uint32)) case reflect.Uint64: field[key] = float64(field2.Interface().(uint64)) case reflect.Float32: field[key] = float64(field2.Interface().(float32)) case reflect.Float64: field[key] = field2.Interface() default: field[key] = field2.Interface() } } _, _ = json.Marshal(p1) // 读取文件中的数据,保存为map格式 // 数据转化为map时,数值类型的统一变成float64 data, _ := ioutil.ReadFile(\"./index.json\") fields := make([]map[string]interface{}, 0) err := json.Unmarshal(data, \u0026fields) if err != nil { log.Fatal(err) } // 查询的条件 columns := []string{\"name\", \"num\"} length := len(columns) for _, item := range fields { for i := 0; i \u003c length; i++ { // 这里的比较需要改进 if item[columns[i]] != field[columns[i]] { break } if i == length-1 { field = item goto OVER } } } OVER: fmt.Println(field) out, _ := json.Marshal(field) _ = json.Unmarshal(out, \u0026product) fmt.Println(product) } 修改操作 修改操作在查询操作的基础上实现, 修改操作需要有一个id值,能确定元素的唯一性.代码如下: func Update() { p1 := \u0026Product{ Id: \"2bbec87025968879c3c9682abe3bf730\", Name: \"John_e\", Num: 100, } // 使用反射将struct转化为map tp := reflect.TypeOf(p1).Elem() vp := reflect.ValueOf(p1).Elem() field := make(map[string]interface{}, 0) for i := 0; i \u003c tp.NumField(); i++ { field1 := tp.Field(i) field2 := vp.Field(i) key := field1.Tag.Get(\"json\") switch field2.Kind() { case reflect.Int: field[key] = float64(field2.Interface().(int)) case reflect.Int8: field[key] = float64(field2.Interface().(int8)) case reflect.Int16: field[key] = float64(field2.Interface().(int16)) case reflect.Int32: field[key] = float64(field2.Interface().(int32)) case reflect.Int64: field[key] = float64(field2.Interface().(int64)) case reflect.Uint: field[key] = float64(field","date":"2019-08-07","objectID":"/golang%E4%BD%BF%E7%94%A8json%E6%A0%BC%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/:0:0","tags":["golang"],"title":"Golang使用json格式实现增删查改","uri":"/golang%E4%BD%BF%E7%94%A8json%E6%A0%BC%E5%BC%8F%E5%AE%9E%E7%8E%B0%E5%A2%9E%E5%88%A0%E6%9F%A5%E6%94%B9/"},{"categories":["运维"],"content":"一、需求 具体实现以下功能：使用 nginx 作为对外的服务机器，让客户端通过访问 nginx 所在的IP+端口的方式能访问内部多个系统，这样一来通过对单台机器作访问控制就可以保证内部系统的访问安全。实现思路如下：在对外的机器上部署 nginx 服务，通过 nginx 虚拟机功能和代理功能相结合实现多组代理。具体场景如下： 代理服务器 代理服务 nginx 192.168.10.10:8080 192.168.10.11:8080 nginx 192.168.10.10:8081 192.168.10.11:9000 二、环境 测试环境如下： 代理服务器：ip 192.168.10.10；系统 CentOS7 ;  需要代理的服务：192.168.10.11:8080 nginx ；192.168.10.11:9000 tomcat 三、配置代理 假如有两个服务需要配置代理，一个 web，一个 tomcat。web 运行在 192.168.10.11:8080 tomcat 运行在 192.168.10.11:9000 现在配置 nginx 代理。 1.安装 nginx先在代理服务器上安装 nginx，使用命令： $ yum install -y nginx 安装成功后就可以尝试启动 nginx 服务器： $ systemctl start nginx 启动服务成功后，nginx 就运行在 80 端口。 2.修改配置文件安装nginx就可以修改配置文件，配置文件的默认路径为  $ ll /etc/nginx/nginx.conf -rw-r--r-- 1 root root 1822 Nov 24 19:30 /etc/nginx/nginx.conf 修改 nginx.conf 如下 # 系统用户 user nginx; # 工作进程数，配置高的机器可以适当增加 worker_processes 4; # 错误日志 error_log /var/log/nginx/error.log; # pid 文件存放目录 pid /run/nginx.pid; events { # linux 使用 epoll 事件机制 use epoll; # 连接数 worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # 配置虚拟机，在该目录下配置多个配置文件对应多台需要代理的机器 include /etc/nginx/conf.d/*.conf; # 配置 https # Settings for a TLS enabled server. # # server { # listen 443 ssl http2 default_server; # listen [::]:443 ssl http2 default_server; # server_name _; # root /usr/share/nginx/html; # # ssl_certificate \"/etc/pki/nginx/server.crt\"; # ssl_certificate_key \"/etc/pki/nginx/private/server.key\"; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 10m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # # # Load configuration files for the default server block. # include /etc/nginx/default.d/*.conf; # # location / { # } # # error_page 404 /404.html; # location = /40x.html { # } # # error_page 500 502 503 504 /50x.html; # location = /50x.html { # } # } } 注意 23 行的配置：include /etc/nginx/conf.d/*.conf; 这个目录下就是要存放代理的配置文件。一般这个文件默认是存在的，如果目录不存在，就创建并修改权限。 $ mkdir /etc/nginx/conf.d $ chmod 755 /etc/nginx/conf.d 3.配置代理文件在这个目录下存放代理服务的文件，最好一个代理对应一个配置文件。我们之前需求上需要代理的服务是两个，直接创建两个代理文件，并修改 # /etc/nginx/conf.d/nginx.conf # 代理的节点 # upstream \u003c代理名称 唯一\u003e upstream nginx_server { # 代理的ip:port,可添加多个ip地址就行负载均衡 server 192.168.10.11:8080; } server { # 监听的地址和端口 # 对应一个代理一个端口 listen 192.168.10.10:8080; # 对外的域名 server_name aaa.test.com; location / { # 代理配置，名称和以上的代理名称对应 proxy_pass http://nginx_server; # 配置使用真实的地址访问，如果不配置此项会导致代理tomcat服务器 400 错误 proxy_set_header Host $host; } } # cat /etc/nginx/conf.d/tomcat.conf upstream tomcat_server { server 192.168.10.11:9000; } server { listen 192.168.10.10:8081; server_name bbb.test.com; location / { proxy_pass http://tomcat_server; proxy_set_header Host $host; } } 修改并保存后，使用 nginx 命令来验证文件的语法： $ # nginx -t nginx: the configuration file /etc/nginx/nginx.conf syntax is ok nginx: configuration file /etc/nginx/nginx.conf test is successful 之后就可以重启 nginx 服务 $ systemctl restart nginx $ netstat -tnlp | grep nginx tcp 0 0 192.168.10.10:8080 0.0.0.0:* LISTEN 11643/nginx: master tcp 0 0 192.168.10.10:8081 0.0.0.0:* LISTEN 11643/nginx: master 可以看到成功绑定两个端口，代理两个服务。通过浏览器访问8080和8081![image.png] 到这里配置就完成了。如果需要再代理，在 /etc/nginx/conf.d 目录下再添加相应的配置文件就可以。如果没有访问成功，请检查各种防火墙和安全策略。 ","date":"2019-07-31","objectID":"/nginx%E5%A4%9A%E7%BB%84%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/:0:0","tags":["linux","nginx"],"title":"Nginx多组代理配置","uri":"/nginx%E5%A4%9A%E7%BB%84%E4%BB%A3%E7%90%86%E9%85%8D%E7%BD%AE/"},{"categories":["笔记"],"content":"制作rpm包的流程 rpm包是redhat和CentOS等linux发行版的包管理工具，能有效的管理系统的软件包，包括添加、删除、升级等操作。所以为了我们自己开发的软件也可以这样容易的管理，我们需要知道怎么制作rpm软件包 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:0:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"安装需要的软件 [root@CentOS1 ~]# yum install -y rpm-build 执行了以上的命令后我们就这里使用rpmbuild这个命令了。 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:1:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"创建rpmbuild 然后就需要创建rpmbuild rpmbuild/ ├── BUILD // 在编译的过程中，有些缓存的数据都会放置在这个目录当中； ├── BUILDROOT // 编译后生成的软件临时安装目录 ├── RPMS // 经过编译之后，并且顺利的编译成功之后，将打包完成的文件放置在这个目录当中。里头有包含了 i386, i586, i686, noarch.... 等等的次目录。 ├── SOURCES // 这个目录当中放置的是该软件的原始档 (*.tar.gz 的文件) 以及 config 这个配置档； ├── SPECS // 这个目录当中放置的是该软件的配置档，例如这个软件的资讯参数、配置项目等等都放置在这里； └── SRPMS // 与 RPMS 内相似的，这里放置的就是 SRPM 封装的文件罗！有时候你想要将你的软件用 SRPM 的方式释出时， 你的 SRPM 文件就会放置在这个目录中了。 [root@CentOS1 ~]# mkdir -p rpmbuild/{BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS} 这个目录就是我们要制作rpm包的相关目录，它里面保存我们需要的各种文件。 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:2:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"创建helloworld.spec文件 接下来来一个简单的demo，先在rpmbuild/SPECS下新建文件helloworld.spec [root@CentOS1 ~]# vim rpmbuild/SPCES/helloworld.spec Name: helloworld Version: 1.0.0 Release: 1%{?dist} Summary: helloworld Group: Development/Tools License: GPL #URL: Source0: %{name}-%{version}.tar.gz #BuildRequires: #Requires: %description %prep %setup -q %build %install mkdir -p $RPM_BUILD_ROOT/usr/bin cp $RPM_BUILD_DIR/%{name}-%{version}/helloworld $RPM_BUILD_ROOT/usr/bin/ %clean rm -rf $RPM_BUILD_ROOT %files %defattr(-,root,root,-) %doc /usr/bin/helloworld %changelog *.spec 文件的内容等下再讲，保存好 helloworld.spec 文件后，还需要再 rpmbuild/SOURCES 目录下添加对应的软件包，软件包的名字和SOURCE0字段对应 [root@CentOS1 ~]# echo \"#! /bin/bash\" \u003e rpmbuild/SOURCES/helloworld-1.0.0/helloworld [root@CentOS1 ~]# echo \"echo 'Hello World'\" \u003e\u003e rpmbuild/SOURCES/helloworld-1.0.0/helloworld [root@CentOS1 ~]# tar -cvf rpmbuild/SOURCES/helloworld-1.0.0.tar.gz rpmbuild/SOURCES/helloworld-1.0.0 rpmbuild/SOURCES/helloworld-1.0.0/ rpmbuild/SOURCES/helloworld-1.0.0/helloworld ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:3:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"制作rpm包 需要的文件都准备好了，就可以制作文件包了。 [root@CentOS1 ~]# rpmbuild -bb rpmbuild/SPECS/helloworld.spec [root@CentOS1 ~]# ls rpmbuild/RPMS/x86_64/helloworld-1.0.0-1.el7.x86_64.rpm rpmbuild/RPMS/x86_64/helloworld-1.0.0-1.el7.x86_64.rpm 生成的rpm包就可以使用 rpm -ivh 命令安装了 spec文件说明 接下来说明spec文件的语法规则。一般的spec文件头包含以下几个域： ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:4:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Name 描述： 软件包的名称，后面可使用%{name}的方式引用 格式： Name: ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:5:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Version 描述： 软件包的名称，后面可使用%{name}的方式引用软件包版本号，后面可使用%{version}引用 格式： Version: ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:6:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Release 描述： 软件包的发行号，后面可使用%{release}引用 格式： Release: ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:7:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Packager 描述： 打包的人（一般喜欢写个人邮箱） 格式： Packager: youner_liucn@126.com ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:8:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"License 描述： 软件授权方式，通常是GPL（自由软件）或GPLv2,BSD 格式： License: GPL ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:9:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Summary 描述： 软件摘要信息 格式： Summary: ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:10:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Group 描述： 软件包所属类别 格式： Group: Applications/Multimedia 具体类别： Amusements/Games（娱乐/游戏） Amusements/Graphics（娱乐/图形） Applications/Archiving（应用/文档） Applications/Communications（应用/通讯） Applications/Databases（应用/数据库） Applications/Editors（应用/编辑器） Applications/Emulators（应用/仿真器） Applications/Engineering（应用/工程） Applications/File（应用/文件） Applications/Internet（应用/因特网） Applications/Multimedia（应用/多媒体） Applications/Productivity（应用/产品） Applications/Publishing（应用/印刷） Applications/System（应用/系统） Applications/Text（应用/文本） Development/Debuggers（开发/调试器） Development/Languages（开发/语言） Development/Libraries（开发/函数库） Development/System（开发/系统） Development/Tools（开发/工具） Documentation （文档） SystemEnvironment/Base（系统环境/基础） SystemEnvironment/Daemons （系统环境/守护） SystemEnvironment/Kernel （系统环境/内核） SystemEnvironment/Libraries （系统环境/函数库） SystemEnvironment/Shells （系统环境/接口） UserInterface/Desktops（用户界面/桌面） User Interface/X（用户界面/X窗口） User Interface/XHardware Support （用户界面/X硬件支持） ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:11:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Source0 描述： 源代码包的名字 格式： Source0: %{name}-%{version}.tar.gz ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:12:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"BuildRoot 描述： 编译的路径。是安装或编译时使用的“虚拟目录”，考虑到多用户的环境，一般定义为： 该参数非常重要，因为在生成rpm的过程中，执行make install时就会把软件安装到上述的路径中，在打包的时候，同样依赖“虚拟目录”为“根目录”进行操作(即%files段)。 后面可使用$RPM_BUILD_ROOT 方式引用。 格式： BuildRoot：%{_tmppath}/%{name}-%{version}-%{release}-buildroot ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:13:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"URL 描述： 软件的主页 格式： URL: ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:14:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Vendor 描述： 发行商或打包组织的信息，例如RedFlagCo,Ltd 格式： Vendor: \u003cRedFlag Co,Ltd\u003e ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:15:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Provides 描述： 指明本软件一些特定的功能，以便其他rpm识别 格式： Provides: 描述：指明本软件一些特定的功能，以便其他rpm识别格式：Provides: ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:16:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"依赖关系 依赖关系定义了一个包正常工作需要依赖的其他包，RPM在升级、安装和删除的时候会确保依赖关系得到满足。rpm支持4种依赖： Requirements, 包依赖其他包所提供的功能 Provides, 这个包能提供的功能 Conflicts, 一个包和其他包冲突的功能 Obsoletes, 其他包提供的功能已经不推荐使用了，这通常是其他包的功能修改了，老版本不推荐使用了，可以在以后的版本中会被废弃。 定义依赖关系的语法是： Requires: capability Provides: capability Obsoletes: capability Conflicts: capability 大部分时候，capability应该是所依赖的包的名称。一行中也可以定义多个依赖，比如： Requires: tbsys tbnet 在指定依赖关系的时候还可以指定版本号，比如:Requires: tbsys \u003e= 2.0 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:17:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"Requires 描述： 所依赖的软件包名称, 可以用\u003e=或\u003c=表示大于或小于某一特定版本。 “\u003e=”号两边需用空格隔开，而不同软件名称也用空格分开。 格式： Requires: libpng-devel \u003e= 1.0.20 zlib 其它写法例如： Requires: bzip2 = %{version}, bzip2-libs =%{version} 或 Requires: perl(Carp)\u003e=3.2 # 需要perl模块Carp 还有例如PreReq、Requires(pre)、Requires(post)、Requires(preun)、Requires(postun)、BuildRequires等都是针对不同阶段的依赖指定。 例如： PreReq: capability\u003e=version # capability包必须先安装 Conflicts:bash\u003e=2.0 # 该包和所有不小于2.0的bash包有冲突 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:18:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"BuildRequires 描述： 编译时的包依赖 格式： BuildRequires: zlib-devel 依赖包格式： ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:19:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"说明%description 软件包详细说明，可写在多个行上。 %description Consul feature - Service Discovery, HealthChecking, KV, Multi Datacenter ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:20:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"预处理%prep 预处理通常用来执行一些解开源程序包的命令，为下一步的编译安装作准备。%prep和下面的%build，%install段一样，除了可以执行RPM所定义的宏命令（以%开头）以外，还可以执行SHELL命令。功能上类似于./configure。作用：用来准备要编译的软件。通常，这一段落将归档中的源代码解压，并应用补丁。这些可以用标准的 shell 命令完成，但是更多地使用预定义的宏。检查标签语法是否正确，删除旧的软件源程序，对包含源程序的tar文件进行解码。如果包含补丁（patch）文件，将补丁文件应用到解开的源码中。它一般包含%setup与%patch两个命令。%setup用于将软件包打开，执行%patch可将补丁文件加入解开的源程序中。 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:21:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"宏%setup 这个宏解压源代码，将当前目录改为源代码解压之后产生的目录。这个宏还有一些选项可以用。例如，在解压后，%setup 宏假设产生的目录是%{name}-%{version}如果 tar 打包中的目录不是这样命名的，可以用 -n 选项来指定要切换到的目录。例如： %setup -n %{name}-April2003Rel %setup-q ：将 tar 命令的繁复输出关闭。 %setup -n newdir ：将压缩的软件源程序在newdir目录下解开。 %setup -c ：在解开源程序之前先创建目录。 %setup -b num ：在包含多个源程序时，将第num个源程序解压缩。 %setup -T ：不使用缺省的解压缩操作。 例如： %setup -T -b 0 //解开第一个源程序文件。 -%setup -c -nnewdir //创建目录newdir，并在此目录之下解开源程序。 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:21:1","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"宏%patch 这个宏将头部定义的补丁应用于源代码。如果定义了多个补丁，它可以用一个数字的参数来指示应用哪个补丁文件。它也接受 -b extension 参数，指示 RPM 在打补丁之前，将文件备份为扩展名是 extension 的文件。 %patch N ：这里N是数字，表示使用第N个补丁文件，等价于%patch-P N -p0 ：指定使用第一个补丁文件，-p1指定使用第二个补丁文件。 -s ：在使用补丁时，不显示任何信息。 -bname ：在加入补丁文件之前，将源文件名上加入name。若为指定此参数，则缺省源文件加入.orig。 -T ：将所有打补丁时产生的输出文件删除 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:21:2","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"编译%build 定义编译软件包所要执行的命令， 这一节一般由多个make命令组成。作用：在这个段落中，包含用来配置和编译已配置的软件的命令。与 Prep 段落一样，这些命令可以是 shell 命令，也可以是宏。如果要编译的宏使用了 autoconf，那么应当用 %configure 宏来配置软件。这个宏自动为 autoconf 指定了安装软件的正确选项，编译优化的软件。如果软件不是用 autoconf 配置的，那么使用合适的 shell 命令来配置它。软件配置之后，必须编译它。由于各个应用程序的编译方法都各自不同，没有用来编译的宏。只要写出要用来编译的 shell 命令就可以了。环境变量 $RPM_OPT_FLAGS 在编译软件时很常用。这个 shell 变量包含针对 gcc 编译器套件的正确的优化选项，使用这样的语法： makeCC=\"gcc $RPM_OPT_FLAGS\" 或者 makeCFLAGS=\"$RPM_OPT_FLAGS\" 就可以保证总是使用合适的优化选项。也可以使用其他编译器标志和选项。默认的 $RPM_OPT_FLAGS 是: -O2 -g-march=i386 -mcpu=i686 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:22:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"安装%install 定义在安装软件包时将执行命令，类似于make install命令。有些spec文件还有%post-install段，用于定义在软件安装完成后的所需执行的配置工作。作用：这个段落用于将已编译的软件安装到虚拟的目录结构中，从而可以打包成一个 RPM。在 Header 段落，可以定义 Buildroot，它定义了虚拟目录树的位置，软件将安装到那里。通常，它是这样的：Buildroot:%{_tmppath}/%{name}-buildroot 使用 RPM 内建的宏来指定 /var/tmp 目录中一个私用的目录。在 spec 文件的其余部分可以用 shell 变量 $RPM_BUILD_ROOT 获取 Buildroot 的值。 mkdir -p $RPM_BUILD_ROOT/usr/share/icons/ cp %{SOURCE3}$RPM_BUILD_ROOT/usr/share/icons/ Install 段落通常列出要将已编译的软件安装到 Buildroot 中的命令 宏 %makeinstall 可以用于安装支持 autoconf 的软件。这个软件自动地将软件安装到 $RPM_BUILD_ROOT 下的正确的子目录中。 有时，软件包必须被构建多次，由于打包错误或其他原因。每次构建时，Install 段落将复制文件到 Buildroot 中。要防止由于 Buildroot 中的旧文件而导致错误的打包，必须在安装新文件之前将 Buildroot 中任何现有的文件删除。为此，可以使用一个 clean 脚本。这个脚本通常以 %clean 标记表示，通常仅仅包含这样一句： rm -rf$RPM_BUILD_ROOT 如果有的话，在制作了在 Install 段落中安装的文件的打包之后，将运行 %clean，保证下次构建之前 Buildroot 被清空。 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:23:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"清理%clean %clean rm-rf $RPM_BUILD_ROOT ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:24:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"文件%files 定义软件包所包含的文件，分为三类：说明文档（doc），配置文件（config）及执行程序，还可定义文件存取权限，拥有者及组别。 这里会在虚拟根目录下进行，千万不要写绝对路径，而应用宏或变量表示相对路径。 如果描述为目录，表示目录中除%exclude外的所有文件。 %defattr (-,root,root) 指定包装文件的属性，分别是(mode,owner,group)，-表示默认值，对文本文件是0644，可执行文件是0755 ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:25:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"更新日志%changelog 每次软件的更新内容可以记录在此到这里，保存到发布的软件包中，以便查询之用。 更复杂的spec Name: oracle-agent Version: 1.0.1 Release: 1%{?dist} Summary: oracle agent Group: Development/Tools License: GPL #URL: Source0: %{name}-%{version}.tar.gz #BuildRequires: #Requires: %define __debug_install_post %{rpmconfigdir}/find-debuginfo.sh %{?find_debuginfo_opts} \"%{_builddir}/%{?buildsubdir}\" %{nil} %description %pre %setup -q %build %install $RPM_BUILD_ROOT # 对应文件系统的根目录，需要的路径要先创建 $RPM_BUILD_DIR # 对应tar解压后的文件目录 mkdir -p $RPM_BUILD_ROOT/etc/init.d/ mkdir -p $RPM_BUILD_ROOT/opt/howlink/oracle-agent cp -r $RPM_BUILD_DIR/%{name}-%{version}/* $RPM_BUILD_ROOT/opt/howlink/oracle-agent/ rm -fr $RPM_BUILD_ROOT/opt/howlink/oracle-agent/debug*.list rm -fr $RPM_BUILD_ROOT/opt/howlink/oracle-agent/elfbins.list cp $RPM_BUILD_ROOT/opt/howlink/oracle-agent/oracle-agent-default.sh $RPM_BUILD_ROOT/etc/init.d/oracle-agent chmod 755 $RPM_BUILD_ROOT/etc/init.d/oracle-agent %post systemctl daemon-reload systemctl start oracle-agent %clean # 这里清理要注意 rm -rf $RPM_BUILD_ROOT/opt/howlink/oracle-agent %files # 生成的文件要这里添加 %defattr(-,root,root,-) %doc /opt/howlink/oracle-agent /etc/init.d/oracle-agent %preun systemctl stop oracle-agent %changelog 问题汇总 rpmbuild报error: Installed (but unpackaged) file(s) found的问题 找到 /usr/lib/rpm/macros 中 %__check_files /usr/lib/rpm/check-files %{buildroot} 注释掉 #%__check_files /usr/lib/rpm/check-files %{buildroot} 意思就是说不要在检查文件了，所以也就不会包file found的报错了 check-rpaths的问题 报error ERROR 0002: file 'xxx.so' contains an invalid rpath 'xxx' in [xxx] 经过网上查询，得知这一步只是一种检测是不是代码中使用了rpath，那我们可以简单的注释掉rpath检测就可以了，具体做法就是： vi ~/.rpmmacros 找到这行 %__arch_install_post /usr/lib/rpm/check-rpaths /usr/lib/rpm/check-buildroot 注释掉 #%__arch_install_post /usr/lib/rpm/check-rpaths /usr/lib/rpm/check-buildroot .在生成rpm包同时，还会生成debuginfo包，如果要避免生成debuginfo包：这个是默认会生成的rpm包。则可以使用下面的命令： echo '%debug_package %{nil}' \u003e\u003e ~/.rpmmacros 把%debug_package %{nil} 追加到 ~/.rpmmacros 文件中便可。 (%prep)阶段提示包找不到 可以是软件的包解压后不会生成一个对应的目录，两个解决方式： 1.重新修改tar包 2.%setup -c ","date":"2019-05-29","objectID":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/:26:0","tags":["linux"],"title":"制作rpm包","uri":"/%E5%88%B6%E4%BD%9Crpm%E5%8C%85/"},{"categories":["笔记"],"content":"友元说明 相对于其他的编程语言，“友元”是C++中特别的一种语法。那它有什么作用呢？ 其实“友元”就是提供一种访问类私有部分的的方法。如果没有“友元”，我们只能通过类本身提供的公有方法来访问，但相对地，这样限制太高了，所以“友元”就是一种的在类的封装性和实用性中很好的“折中”方式。 C++中的友元有三种： 友元函数 友元类 友元成员函数 C++中使用关键字friend来定义。 友元函数 这里直接用代码来说明： #include \u003ciostream\u003e#include \u003cstring\u003e class Person { private: std::string account; std::string passwd; public: Person(std::string ac, std::string pw); // 这里使用friend关键字，指定Point中的getPerson方法可以使用Person类的私有变量。 friend void getPerson(Person \u0026p); }; Person::Person(std::string ac, std::string pw) { account = ac; passwd = pw; } void getPerson(Person \u0026p) { // 因为定义了友元，这里就可以访问Person类的私有变量了。 std::cout \u003c\u003c \"account: \" \u003c\u003c p.account \u003c\u003c \", passwd: \" \u003c\u003c p.passwd \u003c\u003c std::endl; } int main() { Person p(\"xingyys\", \"123456\"); getPerson(p); return 0; } 这个例子还是比较简单的，只要在指定的方法中添加关键字就可以实现了。 友元类 在来一个例子说明： #include \u003ciostream\u003e#include \u003cstring\u003e class Tv { private: int state; int volume; int maxchannel; int channel; int mode; int input; public: // 在这里指定谁是他的友元 friend class Remote; enum { Off, On }; enum { MinVal, MaxVal = 20 }; enum { Antenna, Cable }; enum { TV, DVD }; Tv(int s = Off, int mc = 125) : state(s), volume(5), maxchannel(mc), channel(2), mode(Cable), input(TV) {} void onoff() { state = (state == On) ? Off : On; } bool ison() const { return state == On; } bool volup(); bool voldown(); void chanup(); void chandown(); void set_mode() { mode = (mode == Antenna) ? Cable : Antenna; } void set_input() { input = (input == TV) ? DVD : TV; } void settings() const; }; class Remote { private: int mode; public: Remote(int m = Tv::TV) : mode(m) {} bool volup(Tv \u0026t) { return t.volup(); } bool voldown(Tv \u0026t) { return t.voldown(); } void onoff(Tv \u0026t) { t.onoff(); } void chanup(Tv \u0026t) { t.chanup(); } void chandown(Tv \u0026t) { t.chandown(); } void set_chan(Tv \u0026t, int c) { t.channel = c; } void set_mode(Tv \u0026t) { t.set_mode(); } void set_input(Tv \u0026t) { t.set_input(); } }; bool Tv::volup() { if (volume \u003c MaxVal) { volume++; return true; } else { return false; } } bool Tv::voldown() { if (volume \u003e MinVal) { volume--; return true; } else { return false; } } void Tv::chanup() { if (channel \u003c maxchannel) channel++; else channel = 1; } void Tv::chandown() { if (channel \u003e 1) channel--; else channel = maxchannel; } void Tv::settings() const { using std::cout; using std::endl; cout \u003c\u003c \"TV is \" \u003c\u003c (state == Off ? \"Off\" : \"On\") \u003c\u003c endl; if (state == On) { cout \u003c\u003c \"Volume setting = \" \u003c\u003c volume \u003c\u003c endl; cout \u003c\u003c \"Channel setting = \" \u003c\u003c channel \u003c\u003c endl; cout \u003c\u003c \"Mode = \" \u003c\u003c (mode == Antenna ? \"antenna\" : \"cable\") \u003c\u003c endl; cout \u003c\u003c \"Input = \" \u003c\u003c (input == TV ? \"TV\" : \"DVD\") \u003c\u003c endl; } } int main() { using std::cout; Tv s42; cout \u003c\u003c \"Initial setting for 42\\\"TV:\\n\"; s42.settings(); s42.onoff(); s42.chanup(); cout \u003c\u003c \"\\nAdjusted setting for 42\\\"TV:\\n\"; s42.chanup(); cout \u003c\u003c \"\\nAdjusted settings for 42\\\"TV:\\n\"; s42.settings(); Remote grey; grey.set_chan(s42, 10); grey.volup(s42); grey.volup(s42); cout \u003c\u003c \"\\n42\\\"setting after using remote:\\n\"; s42.settings(); Tv s58(Tv::On); s58.set_mode(); grey.set_chan(s58, 28); cout \u003c\u003c \"\\n58\\\"settings:\\n\"; s58.settings(); return 0; } 友元成员函数 #include \u003ciostream\u003e#include \u003cstring\u003e class Person; class Point { public: void getPerson(Person \u0026p); }; class Person { private: std::string account; std::string passwd; public: Person(std::string ac, std::string pw); // 这里使用friend关键字，指定Point中的getPerson方法可以使用Person类的私有变量。 friend void Point::getPerson(Person \u0026p); }; Person::Person(std::string ac, std::string pw) { account = ac; passwd = pw; } void Point::getPerson(Person \u0026p) { // 因为定义了友元，这里就可以访问Person类的私有变量了。 std::cout \u003c\u003c \"account: \" \u003c\u003c p.account \u003c\u003c \", passwd: \" \u003c\u003c p.passwd \u003c\u003c std::endl; } int main() { Person p (\"xingyys\", \"123456\"); Point pt; pt.getPerson(p); return 0; } 补充 不能定义类的对象。 可以用于定义指向这个类型的指针或引用。 用于声明(不是定义)，使用该类型作为形参类型或者函数的返回值类型。 友元关系不能被继承。 友元关系是单向的，不具有交换性。若类B是类A的友元，类A不一定是类B的友元，要看在类中是否有相应的声明。 友元关系不具有传递性。若类B是类A的友元，类C是B的友元，类C不一定是类A的友元，同样要看类中是否有相应的申明 ","date":"2019-05-11","objectID":"/c-%E5%8F%8B%E5%85%83/:0:0","tags":["C++"],"title":"C++友元","uri":"/c-%E5%8F%8B%E5%85%83/"},{"categories":["运维"],"content":"最近项目需要再 windows 上做开发，而且一些自动化的处理需要使用 windows 的的脚本。所以做些记录，防止遗忘。 基本的语法 首先从基础开始吧，之前都是使用 linux bash 的。可以说 windows bat 脚本和 linux bash 脚本还是有很多区别的。 ","date":"2019-03-22","objectID":"/bat/:0:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["运维"],"content":"设置变量 变量设置使用的命令为set。 set a=\"hello world\" echo %a% 从上面的脚本中可以知道，使用set来设置变量，语法为set var=\u003c值\u003e。如果要引用这个变量的话就使用%var%。 注：bat 脚本不能像 bash 中一样设置临时变量，只用将变量设置为环境变量。 set命令的功能还是比较强大的，比如获取从键盘中输入的字符： set /p a=\"Input a number:\" echo %a% 支持算术： set /a a=1+2 echo %a% set /a a-=1 echo %a% set /a a*=3 echo %a% set /a a/=3 echo %a% 这个关键在于set /a 还有字符串的修改和截取： :::::::::: 字符串的截取 :::::::::: set a=Hello Windows Bat :: 截取所有 set a=%a:~0% :: 截取指定的 set a=%a:~1,-1% set a=%a:~2,4% :::::::::: 字符串的替换 :::::::::: set a=Hello Windows :: 将Windows替换成Linux set a=%a:Windows=Linux% ","date":"2019-03-22","objectID":"/bat/:1:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["运维"],"content":"注释 bat 中能实现注释功能的有两个::和rem。 它们的不同点是：rem是一条命令，在运行的时候相当于把rem本身及其后面的内容置空。既然它是一条命令，就必须处于单独的一行或者有类似 “\u0026” 的连接符号连接。 bat 遇到以冒号 “:” 开头的行时（忽略冒号前的空格），会将其后的语句识别为“标记”而不是命令语句，因此类似 “:label” 这样的在 bat 中仅仅是一个标记。 注: 使用 bat 中的注释时需要注意一点，不要再 () 的边上使用注释。 ","date":"2019-03-22","objectID":"/bat/:2:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["运维"],"content":"条件判断 bat 中的条件判断也是使用if。 set a=1 if %a%==1 ( echo OK ) else ( echo ERROR ) 如果时判断字符串使用为空时,可以这样处理: set a=\"hello\" if (%a%)==() ( echo OK ) else ( echo ERROR ) ","date":"2019-03-22","objectID":"/bat/:3:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["运维"],"content":"循环语句 bat 中的循环有些不同。关键字也是for。还是先来看一个例子： for /f \"delims=: tokens=1,2,3\" %%i in ( \"2018:04:11\" ) do ( echo %%i echo %%j ) 这段脚本中需要注意的点是：delims=:表示使用 “:” 来分割字符串，而tokens=1,2,3则表示取出分割后的字符串的部分，从1开始。%%i是循环中的每个项。输出时%%i和%%j分别对应的就是截取的字段1和2。如果还需要输出第三个，也是使用%%k表示，依次类推。 但 bat 中的for会存在延迟赋值的情况，先来看一段脚本: for /f \"delims=: tokens=2\" %%i in ( 'ipconfig /all ^| findstr /i \"ipv4\" ' ) do ( echo %%i set a=%%i echo %a% ) 输出结果: IPv4 地址 . . . . . . . . . . . . : 192.168.168.1(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 IPv4 地址 . . . . . . . . . . . . : 192.168.157.1(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.160(首选 %a%的值一直等于最后一项。 ","date":"2019-03-22","objectID":"/bat/:4:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["运维"],"content":"函数 bat 中函数是使用:label方式定义的，使用call来调用: call :test Hello World goto EXIT :test echo %1 %2 :EXIT 脚本中的goto用来跳转退出，而且函数要放在脚本的尾部，存在多个函数时还需要使用goto直接跳转，因为脚本是会按顺序执行下去的。 实战操作 @echo off set option=%1 set address=%2 if (%option%) == () ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) if (%address%) == () ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) if %option% == start ( call :start %address% ) else if %option% == stop ( call :stop %address% ) else ( echo \"Usage: connectIscsi.bat \u003cstart|stop\u003e \u003caddress\u003e\" goto EXIT ) ::sc config msiscsi start=auto ::net start msiscsi goto EXIT :: 连接iscsi服务器 :start iscsicli QAddTargetPortal %1 for /f \"delims= tokens=1\" %%i in ( 'iscsicli ListTargets t ^| findstr /i \"iqn.2018-11\" ' ) do ( iscsicli qlogintarget %%i ) goto EXIT :: 断开iscsi服务器 :stop set a= for /f \"delims=: tokens=2\" %%i in ('iscsicli SessionList ^| findstr /i \"fffffa8\"') do ( set a=%%i goto return ) :return set a=%a: =0x% set a=%a:-=-0x% iscsicli LogoutTarget %a% iscsicli RemoveTargetPortal %1 3260 goto EXIT :EXIT 这个脚本是用来连接和断开iscsi服务器的。脚本有两个入参，option 和 address。连接和断开iscsi服务器。脚本的思路很简单，开始判断输入参数是否正确。然后根据 option 选择执行对应的函数。特别在:stop中，因为延时复制的关系，所以循环体中只放简单的复制，处理部分在外面进行处理。 后记 ","date":"2019-03-22","objectID":"/bat/:5:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["运维"],"content":"延时赋值问题 bat 的延时赋值有对应的解决方法： SETLOCAL ENABLEDELAYEDEXPANSION set a=hello set a=!a! set a=!a:~1! ","date":"2019-03-22","objectID":"/bat/:6:0","tags":["bat","脚本"],"title":"Windows Bat总结","uri":"/bat/"},{"categories":["笔记","代码"],"content":"打包 // 打包 func Compress(destPath, srcDir string) error { // 压缩文件路径 fw, err := os.Create(destPath) if err != nil { return err } defer fw.Close() // gzip writer gw := gzip.NewWriter(fw) defer gw.Close() // tar writer tw := tar.NewWriter(gw) defer tw.Close() // 读取要压缩的目录 dir, err := os.Open(srcDir) if err != nil { return err } defer dir.Close() // 读取目录内容 files, err := dir.Readdir(0) if err != nil { return err } for _, file := range files { if file.IsDir() { continue } // 路径补全 filePath := path.Join(dir.Name(), file.Name()) fread, err := os.Open(filePath) if err != nil { continue } // 获取文件头部信息 h := \u0026tar.Header{} h.Name = file.Name() h.Size = file.Size() h.Mode = int64(file.Mode()) h.ModTime = file.ModTime() err = tw.WriteHeader(h) if err == nil { // 开始压缩，这里等于忽略错误 io.Copy(tw, fread) } // 记得关闭文件 fread.Close() } return nil } 解包 // 解压 func DeCompress(srcPath, destDir string) error { // 解压包的路径 fread, err := os.Open(srcPath) if err != nil { return err } defer fread.Close() // 检测目标路径是否存在 _, err = os.Stat(destDir) if err != nil { return err } // gzip reader gr, err := gzip.NewReader(fread) if err != nil { return err } defer gr.Close() // tr reader tr := tar.NewReader(gr) for { // 获取下一个文件 h, err := tr.Next() // 读取完毕 if err == io.EOF { break } if err != nil { continue } fw, err := os.OpenFile(path.Join(destDir, h.Name), os.O_CREATE|os.O_WRONLY, 0644) if err == nil { io.Copy(fw, tr) fw.Close() } } return nil } ","date":"2019-02-15","objectID":"/golang%E6%89%93%E5%8C%85%E5%92%8C%E8%A7%A3%E5%8C%85/:0:0","tags":["golang"],"title":"golang打包和解包","uri":"/golang%E6%89%93%E5%8C%85%E5%92%8C%E8%A7%A3%E5%8C%85/"},{"categories":["笔记"],"content":"需求和分析 在一次项目中需要将进行oracle数据库的备份，要求在oracle机器总是能认到备份的块设备的路径以保证备份和恢复的正常。同时还需要对磁盘进行修改，转化中asm格式的。 基于这种情况下，在linux中将磁盘转化成对应的裸设备是一种合适的方法。 简单的操作就是将配置写入/etc/udev/rule.d/1401-oracle-asmdevice.rules文件中，让udev管理。 udev 规则的匹配键 ACTION： 事件 (uevent) 的行为，例如：add( 添加设备 )、remove( 删除设备 )。 KERNEL： 内核设备名称，例如：sda, cdrom。 DEVPATH：设备的 devpath 路径。 SUBSYSTEM： 设备的子系统名称，例如：sda 的子系统为 block。 BUS： 设备在 devpath 里的总线名称，例如：usb。 DRIVER： 设备在 devpath 里的设备驱动名称，例如：ide-cdrom。 ID： 设备在 devpath 里的识别号。 SYSFS{filename}： 设备的 devpath 路径下，设备的属性文件“filename”里的内容。 例如：SYSFS{model}==“ST936701SS”表示：如果设备的型号为 ST936701SS，则该设备匹配该 匹配键。 在一条规则中，可以设定最多五条 SYSFS 的 匹配键。 ENV{key}： 环境变量。在一条规则中，可以设定最多五条环境变量的 匹配键。 PROGRAM：调用外部命令。 RESULT： 外部命令 PROGRAM 的返回结果。 配置文件 这里是CentOS 6的版本 [root@rac1 ~]# cat /etc/udev/rules.d/99-oracle-asmdevice.rules KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\",RESULT==\"360000000000000000e00000000020fa8\",NAME+=\"oracleasm/disks/HL_360000000000000000e00000000020fa8\",OWNER=\"grid\",GROUP=\"asmadmin\",MODE=\"0660\" 然后加载配置文件 [root@rac1 ~]# start_udev 正在启动 udev： [确定] [root@rac1 ~]# ll /dev/oracleasm/disks 总用量 0 brw-rw---- 1 grid asmadmin 8, 16 1月 23 14:30 HL_360000000000000000e00000000020fa8 注意 在CentOS6和CentOS7的配置有所不同。 一个是scsi_id命令，还有是udev规则变化。 KERNEL==\"sd*\",SUBSYSTEM==\"block\",PROGRAM==\"/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\",RESULT==\"360000000000000000e00000000160fa8\",RUN+=\"/bin/sh -c 'mkdir -pv /dev/oracleasm/disks;mknod /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8 b 1 3; chown grid:oinstall /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8; chmod 0660 /dev/oracleasm/disks/HL_360000000000000000e00000000160fa8'\" scsi_id命令需要安装systemd包，如果知道命令对应的软件包名称，可以使用yum命令查看 yum provides \"/*/scsi_id\" udev需要使用RUN来代替NAME，在RUN中能使用linux的命令，使用；分隔多个命令。 mknod是CentOS7中转化设备的新命令，格式为： mknod /dev/sdb \u003cDEVICE_TYPE\u003e \u003c主设备号\u003e \u003c次设备号\u003e 同时修改udev的命令也发生了变化。 [root@localhost ~]# /usr/sbin/udevadm trigger --type=devices --action=change 在同时添加多个设备时，后添加的设备同步较慢。比较好的方法是先全部添加到.rules文件中，最后再执行udevadm trigger加载。 ","date":"2019-01-26","objectID":"/linux%E4%B8%8A%E4%BD%BF%E7%94%A8udev%E5%88%9B%E5%BB%BA%E8%A3%B8%E8%AE%BE%E5%A4%87/:0:0","tags":["linux"],"title":"linux上使用udev创建裸设备","uri":"/linux%E4%B8%8A%E4%BD%BF%E7%94%A8udev%E5%88%9B%E5%BB%BA%E8%A3%B8%E8%AE%BE%E5%A4%87/"},{"categories":["运维"],"content":"iscsi简单介绍 iSCSI（Internet Small Computer System Interface，发音为/ˈаɪskʌzi/），Internet小型计算机系统接口，又称为IP-SAN，是一种基于因特网及SCSI-3协议下的存储技术，由IETF提出，并于2003年2月11日成为正式的标准。与传统的SCSI技术比较起来，iSCSI技术有以下三个革命性的变化： 把原来只用于本机的SCSI协义透过TCP/IP网络发送，使连接距离可作无限的地域延伸； 连接的服务器数量无限（原来的SCSI-3的上限是15）； 由于是服务器架构，因此也可以实现在线扩容以至动态部署。 简单的说就是tcp协议仿真scsi，将本地的磁盘通过网络共享给其他机器，提供数据的远程存储。 iscsi基本概念 iscsi中有一些常用的基本概念，了解这些能帮助我们认识iscsi服务的具体工作原理，下面就用一张图表来说明： 名词 说明 ACL 访问权限控制列表，用来验证客户端启动器的访问，通常是客户端 iSCSI 启动器的 IQN 名称 IQN 用于标识单个 iSCSI 目标和启动器的唯一名称(全部小写) WWN 用于标识单个光纤通道端口和节点的唯一编号 TARGET iSCSI 服务器上的存储资源 LUN iSCSI 服务器上的块设备 initiator(启动器) 以软件或硬件实施的 iSCSI 客户端 NODE 单个 iSCSI 启动器或者目标 TPG 启动器或者目标上的单个 IP 连接地址 Portal 网络接口及端口 iscsi 安装配置 iscsi 服务管理的软件有多个，这里就简单介绍两个，targetcli和tgt。 ","date":"2019-01-26","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:0:0","tags":["linux"],"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":["运维"],"content":"使用targetcli管理配置iscsi 1.准备阶段 有两台linux机器，分别作为服务端和客户端。实验环境最好在虚拟机上，方便修改的反复操作。同时在服务端上有一块磁盘作为iscsi共享磁盘。 [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 4G 0 part [SWAP] └─sda3 8:3 0 35.5G 0 part / sdb 8:16 0 10G 0 disk └─sdb1 8:17 0 10G 0 part sdc 8:32 0 10G 0 disk sr0 11:0 1 1024M 0 rom 这个选择/dev/sdb1,没有的同学可以使用fdisk命令自己分配一个。 2.安装targetcli yum install -y targetcli 还需要启动targetcli服务 systemctl start target 3.配置targetcli 配置targetcli有几个步骤，添加target，在target上添加lun，将target共享到指定网段。 先来创建一个块设备，使用命令为： /backstores/block create westos:storage1 /dev/sdb1 进入targetcli操作： [root@localhost ~]# targetcli Warning: Could not load preferences file /root/.targetcli/prefs.bin. targetcli shell version 2.1.fb46 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type 'help'. /\u003e /backstores/block create westos:storage1 /dev/sdb1 Created block storage object westos:storage1 using /dev/sdb1. # 注意这里就成功创建一个快设备 /\u003e ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- westos:storage1 .............................................................. [/dev/sdb1 (0 bytes) write-thru deactivated] | | o- alua ................................................................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ....................................................................... [ALUA state: Active/optimized] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ............................................................................................................ [Targets: 0] o- loopback ......................................................................................................... [Targets: 0] /\u003e 接着创建一个iscsi共享的target，使用命令为： /iscsi create iqn.2018-10.com.westos:storage1 这里的target名称其实可以随意，但一般格式为iqn.year.month.com.domain.xxx, 执行的结果如下： /\u003e /iscsi create iqn.2018-10.com.westos:storage1 Created target iqn.2018-10.com.westos:storage1. Created TPG 1. Global pref auto_add_default_portal=true Created default portal listening on all IPs (0.0.0.0), port 3260. /\u003e ls o- / ......................................................................................................................... [...] o- backstores .............................................................................................................. [...] | o- block .................................................................................................. [Storage Objects: 1] | | o- westos:storage1 .............................................................. [/dev/sdb1 (0 bytes) write-thru deactivated] | | o- alua ................................................................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ....................................................................... [ALUA state: Active/optimized] | o- fileio ................................................................................................. [Storage Objects: 0] | o- pscsi .................................................................................................. [Storage Objects: 0] | o- ramdisk ................................................................................................ [Storage Objects: 0] o- iscsi ........................","date":"2019-01-26","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:1:0","tags":["linux"],"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":["运维"],"content":"使用tgt配置iscsi 再来介绍另外一种软件，就是tgt。 1.安装 yum install -y epel-release yum install -y scsi-target-utils 启动服务 systemctl start tgtd 2.配置tgt 配置tgt使用的命令是tgtadm，有以下常用选项： –lld –mode target –op new –tid –targetname # 新建target –lld –mode target –op delete [–force] –tid # 删除target –lld –mode target –op show # 查看所有的target –lld –mode target –op show –tid # 查看指定id的target –lld –mode target –op update –tid –name –value # 更新target –lld –mode target –op bind –tid –initiator-address # target共享到指定网段 –lld –mode target –op bind –tid –initiator-name # target共享到指定的客户端名称 –lld –mode target –op unbind –tid –initiator-address # 解绑 –lld –mode target –op unbind –tid –initiator-name –lld –mode logicalunit –op new –tid –lun –backing-store –bstype –bsopts –bsoflags # 创建lun –lld –mode logicalunit –op delete –tid –lun # 删除lun –lld –mode account –op new –user –password # 添加认证 –lld –mode account –op delete –user # 删除认证 –lld –mode account –op bind –tid –user [–outgoing] # 绑定认证 –lld –mode account –op unbind –tid –user [–outgoing] # 解绑认证 添加target [root@localhost ~]# tgtadm --lld iscsi --mode target --op new --tid 1 --targetname iqn-2019-11.com.iscsi.test [root@localhost ~]# tgtadm --lld iscsi --mode target --op show Target 1: iqn-2019-11.com.iscsi.test System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: Account information: ACL information: 添加lun [root@localhost ~]# tgtadm --lld iscsi --mode logicalunit --op new --tid 1 --lun 22 -b /dev/sdb [root@localhost ~]# tgtadm --lld iscsi --mode target --op show Target 1: iqn-2019-11.com.iscsi.test System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: LUN: 22 Type: disk SCSI ID: IET 00010016 SCSI SN: beaf122 Size: 10737 MB, Block size: 512 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: rdwr Backing store path: /dev/sdb Backing store flags: Account information: ACL information: 注：这里有一个小提示，每个lun中的SCSI ID项是在客户端中的唯一标识，它的值是根据target id和lun id计算得到的，即： SCSI ID = Target ID转16进制(前四位) + Lun ID转16进制(后四位) 所以lun 22的SCSI ID为00010016 共享到客户端： [root@localhost ~]# tgtadm --lld iscsi --mode target --op bind --tid 1 --initiator-address 192.168.3.131 ","date":"2019-01-26","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:2:0","tags":["linux"],"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":["运维"],"content":"客户端连接 1.安装客户端 yum install -y epel-release yum install -y iscsi-initiator-utils 客户端命令： iscsiadm -m session # 查看所有会话 iscsiadm -m discovery -t st -p 192.168.3.150 #查看共享target iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -p 192.168.3.150 -l #登陆连接 iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -u #退出登陆 iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -o delete #删除登陆数据 2.发现设备 [root@localhost ~]# iscsiadm -m discovery -t st -p 192.168.3.150 192.168.3.150:3260,1 iqn.2018-10.com.westos:storage1 登录 注：请关闭防火墙和selinux [root@localhost mnt]# iscsiadm -m node -T iqn.2018-10.com.westos:storage1 -p 192.168.3.150 -l Logging in to [iface: default, target: iqn.2018-10.com.westos:storage1, portal: 192.168.3.150,3260] (multiple) Login to [iface: default, target: iqn.2018-10.com.westos:storage1, portal: 192.168.3.150,3260] successful. [root@localhost ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT fd0 2:0 1 4K 0 disk sda 8:0 0 40G 0 disk ├─sda1 8:1 0 500M 0 part /boot ├─sda2 8:2 0 8G 0 part [SWAP] └─sda3 8:3 0 31.5G 0 part / sdb 8:16 0 2G 0 disk └─sdb1 8:17 0 2G 0 part sr0 11:0 1 1024M 0 rom 同时在/dev/disk/by-id下生成块设备。 ","date":"2019-01-26","objectID":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/:3:0","tags":["linux"],"title":"iscsi共享磁盘服务","uri":"/iscsi%E5%85%B1%E4%BA%AB%E7%A3%81%E7%9B%98%E6%9C%8D%E5%8A%A1/"},{"categories":["笔记"],"content":"今天重新整理了下博客，发现之前配置好的七牛云图片显示错误。重新配置的同时也记录下配置步骤。 添加域名 登录七牛云的官网融合CDN，在“域名管理”中“添加域名”，如图： 填写“加速域名”字段为image.xingyys.club 其他默认。 解析DNS 在添加完域名后，直接会在后台审核。 鼠标停在表格上获取CNAME，image.xingyys.club.qiniudns.com。之后就是在域名后台上添加解析。我的是腾讯云的域名，添加一条CNAME解析： 1.主机记录为二级域名。 2.记录类型为CNAME。 3.线路类型默认。 4.记录值为刚才获取的七牛云CNAME。 然后保存即可。 绑定存储空间 在七牛云的控制台，“对象存储”里“新建存储空间” 最后在新建的存储空间里面在绑定刚添加的二级域名： 配置完成。 ","date":"2019-01-19","objectID":"/%E9%85%8D%E7%BD%AE%E4%B8%83%E7%89%9B%E4%BA%91%E5%AD%98%E5%82%A8%E5%A4%96%E9%93%BE/:0:0","tags":["其他"],"title":"配置七牛云存储外链","uri":"/%E9%85%8D%E7%BD%AE%E4%B8%83%E7%89%9B%E4%BA%91%E5%AD%98%E5%82%A8%E5%A4%96%E9%93%BE/"},{"categories":["存储"],"content":"scaleio-gateway是EMC ScaleIO存储的网关接口，通过调用其api能实现EMC存储软件的管理。下面来介绍怎么安装和配置： 一、安装 1.直接是使用rpm软件安装：gateway运行环境需要 java1.8，内存大于3G # 先配置gateway admin用户的密码 [root@localhost ~]# export GATEWAY_ADMIN_PASSWORD=Scale10 [root@localhost ~]# rpm -ivh /tmp/EMC-ScaleIO-gateway-2.6-11000.113.x86_64.rpm # 安装成功后服务默认启动，绑定在端口80 [root@localhost ~]# netstat -tnlp | grep 80 tcp6 0 0 :::80 :::* LISTEN 4225/java 二、配置 安装完gateway还需要配置，gateway的配置有两种方式。 使用浏览器配置。 直接修改配置文件。 使用浏览器配置使用浏览器输入地址 https://\u003c主机ip\u003e，输入用户名密码(admin/Scale10)后登陆 输入后 直接修改配置文件 [root@localhost ~]# vim /opt/emc/scaleio/gateway/webapps/ROOT/WEB-INF/classes/gatewayUser.properties // 修改以下字段 // scaleio管理的ip地址，使用,或;隔开 mdm.ip.addresses=192.168.3.200;192.168.3.201 // 允许非加密的通讯 gateway-security.allow_non_secure_communication=true // 防止主从切换中gateway错误 security.bypass_certificate_check=true // 记得重启gateway服务 [root@localhost ~]# /etc/init.d/scaleio-gateway restart 三、验证 使用浏览器登陆 https://\u003c主机ip\u003e/api/login 验证curl命令验证验证： [root@localhost ~]# curl -k --user admin:Scale10 https://192.168.3.107/api/login \"YWRtaW46MTU1ODA5ODgyNjQyODozMDVjYWQ3NjljNWFlNWU4ZWI2MDcxZGNiNmI4MmMzMA\" ","date":"2018-08-31","objectID":"/%E5%AE%89%E8%A3%85scaleio-gateway/:0:0","tags":["linux","scaleio"],"title":"安装scaleio Gateway","uri":"/%E5%AE%89%E8%A3%85scaleio-gateway/"},{"categories":["虚拟化"],"content":" 注：运行kvm保证机器支持虚拟化且在bios中开启。 准备工作 ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:0:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"清除iptables规则 # CentOS6 service iptables stop; service iptables save # CentOS7 systemctl stop firewalld ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:1:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"关闭selinux sed -i 's/SELINUX=enforcing/SELINUX=disabled/' /etc/selinux/config setenforce 0 ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:2:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"检测系统是否支持虚拟化 grep -Ei 'vmx|svm' /proc/cpuinfo 如果有输出内容，则支持，其中intel cpu支持会有vmx，amd cpu支持会有svm 安装 ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:3:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"执行安装命令 yum install -y kvm virt-* libvirt bridge-utils qemu-img 说明： kvm:软件包中含有KVM内核模块，它在默认linux内核中提供kvm管理程序 libvirt:安装虚拟机管理工具，使用virsh等命令来管理和控制虚拟机。 bridge-utils:设置网络网卡桥接。 virt-*:创建、克隆虚拟机命令，以及图形化管理工具virt-manager qemu-img:安装qemu组件，使用qemu命令来创建磁盘等。 ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:4:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"检查kvm模块是否加载 lsmod |grep kvm 结果输出： kvm_intel 55496 3 kvm 337772 1 kvm_intel 如果没有，需要执行，还没有就重启一下试试 modprobe kvm-intel ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:5:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"配置网卡 cd /etc/sysconfig/network-scripts/ cp ifcfg-eth0 ifcfg-br0 编辑eth0 DEVICE=eth0 HWADDR=00:0C:29:55:A7:0A TYPE=Ethernet UUID=2be47d79-2a68-4b65-a9ce-6a2df93759c6 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=none BRIDGE=br0 编译br0 DEVICE=br0 #HWADDR=00:0C:29:55:A7:0A TYPE=Bridge #UUID=2be47d79-2a68-4b65-a9ce-6a2df93759c6 ONBOOT=yes NM_CONTROLLED=yes BOOTPROTO=static IPADDR=192.168.11.17 NETMASK=255.255.255.0 GATEWAY=192.168.11.1 DNS1=202.106.0.20 记得重启网卡：/etc/init.d/network restart br0 Link encap:Ethernet HWaddr 00:0C:29:55:A7:0A inet addr:192.168.11.17 Bcast:192.168.11.255 Mask:255.255.255.0 inet6 addr: fe80::20c:29ff:fe55:a70a/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:141326 errors:0 dropped:0 overruns:0 frame:0 TX packets:90931 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:456024940 (434.8 MiB) TX bytes:10933593 (10.4 MiB) eth0 Link encap:Ethernet HWaddr 00:0C:29:55:A7:0A inet6 addr: fe80::20c:29ff:fe55:a70a/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:341978 errors:0 dropped:0 overruns:0 frame:0 TX packets:90946 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:468848861 (447.1 MiB) TX bytes:10934699 (10.4 MiB) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 inet6 addr: ::1/128 Scope:Host UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) virbr0 Link encap:Ethernet HWaddr 52:54:00:14:EF:D5 inet addr:192.168.122.1 Bcast:192.168.122.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:6:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"启动服务 /etc/init.d/libvirtd start /etc/init.d/messagebus restart 此时可以查看网络接口列表 $ brctl show bridge name bridge id STP enabled interfaces br0 8000.000c2955a70a no eth0 virbr0 8000.52540014efd5 yes virbr0-nic 创建虚拟机 创建一个存储虚拟机虚拟磁盘的目录，该目录所在分区必须足够大 mkdir /data/ 执行命令： virt-install \\ --name ping \\ --ram 512 \\ --disk path=/data/ping.img,size=20 \\ --vcpus 1 \\ --os-type linux \\ --os-variant rhel6 \\ --network bridge=br0 \\ --graphics none \\ --console pty,target_type=serial \\ --location 'http://mirrors.163.com/centos/6.8/os/x86_64/' \\ --extra-args 'console=ttyS0,115200n8 serial' 说明： –name 指定虚拟机的名字 –ram 指定内存分配多少 –disk path 指定虚拟磁盘放到哪里，size=30 指定磁盘大小为30G,这样磁盘文件格式为raw，raw格式不能做快照，后面有说明，需要转换为qcow2格式，如果要使用qcow2格式的虚拟磁盘，需要事先创建qcow2格式的虚拟磁盘。 参考 http://www.361way.com/kvm-qcow2-preallocation-metadata/3354.html 示例:qemu-img create -f qcow2 -o preallocation=metadata /data/test02.img 7G; –disk path=/data/test02.img,format=qcow2,size=7,bus=virtio –vcpus 指定分配cpu几个 –os-type 指定系统类型为linux –os-variant 指定系统版本 –network 指定网络类型 –graphics 指定安装通过哪种类型，可以是vnc，也可以没有图形，在这里我们没有使用图形直接使用文本方式 –console 指定控制台类型 –location 指定安装介质地址，可以是网络地址，也可以是本地的一个绝对路径，（–location ‘/mnt/’, 其中/mnt/下就是我们挂载的光盘镜像mount /dev/cdrom /mnt)如果是绝对路径，那么后面还需要指定一个安装介质，比如NFS 之后就出现： 开始安装...... 搜索文件 .treeinfo...... | 720 B 00:00 ... 搜索文件 vmlinuz...... | 7.7 MB 00:02 ... 搜索文件 initrd.img...... | 63 MB 00:23 ... 创建存储文件 ping.img | 30 GB 00:00 创建域...... | 0 B 00:00 连接到域 ping Escape character is ^] 然后就是我们非常熟悉的OK or Next 了 ，只不过这个过程是文本模式，如果想使用图形，只能开启vnc啦 最后安装完，reboot就进入刚刚创建的虚拟机了。要想退回到宿主机，ctrl + ] 即可。 virsh list 可以列出当前的子机列表。 virsh start ping 开启子机 virsh console ping 可以进入指定的子机 使用python管理API ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:7:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"安装相关包 yum install libvirt-devel ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:8:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"安装python的libvirt库 pip install libvirt-python libvirt ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:9:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"测试 import libvirt conn = libvirt.open(\"qemu:///system\") ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:10:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["虚拟化"],"content":"远程管理 直接上述安装还只能在本地使用python管理。如果还需要远程管理的话还要额外的配置。 修该配置文件/etc/libvirt/libvirtd.conf ###/etc/libvirt/libvirtd.conf listen_tls = 0　#禁用tls登录 listen_tcp = 1　#启用tcp方式登录 tcp_port = \"16509\"　#tcp端口16509 listen_addr = \"0.0.0.0\" unix_sock_group = \"libvirtd\" unix_sock_rw_perms = \"0770\" auth_unix_ro = \"none\" auth_unix_rw = \"none\" auth_tcp = \"none\"　#TCP不使用认证 max_clients = 1024　#最大总的连接客户数1024 min_workers = 50　#libvirtd启动时，初始的工作线程数目 max_workers = 200　#同上，最大数目 max_requests = 1000　#最大同时支持的RPC调用，必须大于等于max_workers max_client_requests = 200　#每个客户端支持的最大连接数 修改配置文件/etc/sysconfig/libvirtd： LIBVIRTD_ARGS=\"--listen\" 重启服务后libvirtd会绑定在16509端口 在远程的机器上安装python库 yum install libvirt-devel python-devel # 要先安装libvirt-devel包，因为libvirt-python依赖于libvirt-devel pip install libvirt libvirt-python 测试代码： import libvirt conn = libvirt.open(\"qemu+tcp://192.168.11.17/system\") 没有报错，安装完毕。 ","date":"2018-06-30","objectID":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/:11:0","tags":["kvm","linux"],"title":"CentOS下kvm安装","uri":"/centos%E4%B8%8Bkvm%E5%AE%89%E8%A3%85/"},{"categories":["运维"],"content":"lnmp即：nginx + mysql + php 与lamp不同的是，lnmp的php不在只是httpd中的一个库，lnmp架构中php作为一个服务，专门解析php。 同样的php依赖mysql，所以首先安装mysql 这里环境为CentOS6.5 安装mysql 这里选择免编译安装，可以在官网找到。在mysql5.5之后的版本不在开源了，但还可以选择mariadb的分支版本作为这个架构的代替。接下来就可以开始mysql的安装了。 ","date":"2018-05-31","objectID":"/lnmp/:0:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"下载mysql wget http://mirrors.sohu.com/mysql/MySQL-5.1/mysql-5.1.73-linux-i686-glibc23.tar.gz 这个版本有点低，可以自己选择合适版本 ","date":"2018-05-31","objectID":"/lnmp/:1:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"解压 tar -zxvf tar -zxvf mysql-5.1.73-linux-i686-glibc23.tar.gz ","date":"2018-05-31","objectID":"/lnmp/:2:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"移动到指定目录 mv mysql-5.1.73-linux-i686-glibc23 /usr/local/mysql ","date":"2018-05-31","objectID":"/lnmp/:3:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"创建mysql用户，但不允许登录，不创建家目录 useradd -s /sbin/nologin -M mysql -s表示指定bash，这里出于安全性考虑设置不允许登录，-M不创建家目录 ","date":"2018-05-31","objectID":"/lnmp/:4:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"创建数据库目录，并改为mysql属主 mkdir /data/mysql -pv chown -R mysql：mysql /data/mysql ","date":"2018-05-31","objectID":"/lnmp/:5:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"初始化mysql cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql --user=*是指定用户mysql，--datadir=*是指定数据库目录。可以使用echo $?验证命令执行结果是否正确，0为正确。 ","date":"2018-05-31","objectID":"/lnmp/:6:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"mysql配置文件 cp /usr/local/mysql/support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf ...... port = 3306 #监听端口 socket = /tmp/mysql.sock #socket ..... log-bin=mysql-bin #修改mysql数据库时，记录日志 ","date":"2018-05-31","objectID":"/lnmp/:7:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"mysql启动脚本 cp /usr/local/mysql/mysql.server /etc/init.d/mysqld vim /etc/init.d/mysqld basedir=/usr/local/mysql #指定安装目录 datadir=/data/mysql #指定数据库目录 ","date":"2018-05-31","objectID":"/lnmp/:8:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"设置开机启动 chkconfig --add mysqld；chkconfig mysqld on 开机启动 编译安装mysql时编译参数记录在cat /usr/local/mysql/bin/mysqlbug |grep -i configure 安装php ","date":"2018-05-31","objectID":"/lnmp/:9:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"下载 wget http://cn2.php.net/get/php-5.4.45.tar.bz2/from/this/mirror ","date":"2018-05-31","objectID":"/lnmp/:10:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"解压 mv mirror php-5.4.45.tar.bz2 tar -jxvf php-5.4.45.tar.bz2 ","date":"2018-05-31","objectID":"/lnmp/:11:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"编译安装 cd php-5.4.45 ./configure --prefix=/usr/local/php --with-config-file-path=/usr/local/php/etc --enable-fpm --with-fpm-user=php-fpm --with-fpm-group=php-fpm --with-mysql=/usr/local/mysql --with-mysql-sock=/tmp/mysql.sock --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-ftp --enable-mbstring --enable-exif --enable-zend-multibyte --disable-ipv6 --with-pear --with-curl # 出现错误： configure: error: jpeglib.h not found. #解决方法： yum install -y libjpeg-devel #出现错误： configure: error: mcrypt.h not found. # 解决方法： wget http://www.lishiming.net/data/attachment/forum/epel-release-6-8_32.noarch.rpm #CentOS的yum扩展源 rpm -ivh epel-release-6-8_32.noarch.rpm yum install -y libmcrypt-devel make make install /usr/local/php/bin/php -m :查看静态模块 /usr/local/php/bin/php -i ：查看相关配置 ","date":"2018-05-31","objectID":"/lnmp/:12:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"php的配置文件 cp /usr/src/php-5.4.45/php.ini-production /usr/local/php/etc/php.ini ","date":"2018-05-31","objectID":"/lnmp/:13:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"php开机启动 cp /usr/src/php-5.4.45/sapi/fpm/init.d.php-fpm /etc/init.d/php-fpm mv /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf #服务启动的脚本配置文件 chkconfig --add php-fpm chkconfig --level 345 php-fpm on ","date":"2018-05-31","objectID":"/lnmp/:14:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"启动php useradd -s /sbin/nologin php-fpm chmod +x /etc/init.d/php-fpm service php-fpm start 安装nginx ","date":"2018-05-31","objectID":"/lnmp/:15:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"下载nginx cd /usr/src wget http://nginx.org/download/nginx-1.6.2.tar.gz ","date":"2018-05-31","objectID":"/lnmp/:16:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"解压 tar -xvf nginx-1.6.2.tar.gz ","date":"2018-05-31","objectID":"/lnmp/:17:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"编译安装 ./configure --prefix=/usr/local/nginx --with-pcre #出现错误： ./configure: error: the HTTP rewrite module requires the PCRE library. #解决方法： yum install -y pcre-devel make make install ","date":"2018-05-31","objectID":"/lnmp/:18:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"启动 编辑启动脚本 vim /etc/init.d/nginx #!/bin/bash # chkconfig: - 30 21 # description: http service. # Source Function Library . /etc/init.d/functions # Nginx Settings NGINX_SBIN=\"/usr/local/nginx/sbin/nginx\" NGINX_CONF=\"/usr/local/nginx/conf/nginx.conf\" NGINX_PID=\"/usr/local/nginx/logs/nginx.pid\" RETVAL=0 prog=\"Nginx\" start() { echo -n $\"Starting $prog: \" mkdir -p /dev/shm/nginx_temp daemon $NGINX_SBIN -c $NGINX_CONF RETVAL=$? echo return $RETVAL } stop() { echo -n $\"Stopping $prog: \" killproc -p $NGINX_PID $NGINX_SBIN -TERM rm -rf /dev/shm/nginx_temp RETVAL=$? echo return $RETVAL } reload(){ echo -n $\"Reloading $prog: \" killproc -p $NGINX_PID $NGINX_SBIN -HUP RETVAL=$? echo return $RETVAL } restart(){ stop start } configtest(){ $NGINX_SBIN -c $NGINX_CONF -t return 0 } case \"$1\" in start) start ;; stop) stop ;; reload) reload ;; restart) restart ;; configtest) configtest ;; *) echo $\"Usage: $0{start|stop|reload|restart|configtest}\" RETVAL=1 esac exit $RETVAL 保存后，更改权限: chmod 755 /etc/init.d/nginx chkconfig --add nginx 开机启动 chkconfig nginx on 启动服务 service nginx start ","date":"2018-05-31","objectID":"/lnmp/:19:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":"测试解析php 编辑配置文件/usr/local/nginx/conf/nginx.conf 修改制定行 ...... location ~ \\.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /usr/local/nginx/html$fastcgi_script_name; #路径为网站根目录 include fastcgi_params; } ...... 在/usr/local/nginx/html/下创建一个info.php文件 \u003c?php phpinfo(); ?\u003e 浏览器访问：http://127.0.0.1/info.php测试 ","date":"2018-05-31","objectID":"/lnmp/:20:0","tags":["linux"],"title":"搭建lnmp环境","uri":"/lnmp/"},{"categories":["运维"],"content":" lamp即 apache + mysql + php，是互联网常用架构。 要注意的是php依赖apache和mysql，所以要最后安装。系统环境为CentOS6.5 安装mysql 这里选择免编译安装，可以在官网找到。在mysql5.5之后的版本不在开源了，但还可以选择mariadb的分支版本作为这个架构的代替。接下来就可以开始mysql的安装了。 ","date":"2018-05-31","objectID":"/lamp/:0:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"下载mysql wget http://mirrors.sohu.com/mysql/MySQL-5.1/mysql-5.1.73-linux-i686-glibc23.tar.gz 这个版本有点低，可以自己选择合适版本 ","date":"2018-05-31","objectID":"/lamp/:1:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"解压 tar -zxvf tar -zxvf mysql-5.1.73-linux-i686-glibc23.tar.gz ","date":"2018-05-31","objectID":"/lamp/:2:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"移动到指定目录 mv mysql-5.1.73-linux-i686-glibc23 /usr/local/mysql ","date":"2018-05-31","objectID":"/lamp/:3:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"创建mysql用户，但不允许登录，不创建家目录 useradd -s /sbin/nologin -M mysql -s表示指定bash，这里出于安全性考虑设置不允许登录，-M不创建家目录 ","date":"2018-05-31","objectID":"/lamp/:4:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"创建数据库目录，并改为mysql属主 mkdir /data/mysql -pv chown -R mysql：mysql /data/mysql ","date":"2018-05-31","objectID":"/lamp/:5:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"初始化mysql cd /usr/local/mysql ./scripts/mysql_install_db --user=mysql --datadir=/data/mysql --user=*是指定用户mysql，--datadir=*是指定数据库目录。可以使用echo $?验证命令执行结果是否正确，0为正确。 ","date":"2018-05-31","objectID":"/lamp/:6:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"mysql配置文件 cp /usr/local/mysql/support-files/my-large.cnf /etc/my.cnf vim /etc/my.cnf ...... port = 3306 #监听端口 socket = /tmp/mysql.sock #socket ..... log-bin=mysql-bin #修改mysql数据库时，记录日志 ","date":"2018-05-31","objectID":"/lamp/:7:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"mysql启动脚本 cp /usr/local/mysql/mysql.server /etc/init.d/mysqld vim /etc/init.d/mysqld basedir=/usr/local/mysql #指定安装目录 datadir=/data/mysql #指定数据库目录 ","date":"2018-05-31","objectID":"/lamp/:8:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"设置开机启动 chkconfig --add mysqld；chkconfig mysqld on 开机启动 编译安装mysql时编译参数记录在cat /usr/local/mysql/bin/mysqlbug |grep -i configure 安装httpd 使用apache的httpd提供网络web服务 ","date":"2018-05-31","objectID":"/lamp/:9:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"下载httpd wget http://mirrors.cnnic.cn/apache/httpd/httpd-2.2.31.tar.gz ","date":"2018-05-31","objectID":"/lamp/:10:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"解压 tar -zxvf httpd-2.2.31.tar.gz ","date":"2018-05-31","objectID":"/lamp/:11:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"编译安装 # 编译 ./configure --prefix=/usr/local/apache \\ \u003e-with-include-apr --enable-so \\ \u003e--enable-deflate=shared \\ \u003e--enable-rewrite=shared \\ \u003e--enable-expires=shared \\ \u003e-with-pcre \\ \u003e-with-mpm=prefork make # 安装 make install 编译选项记录在/usr/local/apache/build/config.nice 中 ","date":"2018-05-31","objectID":"/lamp/:12:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"启动httpd /usr/local/apache/bin/apachectl start /usr/local/apache/bin/apachectl -M ：查看各种库 静态库(编译时直接放入下列文件) /usr/local/apache/bin/httpd 动态库(用到时加载) /usr/local/apache/modules/ /usr/local/apache/bin/apachectl -l ：查看静态库以及apache工作模式 /usr/local/apache/bin/apachectl -t ：查看配置文件有无语法错误 配置文件 /usr/local/apache/conf/httpd.conf /usr/local/apache/bin/apachectl graceful 加载配置文件 启动httpd时的警告： httpd: apr_sockaddr_info_get() failed for 【linux】 httpd: Could not reliably determine the server's fully qualified domain name, using 127.0.0.1 for ServerName 解决方法(问题在于主机名不匹配) 警告1 ：在/etc/hosts中的127.0.0.1行后添加linux 警告2 ：在httpd的配置文件/usr/local/apache/conf/httpd.conf中的ServerName行中改为 ServerName linux:80 ","date":"2018-05-31","objectID":"/lamp/:13:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"开机启动 修改启动脚本 cp /usr/local/apache/bin/apachectl /etc/init.d/httpd vim /etc/init.d/httpd 在#!/bin/bash下加入 #chkconfig:345 61 61 #description:Apache httpd 设置开机启动 chkconfig --add httpd chkconfig --level 345 httpd on 安装php ","date":"2018-05-31","objectID":"/lamp/:14:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"下载php wget http://cn2.php.net/get/php-5.4.45.tar.bz2/from/this/mirror ","date":"2018-05-31","objectID":"/lamp/:15:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"解压 mv mirror php-5.4.45.tar.bz2 tar -jxvf php-5.4.45.tar.bz2 ","date":"2018-05-31","objectID":"/lamp/:16:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"编译安装 cd php-5.4.45 ./configure --prefix=/usr/local/php --with-apxs2=/usr/local/apache/bin/apxs --with-config-file-path=/usr/local/php/etc --with-mysql=/usr/local/mysql --with-libxml-dir --with-gd --with-jpeg-dir --with-png-dir --with-freetype-dir --with-iconv-dir --with-zlib-dir --with-bz2 --with-openssl --with-mcrypt --enable-soap --enable-gd-native-ttf --enable-mbstring --enable-sockets --enable-exif --disable-ipv6 #出现错误： configure: error: jpeglib.h not found. # 解决方法： yum install -y libjpeg-devel #出现错误： configure: error: mcrypt.h not found. #解决方法： wget http://www.lishiming.net/data/attachment/forum/epel-release-6-8_32.noarch.rpm #CentOS的yum扩展源 rpm -ivh epel-release-6-8_32.noarch.rpm yum install -y libmcrypt-devel make make install /usr/local/php/bin/php -m :查看静态模块 /usr/local/php/bin/php -i ：查看相关配置 ","date":"2018-05-31","objectID":"/lamp/:17:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"修改配置文件 cp /usr/src/php-5.4.45/php.ini-production /usr/local/php/etc/php.ini vim /usr/local/apache/conf/httpd.conf 在 AddType application/x-compress .Z AddType application/x-gzip .gz .tgz 两行下加入 AddType application/x-httpd-php .php 将 DirectoryIndex index.html 后添加 1.php DirectoryIndex index.html 1.php ","date":"2018-05-31","objectID":"/lamp/:18:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["运维"],"content":"测试 在Apache的安装文件中添加php文件 /usr/local/apache/htdocs/目录下创建 vim 1.php \u003c?php echo \"Welcome to 1.php\" ; ?\u003e ","date":"2018-05-31","objectID":"/lamp/:19:0","tags":["linux"],"title":"搭建lamp环境","uri":"/lamp/"},{"categories":["笔记"],"content":"简单的装饰器函数： import time from functools import wraps def timethis(func): \"\"\" Decorator that reports the execution time. \"\"\" @wraps(func) def wrapper(*args, **kwargs): start = time.time() result = func(*args, **kwargs) end = time.time() print(func.__name__, end-start) return result return wrapper 函数的功能很简单，就是输出调用函数的执行时间。 In [2]: @timethis ...: def countdown(n): ...: while n \u003e 0: ...: n -= 1 ...: In [3]: countdown(100000) countdown 0.009751319885253906 本质上来说python的装饰器就是一个函数外再包装一个函数，等同于： timethis(countdown(100000)) 装饰器内部的wrapper()函数中使用*args和**kwargs来接受任意参数，并用新的函数包装器来代替原来函数，其中的func就是原来的函数，即调用包装器的函数。而使用@wraps(func)的目的时保留原始函数的元数据。 In [19]: @timethis ...: def countdown(n:int): ...: '''counts down''' ...: while n \u003e 0: ...: n -= 1 ...: In [20]: countdown(100000) countdown 0.008384943008422852 In [21]: countdown.__name__ Out[21]: 'countdown' In [22]: countdown.__doc__ Out[22]: 'counts down' In [23]: countdown.__annotations__ Out[23]: {'n': int} 输出的原始函数的元数据都正常 再来看看去掉wraps()函数的 In [26]: countdown.__name__ Out[26]: 'wrapper' In [27]: countdown.__doc__ In [28]: countdown.__annotations__ Out[28]: {} @wraps 有一个重要特征是它能让你通过属性 wrapped 直接访问被包装函数。例如: In [34]: countdown.__wrapped__.__name__ Out[34]: 'countdown' __wrapped__ 属性还能让被装饰函数正确暴露底层的参数签名信息。例如： In [43]: from inspect import signature In [44]: signature(countdown) Out[44]: \u003cSignature (n:int)\u003e 带参数的装饰器 import logging from functools import wraps def logged(level, name=None, message=None): def decorate(func): logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper return decorate @logged(logging.DEBUG) def add(x, y): return x + y @logged(logging.CRITICAL, 'example') def spam(): print(\"Spam!\") 带可选参数的装饰器 import logging from functools import wraps, partial def logged(func=None, *, level=logging.DEBUG, name=None, message=None): if func is None: return partial(logged, level=level, name=name, message=message) logname = name if name else func.__module__ log = logging.getLogger(logname) logmsg = message if message else func.__name__ @wraps(func) def wrapper(*args, **kwargs): log.log(level, logmsg) return func(*args, **kwargs) return wrapper @logged def add(x, y): return x + y @logged(level=logging.CRITICAL, name='example') def spam(): print(\"Spam!\") ","date":"2018-03-31","objectID":"/python%E8%A3%85%E9%A5%B0%E5%99%A8/:0:0","tags":["python"],"title":"python装饰器","uri":"/python%E8%A3%85%E9%A5%B0%E5%99%A8/"},{"categories":["代码"],"content":" 后端使用flask设计基于token认证方式的restful接口，前端使用vue.js全家桶，利用axios通讯。 感谢两篇文章的作者： http://www.cnblogs.com/vovlie/p/4182814.html https://segmentfault.com/a/1190000008383094?_ea=1639495 源码链接：https://github.com/xingyys/flaskvue 后端Flask Flask采用token认证方式，主要思路是通过/api/login登录获取token，然后使用token调用各个接口。 所用到框架的库： flask flask-cors：flask跨域 flask-sqlachemy: flask数据库orm flask-httpauth：flask的auth认证 passlib: python密码解析库 itsdangerous ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:0:0","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"后端结构图 flask/ ├── app # 主目录 │ ├── __init__.py │ ├── __init__.pyc │ ├── models.py # 数据库 │ ├── models.pyc │ ├── views.py # 视图 │ └── views.pyc ├── config.py # 配置信息 ├── config.pyc ├── db_create.py # 创建数据库 ├── db_migrate.py # 更新数据库 ├── db_repository │ ├── __init__.py │ ├── __init__.pyc │ ├── manage.py │ ├── migrate.cfg │ ├── README │ └── versions │ ├── 008_migration.py │ ├── 008_migration.pyc │ ├── 009_migration.py │ ├── 009_migration.pyc │ ├── __init__.py │ └── __init__.pyc ├── index.html └── run.py # app的运行文件 ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:1:0","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"具体实现 ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:0","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"系统初始化app/__init__.py # -*- coding:utf-8 -*- from flask import Flask from flask_sqlalchemy import SQLAlchemy from flask_httpauth import HTTPBasicAuth from flask_cors import CORS app = Flask(__name__) # flask的跨域解决 CORS(app) app.config.from_object('config') db = SQLAlchemy(app) auth = HTTPBasicAuth() from . import models, views ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:1","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"配置文件config.py import os basedir = os.path.abspath(os.path.dirname(__file__)) SQLALCHEMY_DATABASE_URI = \"mysql://root:123456@127.0.0.1/rest\" SQLALCHEMY_MIGRATE_REPO = os.path.join(basedir, 'db_repository') SQLALCHEMY_TRACK_MODIFICATIONS = True BASEDIR = basedir # 安全配置 CSRF_ENABLED = True SECRET_KEY = 'jklklsadhfjkhwbii9/sdf\\sdf' 环境中使用mysql数据库，版本为mariadb 10.1.22。创建rest表 $ mysql -uroot -p xxxxxx $ create database rest default charset utf8; ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:2","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"创建数据库表app/models.py # -*- coding:utf-8 -*- from app import db, app from passlib.apps import custom_app_context from itsdangerous import TimedJSONWebSignatureSerializer as Serializer, SignatureExpired, BadSignature class User(db.Model): __tablename__ = 'users' id = db.Column(db.Integer, primary_key=True) username = db.Column(db.String(32), index=True) password = db.Column(db.String(128)) # 密码加密 def hash_password(self, password): self.password = custom_app_context.encrypt(password) # 密码解析 def verify_password(self, password): return custom_app_context.verify(password, self.password) # 获取token，有效时间10min def generate_auth_token(self, expiration = 600): s = Serializer(app.config['SECRET_KEY'], expires_in = expiration) return s.dumps({ 'id': self.id }) # 解析token，确认登录的用户身份 @staticmethod def verify_auth_token(token): s = Serializer(app.config['SECRET_KEY']) try: data = s.loads(token) except SignatureExpired: return None # valid token, but expired except BadSignature: return None # invalid token user = User.query.get(data['id']) return user 创建数据库users表： $ python db_create.py $ python db_migrate.py ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:3","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"视图app/views.py from app import app, db, auth from flask import render_template, json, jsonify, request, abort, g from app.models import * @app.route(\"/\") @auth.login_required def index(): return jsonify('Hello, %s' % g.user.username) @app.route('/api/users', methods = ['POST']) def new_user(): username = request.json.get('username') password = request.json.get('password') if username is None or password is None: abort(400) # missing arguments if User.query.filter_by(username = username).first() is not None: abort(400) # existing user user = User(username = username) user.hash_password(password) db.session.add(user) db.session.commit() return jsonify({ 'username': user.username }) @auth.verify_password def verify_password(username_or_token, password): if request.path == \"/api/login\": user = User.query.filter_by(username=username_or_token).first() if not user or not user.verify_password(password): return False else: user = User.verify_auth_token(username_or_token) if not user: return False g.user = user return True @app.route('/api/login') @auth.login_required def get_auth_token(): token = g.user.generate_auth_token() return jsonify(token) 用户注册后密码加密存储，确认用户身份时密码解密。需要认证的api上添加@auth.login_required，它会在调用接口之前调用@auth.verify_password下的方法(此方法唯一)如verify_password。根据请求的路径选择不同的认证方式。 ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:4","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"测试 使用curl命令测试接口 注册用户: $ curl -i -X POST -H \"Content-Type: application/json\" -d '{\"username\":\"admin\",\"password\":\"123456\"}' http://127.0.0.1:5000/api/register HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 26 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:33:46 GMT { \"username\": \"admin\" } 查看数据库： MariaDB [rest]\u003e select * from users\\G; *************************** 1. row *************************** id: 1 username: admin password: $6$rounds=656000$etV4F3xLL0dwflX8$mLFX9l5dumBnQFtajGmey346viGuQ4bxR7YhQdKtB/nQH9ij2e3HHMEBPj.ef/o//4o9P2Wd3Y7dxQfjwR2hY/ 1 row in set (0.00 sec) 获取token： curl -i -u admin:123456 -X GET -H \"Content-Type: application/json\" http://127.0.0.1:5000/api/login HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 125 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:37:01 GMT \"eyJhbGciOiJIUzI1NiIsImV4cCI6MTUwNTg5MDAyMSwiaWF0IjoxNTA1ODg5NDIxfQ.eyJpZCI6MX0.nUIKq-ZhFOiLPwZyUmfgWPfHYNy8o6eoR6lmzdsY0oQ\" 使用token调用api： $ curl -i -u eyJhbGciOiJIUzI1NiIsImV4cCI6MTUwNTg5MDAyMSwiaWF0IjoxNTA1ODg5NDIxfQ.eyJpZCI6MX0.nUIKq-ZhFOiLPwZyUmfgWPfHYNy8o6eoR6lmzdsY0oQ:unused -X GET -H \"Content-Type: application/json\" http://127.0.0.1:5000/ HTTP/1.0 200 OK Content-Type: application/json Access-Control-Allow-Origin: * Content-Length: 15 Server: Werkzeug/0.12.2 Python/2.7.13 Date: Wed, 20 Sep 2017 06:38:22 GMT \"Hello, admin\" 基于token的Flask api成功！！！！ 前端Vue.js 前端使用vue的全家桶，axios前后端通讯，axios拦截器，localStorage保存token 所使用的框架和库： vue2.0 iview2.X axios vuex vue-router ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:2:5","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"具体实现 ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:0","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"main.js // 初始化axios axios.defaults.baseURL = 'http://127.0.0.1:5000' axios.defaults.auth = { username: '', password: '', } // axios.interceptors.request.use((config) =\u003e { // console.log(config) // return config; // }, (error) =\u003e { // return Promise.reject(error) // }) // axios拦截器，401状态时跳转登录页并清除token axios.interceptors.response.use((response) =\u003e { return response; }, (error) =\u003e { if (error.response) { switch (error.response.status) { case 401: store.commit('del_token') router.push('/login') } } return Promise.reject(error.response.data) }) // 路由跳转 router.beforeEach((to, from, next) =\u003e { if (to.meta.required) { // 检查localStorage if (localStorage.token) { store.commit('set_token', localStorage.token) // 添加axios头部Authorized axios.defaults.auth = { username: store.state.token, password: store.state.token, } // iview的页面加载条 iView.LoadingBar.start(); next() } else { next({ path: '/login', }) } } else { iView.LoadingBar.start(); next() } }) router.afterEach((to, from, next) =\u003e { iView.LoadingBar.finish(); }) ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:1","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"路由 export default new Router({ routes: [{ path: '/', name: 'index', component: Index, meta: { required: true, } }, { path: '/login', name: 'login', component: Login, }] }) 路由添加meta字段，作为需要认证路由的标志 ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:2","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"vuex export default new Vuex.Store({ state: { token: '' }, mutations: { set_token(state, token) { state.token = token localStorage.token = token }, del_token(state) { state.token = '' localStorage.removeItem('token') } } }) vuex中保存token，同时修改删除token和localStorage.token ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:3","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"},{"categories":["代码"],"content":"登录和登出 登录： handleSubmit(name, form) { this.$refs[name].validate((valid) =\u003e { if (valid) { // 用户名密码简单验证后添加到axios的auth中 this.$axios.defaults.auth = { username: form.username, password: form.password, } this.$axios.get('/api/login').then(response =\u003e { this.$Message.success(\"提交成功\") let data = response.data // 保存token this.$store.commit('set_token', data) this.$router.push('/') }).catch(error =\u003e { this.$Message.error(error.status) }) } else { this.$Message.error('表单验证失败!'); } }) } 登出： logout() { this.$store.commit('del_token') this.$router.push('/login') } 删除token并跳转到登录页 flask和vue的token认证就完成了！！！！ ","date":"2017-09-20","objectID":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/:3:4","tags":["flask","vue"],"title":"Flask与Vue的token认证","uri":"/flask%E4%B8%8Evue%E7%9A%84token%E8%AE%A4%E8%AF%81/"}]